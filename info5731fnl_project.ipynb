{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhQvqDXuzm2LkTKbjONYUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kusalsai/Ayinala_INFO5731_Spring2025/blob/main/info5731fnl_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1Re-Ra8jJfML",
        "outputId": "d383dc91-9ef6-42b0-b524-9a606bd521ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.25)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.2.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.15)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install llama-index\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "from llama_index.core.node_parser import NodeParser # Import NodeParser\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "4rK9hfUrJnQi"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade python-pptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgP9di5aMFJW",
        "outputId": "8b07a76c-cf3d-4cc6-e18c-f24466a9b630"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
        "\n",
        "# Assuming the PDF is directly in /content/\n",
        "# If it's in a subfolder, adjust the path accordingly\n",
        "document = SimpleDirectoryReader(\n",
        "    input_files=[\"/content/[Thien Huu Nguyen][DEEP LEARNING FOR INFORMATION EXTRACTION]-1.pdf\"]\n",
        ").load_data()\n",
        "\n"
      ],
      "metadata": {
        "id": "hkJL21WFE0Qu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "# initialize settings (set chunk size)\n",
        "Settings.chunk_size = 1024  # You can set this to any value you want"
      ],
      "metadata": {
        "id": "LrsX2wqdolCN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMXT4h1dpgn4",
        "outputId": "27d951f5-f83f-4fa2-93aa-38d76744c4a5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id_='a59d7e30-46ba-4358-8aaf-de627d8f6fd2', embedding=None, metadata={'page_label': 'ii', 'file_name': '[Thien Huu Nguyen][DEEP LEARNING FOR INFORMATION EXTRACTION]-1.pdf', 'file_path': '/content/[Thien Huu Nguyen][DEEP LEARNING FOR INFORMATION EXTRACTION]-1.pdf', 'file_type': 'application/pdf', 'file_size': 7952475, 'creation_date': '2025-03-19', 'last_modified_date': '2025-03-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='© Thien Huu Nguyen\\nAll Rights Reserved, 2017', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in document:\n",
        "  print(i)\n",
        "  print(\"/n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlpyvSRajuE2",
        "outputId": "210f6a7b-f403-4e9b-fab9-e8ce3c3cb03e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc ID: 83e46c27-50d5-4a32-993c-f9f21d9be537\n",
            "Text: DEEP LEARNING FOR INFORMATION EXTRACTION by Thien Huu Nguyen A\n",
            "dissertation submitted in partial fulfillment of the requirements for\n",
            "the degree of Doctor of Philosophy Department of Computer Science New\n",
            "York University May, 2017 Professor Ralph Grishman\n",
            "/n\n",
            "Doc ID: a59d7e30-46ba-4358-8aaf-de627d8f6fd2\n",
            "Text: © Thien Huu Nguyen All Rights Reserved, 2017\n",
            "/n\n",
            "Doc ID: 0f590758-3e07-4c6a-b854-dcac999a4c27\n",
            "Text: Dedication To my beloved mother iii\n",
            "/n\n",
            "Doc ID: ca40a394-7ca0-48d1-ba39-e259b57f2482\n",
            "Text: Acknowledgments PeoplehavedifferentstoriestotellintheirPhDtime.\n",
            "MyPhDjourneybeganat a day of Fall 2012. I was supposed to meet my\n",
            "advisor, Professor Ralph Grishman, for the first time in his office.\n",
            "However, on my road to his office that day, I accidentally ran into\n",
            "him in the Broadway avenue. It was the first time I talked to Ralph in\n",
            "person af...\n",
            "/n\n",
            "Doc ID: 2c6038e2-8463-471b-ab7f-74645927dff2\n",
            "Text: ACKNOWLEDGMENTS I own special thanks to Professor Kyunghyun Cho,\n",
            "an outstanding advisor and a great friend who taught me much about\n",
            "deep learning and its potentials to transform our life. Kyunghyun has\n",
            "always been generous on spending his time discussing with me and\n",
            "providing me with great helps and encouragement. I also would like to\n",
            "thank the ...\n",
            "/n\n",
            "Doc ID: f030fe91-2051-48ca-ada4-f3c167ac0a0f\n",
            "Text: ACKNOWLEDGMENTS within the Knowledge Induction team, working\n",
            "with Dr. Mariano Rodriguez muro, Dr. Oktie Hassanzadeh, Dr. Achille\n",
            "Fokoue, Dr. Mohammad Sadoghi Hamedani, Dr. Alfio M Gliozzo and Dr.\n",
            "Lisa Amini. This was another fruitful internship at IBM with one paper\n",
            "and one patent published that I would not be able to make without such\n",
            "great men...\n",
            "/n\n",
            "Doc ID: 35ae7682-8d3a-4b41-8305-5e0b99e3bb66\n",
            "Text: Abstract The explosion of data has made it crucial to analyze\n",
            "the data and distill im- portant information effectively and\n",
            "efficiently. A significant part of such data is presented in\n",
            "unstructured and free-text documents. This has prompted the\n",
            "development of the techniques for information extraction that allow\n",
            "computers to automatically extract ...\n",
            "/n\n",
            "Doc ID: 5f01df0f-cfa7-4592-8ff6-b3d44cc0c559\n",
            "Text: ABSTRACT multiple layers of connections to reveal the underlying\n",
            "representations of data. I develop the fundamental deep learning\n",
            "models for information extraction problems and demonstrate their\n",
            "benefits through systematic experiments. First, I examine word\n",
            "embeddings, a general word representation that is pro- duced by\n",
            "training a deep learning ...\n",
            "/n\n",
            "Doc ID: 456b9f9b-9845-484a-93c9-dfc8b742d464\n",
            "Text: T able of contents Dedication iii Acknowledgments iv Abstract\n",
            "vii List of Figures xiv List of T ables xvi 1 Introduction 1 1.1\n",
            "Information Extraction . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". 4 1.1.1 Entity Mention Detection . . . . . . . . . . . . . . . . . .\n",
            ". 7 1.1.2 Relation Extraction . . . . . . . . . . . . . . . . . . . .\n",
            ". . . 8 ...\n",
            "/n\n",
            "Doc ID: d1e314d3-e7a5-4b33-b28d-43413004f246\n",
            "Text: TABLE OF CONTENTS 1.2.2 Representation Learning . . . . . . . .\n",
            ". . . . . . . . . . . . 20 1.3 Prior Work . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . 26 1.4 Outline of Thesis . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . 30 2 W ord Embeddings for\n",
            "Domain Adaptation of Relation Extraction 31 2.1 The Feature-based\n",
            "Approa...\n",
            "/n\n",
            "Doc ID: 4cd8c6f7-c8c0-42b1-b711-5e3a19fba6d1\n",
            "Text: TABLE OF CONTENTS 3.2 Word Representation . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . 76 3.3 Experiments . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . 77 3.3.1 Dataset . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . 77 3.3.2 Resources and\n",
            "Parameters . . . . . . . . . . . . . . . . . . . 78 3.3.3 Model\n",
            "Architectu...\n",
            "/n\n",
            "Doc ID: 427c555a-d51b-476f-ad63-9341def7d60f\n",
            "Text: TABLE OF CONTENTS 5 Deep Learning for Event Detection 129 5.1\n",
            "Convolutional Neural Networks for Event Detection. . . . . . . . . 130\n",
            "5.1.1 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". 131 5.1.2 Experiments . . . . . . . . . . . . . . . . . . . . . . .\n",
            ". . . . 134 5.2 Non-consecutive Convolutional Neural Networks for\n",
            "Event De...\n",
            "/n\n",
            "Doc ID: 8bf3e8fe-246d-4f47-a458-59276d79aa35\n",
            "Text: TABLE OF CONTENTS 6.4.3 Experiments . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . 185 6.4.4 Comparing to the Previous Work . .\n",
            ". . . . . . . . . . . . . 188 6.4.5 Domain Adaptation Experiments . .\n",
            ". . . . . . . . . . . . . 190 6.5 Related Work . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . 194 6.6 Conclusion . . . . . . . .\n",
            "...\n",
            "/n\n",
            "Doc ID: b91316ef-5849-4776-b04b-06edfbf939e3\n",
            "Text: List of Figures 1.1 Information extraction system. . . . . . . .\n",
            ". . . . . . . . . . . . . . . 6 1.2 Information extraction pipeline. .\n",
            ". . . . . . . . . . . . . . . . . . . . . 7 1.3 Feed-forward Neural\n",
            "Networks. . . . . . . . . . . . . . . . . . . . . . . 23 2.1   vs\n",
            "F-measure on PET+HEAD+PHRASE . . . . . . . . . . . . . . . 56 3.1 The\n",
            "ELMAN a...\n",
            "/n\n",
            "Doc ID: fdd148c2-84cf-4d05-8d3e-ac7b43b1f860\n",
            "Text: List of Figures 6.3 Prediction tasks for event extraction. . . .\n",
            ". . . . . . . . . . . . . . . . 157 6.4 Memory-augmented neural\n",
            "networks for event extraction.. . . . . . . . 159 6.5 ThejointEE\n",
            "modelfor theinputsentence“ a man died when a tank fired in Baghdad ”\n",
            "with local context windowd = 1 . We only demonstrate the memory\n",
            "matricesGarg/trg i i...\n",
            "/n\n",
            "Doc ID: d6f28180-d9d9-4b7e-a183-a9ac31b2673b\n",
            "Text: List of T ables 2.1 Lexical feature groups ordered by\n",
            "importance. . . . . . . . . . . . . . . 38 2.2 In-domain and Out-of-\n",
            "domain performance for different embedding fea- tures. . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 2.3 Domain\n",
            "adaptation results with word representations.. . . . . . . . . . 41\n",
            "2.4 Domain adapt...\n",
            "/n\n",
            "Doc ID: f069b055-5fcf-4269-8828-441dcb9ff465\n",
            "Text: List of Tables 3.3 The bidirectional models’ performance . . . .\n",
            ". . . . . . . . . . . . . . 80 3.4 Comparison to (Mesnil et al.,\n",
            "2013). . . . . . . . . . . . . . . . . . . . 81 3.5 Comparison of\n",
            "methods for word embeddings. . . . . . . . . . . . . . . 82 3.6\n",
            "System’s performance on the cross-domain setting. Cells marked with\n",
            "†designate the BIDI...\n",
            "/n\n",
            "Doc ID: 5bbb0513-bc25-4404-992b-211ad3e24fdd\n",
            "Text: List of Tables 4.9 Performance of relation classification\n",
            "systems. The “†” refers to special treatment of theOther class. . . .\n",
            ". . . . . . . . . . . . . . . . . . . . 126 4.10 The performance\n",
            "breakdown per relation for CNN and BIDIRECT on the development set. .\n",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . 126 5.1\n",
            "Performance on the dev...\n",
            "/n\n",
            "Doc ID: 1d9f1938-2c99-43e9-9f15-549cc4484b50\n",
            "Text: List of Tables 6.4 System performance on single event sentences\n",
            "(1/1) and multiple event sentences (1/N). . . . . . . . . . . . . . .\n",
            ". . . . . . . . . . . . . . . . 175 6.5 Performance of the global\n",
            "features on the development set.No means not using the global\n",
            "features. . . . . . . . . . . . . . . . . . . . . . . . 188 6.6\n",
            "Performance of the sy...\n",
            "/n\n",
            "Doc ID: 6082a787-139c-4fad-afe8-b47edfad988f\n",
            "Text: Chapter 1 Introduction Entities and events are the central\n",
            "objects in the languages we produce in\n",
            "discussionandcommunicationeveryday. Forinstance, thearticlesfrom\n",
            "newsmight describe some recent attacks (events) while we might talk\n",
            "about celebrities or politicians(entities)inourcasualdiscussion.\n",
            "Itisthereforecrucialforcomputersto recognizesuchent...\n",
            "/n\n",
            "Doc ID: be49cd5d-e9ac-4e27-8c86-9660c59738fb\n",
            "Text: CHAPTER 1. INTRODUCTION pipelines often involve various NLP\n",
            "supervised modules and resources to extract different linguistic\n",
            "characteristics, hopefully capturing important features for the IE\n",
            "tasks. The determination of which NLP modules and resources are used\n",
            "and which features should be extracted is called “feature\n",
            "engineering”. For convenienc...\n",
            "/n\n",
            "Doc ID: 216f79c7-50fa-4210-94c6-b85cda43c924\n",
            "Text: CHAPTER 1. INTRODUCTION learning models do not appear in the new\n",
            "data to which we want to apply the models, causing the failure of the\n",
            "models on such new data. The unseen word/feature problem is stem from\n",
            "the representations of words as symbolic items and the computation of\n",
            "the feature values as the discrete compositions of words. Such\n",
            "discrete ...\n",
            "/n\n",
            "Doc ID: 45957ab7-69d8-4c2d-b250-2284987d6b94\n",
            "Text: CHAPTER 1. INTRODUCTION and then review some background on\n",
            "machine learning and deep learning that is\n",
            "necessaryforthenextchapters. Afterward,\n",
            "Iwillpresentsomeoftherepresentative previous works for IE. Finally, I\n",
            "will sketch an outline for this dissertation. 1.1 Information\n",
            "Extraction Information Extraction is the process of extracting\n",
            "structured...\n",
            "/n\n",
            "Doc ID: 9210a34d-9ad8-43e8-8ac0-b1aaca4fa9a5\n",
            "Text: CHAPTER 1. INTRODUCTION presents a piece of unstructured text\n",
            "from some set of documents while the right side demonstrates the\n",
            "relation and event databases we want to create from the left side’s\n",
            "text. As we can see in the figure, the relation database contains the\n",
            "semantic relation “leaderOf ” between Giuliani (the former mayor of\n",
            "New York City)...\n",
            "/n\n",
            "Doc ID: df6bc0a1-4f9a-4656-b1cc-114a272ecf5d\n",
            "Text: CHAPTER 1. INTRODUCTION Figure 1.1: Information extraction\n",
            "system. “Giuliani finally settled his divorce from Donna Hanover in\n",
            "July after 20 years of marriage. Five months later, Giuliani proposed\n",
            "to Nathan, a former nurse, who gave him tremendous emotional support\n",
            "through his cancer treatment and as he led New York City during the\n",
            "Sept. 11, 200...\n",
            "/n\n",
            "Doc ID: 5ff2e7c3-1044-4154-a369-a21a3f724209\n",
            "Text: CHAPTER 1. INTRODUCTION Figure 1.2: Information extraction\n",
            "pipeline. 1.1.1 Entity Mention Detection In the IE pipeline, the first\n",
            "task to build the relation database is Entity Mention Detection (EMD)\n",
            "that is supposed to locate and classify entity mentions in text into\n",
            "predefined classes (types). Entity mentions are continuous sequences\n",
            "of words ...\n",
            "/n\n",
            "Doc ID: 8e143337-d9f2-4329-852c-6f251b3e93ae\n",
            "Text: CHAPTER 1. INTRODUCTION for entity names, an EMD system should\n",
            "be able to recognize “Giuliani”, “Donna Hanover” and “Nathan” as\n",
            "person names, “New Y ork City” as a city name, and “July” and “Sept.\n",
            "11, 2011 ” as times3. Besides, an EMD system should realize that the\n",
            "pronouns “he”, “his”, “him” and “who” as well as the nominal “a former\n",
            "nurse” are...\n",
            "/n\n",
            "Doc ID: fc565de6-09f4-4aee-b617-76239371a80d\n",
            "Text: CHAPTER 1. INTRODUCTION semantic relationships between two\n",
            "entity mentions within in the same sentences. For convenience, we\n",
            "often call any pairs of entity mentions appearing in the same\n",
            "sentences as relation mentions. In our example text, a relation\n",
            "extraction system is expected to identify the relation of type “leader\n",
            "of ” between the entity m...\n",
            "/n\n",
            "Doc ID: b397809d-657b-4115-bdfe-b4150e54c1c1\n",
            "Text: CHAPTER 1. INTRODUCTION 1.1.4 Entity Linking The name “Giuliani”\n",
            "provides some identity information for the the pronouns “he”, “his”,\n",
            "and “him”, and their corresponding entity cluster. However, it is not\n",
            "sufficient to determine an unique person (entity) in reality that is\n",
            "necessary to find the entry for this entity in the database. This\n",
            "problem ...\n",
            "/n\n",
            "Doc ID: 68356b61-2d07-40f0-8d84-db957f7f1868\n",
            "Text: CHAPTER 1. INTRODUCTION (i.e, Entity Mention Detection, Relation\n",
            "Extraction, Coreference Resolution and Entity Linking) allows us to\n",
            "populate the relation database as we can see in Figure 1.1. In the\n",
            "next section, we discuss the necessary steps to fill in the event\n",
            "database. Similartotherelationdatabase,\n",
            "thefirststepfortheeventdatabaseisdetectin...\n",
            "/n\n",
            "Doc ID: 680c19fd-07aa-4e86-be60-9845ecba1bde\n",
            "Text: CHAPTER 1. INTRODUCTION The Event Extraction task is to identify\n",
            "and classify the trigger words into some types of interest as well as\n",
            "locate arguments for the detected event types within the same\n",
            "sentence. Traditionally, event extraction systems have sequen- tially\n",
            "performed the two following steps: (i) recognizing event triggers in\n",
            "sentences (...\n",
            "/n\n",
            "Doc ID: 2dcf54f6-81cc-45dd-b830-548a0828dd03\n",
            "Text: CHAPTER 1. INTRODUCTION In order to solve this classification\n",
            "problem for IE, the first step is to design some functionR to\n",
            "transform the initial input objectX into some mathematical\n",
            "representation R(X) that is more convenient for the mathematical\n",
            "analysis later. Practically,R(X) is often a binary of continuous\n",
            "vector that is expected to involve...\n",
            "/n\n",
            "Doc ID: eebf2ea6-4b28-4958-8c93-c93a20c714cf\n",
            "Text: CHAPTER 1. INTRODUCTION joint probability distribution over\n",
            "these two variables. In addition,L(S(X;\u0012);Y ) is the cost function or\n",
            "the objective function that evaluates the loss of usingS(X;\u0012) to\n",
            "determine the class forX (the predicted class) given thatY is the\n",
            "correct class for X in this case. Unfortunately, the evaluation of the\n",
            "expectation in ...\n",
            "/n\n",
            "Doc ID: 1c612ad8-abee-4df5-a5a1-65d008788516\n",
            "Text: CHAPTER 1. INTRODUCTION \u0012\u0003 \u0019argmin\u0012 [ 1 n n∑ i=1 L(S(Xi;\u0012);Yi) +\n",
            "\u0015Ω(\u0012) ] (1.4) where \u0015 is a tradeoff between the loss on the training\n",
            "datasetD and the com- plexity of the model measured byΩ(\u0012). The\n",
            "regularizerΩ(\u0012) is often some norm of \u0012 such as theL1 norm jj\u0012jj1 or\n",
            "theL2 norm jj\u0012jj2. The optimization problem in Equation1.4 can be\n",
            "solved by tech...\n",
            "/n\n",
            "Doc ID: 6016580e-737a-4a5e-a7ed-90287cfd486f\n",
            "Text: CHAPTER 1. INTRODUCTION mechanisms to compute such\n",
            "characteristics for the input instancesX. Features in this approach\n",
            "often have binary values to indicate the presence or absence of some\n",
            "discrete linguistic structures (i.e, the appearance of some word in\n",
            "some gazetteer, the occurrence of some word or syntactic relation in\n",
            "the context, etc). Fea...\n",
            "/n\n",
            "Doc ID: 4f449e9c-1457-4291-9cb5-dd847b3fa07a\n",
            "Text: CHAPTER 1. INTRODUCTION convenience, we denoted as the size of\n",
            "the vectorR(X) (jR(X)j= d). Note that this sized is fixed for all the\n",
            "representation vectorsR(X) of all the possible input instances X.\n",
            "1.2.1.1 Maximum Entropy In Maximum Entropy (Kambhatla,2004), we\n",
            "parameterizeS(R(X)) by a pa- rameter matrixB (B 2Rd\u0002K) to assign\n",
            "importance weights ...\n",
            "/n\n",
            "Doc ID: 39d99fcc-ceb4-4381-bf40-431672cf3bd0\n",
            "Text: CHAPTER 1. INTRODUCTION The parameter we need to learn in this\n",
            "case is\u0012= [ B;b] while the loss function L(S(X;\u0012);Y ) is often the\n",
            "negative log-likelihood: L(S(X;\u0012);Y ) = \u0000logS(X;\u0012)[Y] = \u0000log [ eaY ∑K\n",
            "i=1 eai ] (1.7) The classY\u0003 for a new instanceX is determined by the\n",
            "class with the highest score inS(X;\u0012): Y\u0003 = argmaxS(X;\u0012) (1.8) 1.2.1.2\n",
            "Support...\n",
            "/n\n",
            "Doc ID: 92f93ffa-16c2-4509-bd32-b6afefb99b03\n",
            "Text: CHAPTER 1. INTRODUCTION hyperplane of SVM is then the hyperplane\n",
            "that stands in the middle of the such two hyperplanes. This process\n",
            "translates into the score functionS(R(X)) that are parameterized by a\n",
            "weight vectorB (jBj= jR(X)j) and a biasb (\u0012= [ B;b]): S(R(X)) = BTR(X)\n",
            "\u0000b (1.9) The loss function in this case is the hinge loss function:\n",
            "L(S(X...\n",
            "/n\n",
            "Doc ID: 91c21b7b-5b31-448d-a374-9ffaf271f008\n",
            "Text: CHAPTER 1. INTRODUCTION mapping the instances in the original\n",
            "space, the kernel trick suggests that we only need to build a kernel\n",
            "functionk : X\u0002X! R to compute a score for every pair of instances\n",
            "(X;X′) in X. The expectation is that this score will correspond to the\n",
            "dot product between the images ofX and X′ in the new spaceV, and that\n",
            "the kerne...\n",
            "/n\n",
            "Doc ID: e99fa2c5-f752-4b7a-a575-dc17f497e820\n",
            "Text: CHAPTER 1. INTRODUCTION problems, the input instancesX are not\n",
            "readily presented in this format as they often involve sentences,\n",
            "sequences of discrete symbols for words. I will show how to convert\n",
            "the discrete instancesX in IE into the continuos tensors when we\n",
            "discuss the specific IE problems. For convenience, in this section, we\n",
            "will assume th...\n",
            "/n\n",
            "Doc ID: 6d056bab-6f5f-4d00-b6af-11d59bc93566\n",
            "Text: CHAPTER 1. INTRODUCTION g([v1;v2;:::;v h]) = [ g(v1);g(v2);:::;g\n",
            "(vh)] (1.13) Some typical nonlinear functions for deep learning\n",
            "includesigmoid, tanh and rectifier: sigmoid(t) = 1 1 + e\u0000t (1.14)\n",
            "tanh(t) = 1 \u0000e\u00002t 1 + e\u00002t (1.15) rectifier(t) = max(0;t) (1.16)\n",
            "Agraphicalillustrationforfeed-forwardnaturalnetworksisshowninFigure\n",
            "1.3. As we can see ...\n",
            "/n\n",
            "Doc ID: a3c8f3ea-8fa9-4dcc-8aa6-5c9c49448430\n",
            "Text: CHAPTER 1. INTRODUCTION H1 H2 Hm Hm+1 = R(X)H0 = X Figure 1.3:\n",
            "Feed-forward Neural Networks. jointly with the parameter\u0012 of the score\n",
            "functionS(R(X)) by solving Equation 1.4 over the training dataD.\n",
            "Eventually, it helps to capture the underlying rep- resentation of\n",
            "data via optimization, potentially introducing useful features for the\n",
            "classifica...\n",
            "/n\n",
            "Doc ID: 527b0593-ad3e-4213-9138-5745d7b63bd2\n",
            "Text: CHAPTER 1. INTRODUCTION searching for a local minima often\n",
            "provides a practically good solution. Regarding the computation\n",
            "expense, the development ofGraphics Processing Units (GPU) allows us\n",
            "to complete the operations in representation learning (deep learning)\n",
            "much faster via the use of massively parallel graphics processors.\n",
            "This has signifi- ...\n",
            "/n\n",
            "Doc ID: 52f9b4b5-489e-4079-8d1e-9a3de4bfe23b\n",
            "Text: CHAPTER 1. INTRODUCTION The parameterϵ is calledthe learning\n",
            "rate that determines the amount or the step we move in each update\n",
            "step. In SDG,ϵ is fixed during the training process and often chosen\n",
            "via some development dataset8. In practice, fixing the learning rate\n",
            "might not work very well as it might slow down the convergence of SGD\n",
            "(i.e, long ...\n",
            "/n\n",
            "Doc ID: bc70c972-b50e-4157-9408-2ddad1f5340d\n",
            "Text: CHAPTER 1. INTRODUCTION deep learning, a more common method to\n",
            "overcome overfitting isdropout that ran- domly drops (i.e, sets to\n",
            "zero) units along with their connections in the network architecture\n",
            "during training. The key idea is to prevent the co-adaptation among\n",
            "the units (Srivastava et al.,2014). Formally, consider the hidden\n",
            "vector Hi in t...\n",
            "/n\n",
            "Doc ID: 06874fee-0f07-47fa-9a96-d0d7fbb14b44\n",
            "Text: CHAPTER 1. INTRODUCTION engineering approach in this section and\n",
            "leave the related work on representation learning for discussion in\n",
            "the later chapters. Information extraction is an active area of\n",
            "research in natural language pro- cessing in the last decades. A large\n",
            "portion of the previous research effort has been spent on developing\n",
            "effective ...\n",
            "/n\n",
            "Doc ID: f57bf5b1-7115-439c-903b-3bcf1b01c4f6\n",
            "Text: CHAPTER 1. INTRODUCTION 2011; McClosky et al.,2011; Patwardhan\n",
            "and Rilof,2009), entity linking (Bunescu and Pasca,2006; Cassidy et\n",
            "al.,2011; Ji and Grishman,2011; Mendes et al.,2011; Milne and\n",
            "Witten,2008; Shen et al.,2014b; Zheng et al.,2010) or coreference res-\n",
            "olution (Clark and Manning,2016; Durrett and Klein,2013; Raghunathan\n",
            "et al., 2010; ...\n",
            "/n\n",
            "Doc ID: 2071dab7-3adf-414f-b775-162b915558bf\n",
            "Text: CHAPTER 1. INTRODUCTION assumption does not hold sometime in\n",
            "reality as the training data for some tasks and domains might be very\n",
            "expensive and difficult to obtain. How can we relax this assumption so\n",
            "we can build good models for IE without requiring much train- ing\n",
            "data? This is the key target of semi-supervised learning that employs\n",
            "large amo...\n",
            "/n\n",
            "Doc ID: 8942d723-d31f-4cf2-a848-6c02eae40d70\n",
            "Text: CHAPTER 1. INTRODUCTION guide the learning process. The goal of\n",
            "active learning is to minimize the number of requests from users so an\n",
            "effective IE system can be built quickly without much annotation\n",
            "effort (Becker et al.,2005; Fu and Grishman,2013; Sun and Grishman,\n",
            "2012). Semi-supervised learning, distant supervision and unsupervised\n",
            "learning ...\n",
            "/n\n",
            "Doc ID: 3afaeb22-d3aa-48c8-9488-1939cf18f374\n",
            "Text: Chapter 2 W ord Embeddings for Domain Adaptation of Relation\n",
            "Extraction The previous research on supervised learning has mainly\n",
            "approached relation extraction (RE) in two directions: (Boschee et\n",
            "al.,2005; Chan and Roth,2010; Grishman et al.,2005; Jiang and\n",
            "Zhai,2007a; Kambhatla,2004; Sun et al.,2011; Zhou et al.,2005) and\n",
            "kernel-based (Bunescu a...\n",
            "/n\n",
            "Doc ID: 13fe8daf-4513-44a4-86d6-4c58ff2dd3b0\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION techniques (DA) to adapt a model trained on one domain (the\n",
            "source domain) into a new model which can perform well on new domains\n",
            "(the target domains). To make it clear, we assume the same relation\n",
            "classes (types), thus the same extraction task in both source and\n",
            "target doma...\n",
            "/n\n",
            "Doc ID: 1e67e646-3c06-4d37-bcb3-6c2254d68541\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION and Moschitti,2013 who find that the out-of-domain\n",
            "performance of kernel-based relation extractors can be improved by\n",
            "embedding semantic similarity information generated from word\n",
            "clustering and latent semantic analysis (LSA) into syntactic tree\n",
            "kernels. Although this idea i...\n",
            "/n\n",
            "Doc ID: 96800778-7325-4feb-adc2-352cb8b260bb\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION different, word representations would mitigate the lexical\n",
            "sparsity by providing general features of words that are shared across\n",
            "domains, hence bridge the gap between domains. The underlying\n",
            "hypothesis here is that the absence of lexical target-domain features\n",
            "in the source...\n",
            "/n\n",
            "Doc ID: f8de5fa6-b666-4d4e-a8d6-3536ee3d786d\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION good generalization performance is the one that not only\n",
            "fits the training data, but also avoids ovefitting over it. This is\n",
            "often obtained via regularization methods to penalize complexity of\n",
            "classifiers. Exploiting the shared interest in generaliza- tion\n",
            "performance with t...\n",
            "/n\n",
            "Doc ID: 97faa1e0-cf94-487e-81bc-a222b6f091ab\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION up the regularization parameter is to impose the same\n",
            "regularization parameter on every feature rather than a skewed\n",
            "regularization (Jiang and Zhai,2007c). 2.1.2 W ord Representations\n",
            "Word representations are high-dimensional vectors that are associated\n",
            "with words in an unla...\n",
            "/n\n",
            "Doc ID: ee18f703-9805-4115-b7b6-c81c8d67027b\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION (Plank and Moschitti, 2013). This issue becomes more\n",
            "serious in our setting of single-system DA where we have a single\n",
            "source domain with multiple dissimilar target domains and an automatic\n",
            "system able to recognize entity and mention types very well in\n",
            "different domains may ...\n",
            "/n\n",
            "Doc ID: 70c77f44-7b13-4019-998a-d7ae30861d84\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION rank of importance. For each of these group combinations,\n",
            "we assess the system performance with different numbers of dimensions\n",
            "for both C&W and HLBL word embeddings. Let M1 and M2 be the first and\n",
            "second entity mentions in the relation mention. Table2.1 describes the\n",
            "lexica...\n",
            "/n\n",
            "Doc ID: 42bccc35-8507-4e19-9152-8d825f4652fb\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION and unbiased resources generated from the previous works\n",
            "for evaluation not only helps to verify the effectiveness of the\n",
            "resources across different tasks and settings but also supports our\n",
            "setting of single-system DA. We use the ACE 2005 corpus for DA\n",
            "experiments (as in (Pl...\n",
            "/n\n",
            "Doc ID: 8b44208a-2238-4441-b341-5ba0be8f27bf\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION In-domain (bn+nw) Out-of-domain (bc development set)System \n",
            "C&W,25C&W,50C&W,100HLBL,50HLBL,100C&W,25C&W,50C&W,100HLBL,50HLBL,1001B\n",
            "aseline 51.4 51.4 51.4 51.4 51.4 49.0 49.0 49.0 49.0 49.021+HM_ED54.0(\n",
            "+2.6)54.1(+2.7)55.7(+4.3)53.7(+2.3)55.2(+3.8)51.5(+2.5)52.7(+3.7)52.5(\n",
            "+3.5)5...\n",
            "/n\n",
            "Doc ID: 17275cf2-a14c-4c06-b335-4ad872719f6d\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION the incremental addition of features (rows 6, 7, 8), C&W is\n",
            "better for the out- of-domain performance when 50 dimensions are used,\n",
            "whereas HLBL (with both 50 and 100 dimensions) is more effective for\n",
            "the in-domain setting. For the next experiments, we will apply the C&W\n",
            "embe...\n",
            "/n\n",
            "Doc ID: 99f94c63-1308-41a5-9a2c-3d60c7cdbda0\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION (i): The baseline system achieves a performance of 51.4%\n",
            "within its own domain while the performance on target domainsbc, cts,\n",
            "wl drops to 49.7%, 41.5% and 36.6% respectively. Our baseline\n",
            "performance is worse than that of (Plank and Moschitti, 2013) only on\n",
            "the target domai...\n",
            "/n\n",
            "Doc ID: 01186591-128f-485d-9c3f-ab94196de399\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION that word embeddings provide for word clusters is modest.\n",
            "This is because the RCV1 corpus used to induce the word embeddings\n",
            "(Turian et al.,2010) does not cover spoken language words incts very\n",
            "well. (v): Finally, the in-domain performance is also improved\n",
            "consistently demon...\n",
            "/n\n",
            "Doc ID: d94959f7-c96a-4ebb-8f95-6df81cdbaee5\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION nificantly better than the corresponding cell in Table2.3\n",
            "(5% or better gain in F measure, a significant improvement at\n",
            "confidence level\u001595%). This demonstrates the effectiveness of\n",
            "regularization for RE in general and for domain adaptation of RE\n",
            "specifically. 2.2 The Kernel...\n",
            "/n\n",
            "Doc ID: 8075a169-4968-47df-b81e-872332718342\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION extractors across domains, the application of word\n",
            "embeddings (Bengio et al.,2003; Mnih and Hinton,2008; Turian et\n",
            "al.,2010) for DA of RE is only examined in the feature-based method\n",
            "and never explored in the tree kernel-based method so far, giving rise\n",
            "to the first question...\n",
            "/n\n",
            "Doc ID: 83930cbb-fcc0-44d2-a3e9-e9c40a114cd0\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION rather different resources and settings in their\n",
            "evaluation, making it impossible to directly compare their\n",
            "performance. In particular, while Plank and Moschitti, 2013 only use\n",
            "the path-enclosed trees induced from the constituent parse trees as\n",
            "the representation for relatio...\n",
            "/n\n",
            "Doc ID: 97a44c28-914a-46e8-92af-7a8216a9b323\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION 2.2.1 Relation Extraction Approaches In the following, we\n",
            "review and compare the two relation extraction systems with greater\n",
            "details to facilitate the later discussion. 2.2.1.1 T ree kernel-based\n",
            "Method In the tree kernel-based method (Moschitti,2006, 2008; Plank\n",
            "and Moschi...\n",
            "/n\n",
            "Doc ID: 66a12a18-802e-40e3-9f42-66f47c50a4a7\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION utilized to activate the SSTK: (i) replace the part-of-\n",
            "speech nodes in the PET trees by the new ones labeled by the word\n",
            "clusters of the corresponding terminals (words); (ii) replace the\n",
            "binary similarity scores between words (i.e, either 1 or 0) by the\n",
            "similarities induced ...\n",
            "/n\n",
            "Doc ID: 2cf9d642-e86b-415d-8e55-42c0c5e2461f\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION address this problem for the feature-based method in DA of\n",
            "RE by introducing word embeddings as additional features. The\n",
            "rationale is based on the fact that word embeddings are low\n",
            "dimensional and real valued vectors, capturing latent syntactic and\n",
            "semantic properties of wor...\n",
            "/n\n",
            "Doc ID: ce056215-0fe2-4e2e-9740-89c977ca8257\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION this work (denoted by FET) includes: the lexical features,\n",
            "i.e., the context words, the head words, the bigrams, the number of\n",
            "words, the lexical path, the order of mention (Sun et al.,2011; Zhou\n",
            "et al.,2005); and the syntactic features, i.e., the path connecting\n",
            "the two men...\n",
            "/n\n",
            "Doc ID: cef06f0b-1aac-49c6-853f-eeca0e8b4587\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION class. For instance, the two fragments “T om is the CEO of\n",
            "the company ” and “the company, headed by T om” express the same\n",
            "relationship between “T om” and “company” based on the semantics of\n",
            "their context words, but cannot be matched in SSTK as their syntactic\n",
            "structures ar...\n",
            "/n\n",
            "Doc ID: 3cc1daeb-67c5-438f-9a86-4d083932988e\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION (TREEi;VECTi). The new kernel function in this case is then\n",
            "defined by: Knew(RELi;RELj) = (1 \u0000 )SSTK(TREEi;TREEj) +\n",
            "Kvec(VECTi;VECTj) (2.1) where Kvec(VECTi;VECTj) is some standard\n",
            "vector kernel like the polynomial kernels.   is a trade-off parameter\n",
            "and indicates whether t...\n",
            "/n\n",
            "Doc ID: 93fe9e54-5c07-4d26-bf47-2ecb7fa95b55\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION semantics. TREE: This is motivated by the training of\n",
            "recursive neural networks (Socher et al.,2012a) for semantic\n",
            "compositionality and attempts to aggregate the context words\n",
            "embeddings syntactically. In particular, we compute an embedding for\n",
            "every node in the PET tree in ...\n",
            "/n\n",
            "Doc ID: f4b610d5-23ba-4400-836d-f79981369c53\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION 2014a). In order to make the comparisons compatible, we\n",
            "introduce word em- beddings into the tree kernel by extending the\n",
            "package provided by (Plank and Moschitti, 2013), which uses the\n",
            "Charniak parser to obtain the constituent trees, the SVM-light-TK for\n",
            "the SSTK kernel in ...\n",
            "/n\n",
            "Doc ID: a5dbba16-79a3-4d1e-b634-5a11ff3e6ae3\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION Method P R F1 PET (Plank and Moschitti,2013) 52.2 41.7 46.4\n",
            "PET+SIM 39.4 37.2 38.3 PET+HEAD 60.4 44.9 51.5 PET+PHRASE 58.4 40.7\n",
            "48.0 PET+TREE 59.8 42.2 49.5 PET+HEAD+PHRASE 63.2 46.2 53.4\n",
            "PET+HEAD+TREE 61.0 45.7 52.3 PET+PHRASE+TREE 59.2 42.4 49.4\n",
            "PET+HEAD+PHRASE+TREE 60.8 4...\n",
            "/n\n",
            "Doc ID: e4e3e293-ecdd-49cb-a8b3-e431ce5b3c12\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION 0 0:1 0:3 0:5 0:7 0:9 146 48 50 52   F-measure Figure 2.1:\n",
            "vs F-measure on PET+HEAD+PHRASE Figure 2.1 additionally shows the\n",
            "variation of the performance with changing  (for the best system on\n",
            "dev, i.e., for the representation PET+HEAD+PHRASE). As we can see, the\n",
            "performan...\n",
            "/n\n",
            "Doc ID: cb575851-1636-483d-9ee3-2870c0b0f4db\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION of these augmented systems in Table2.6 for the two\n",
            "scenarios: (i) in-domain: both training and testing are performed on\n",
            "the source domain via 5-fold cross validation and (ii) out-of-domain:\n",
            "models are trained on the source domain but evaluated on the three\n",
            "target domains. To...\n",
            "/n\n",
            "Doc ID: 7c95d018-eb90-4e41-ad33-8601f81d5f28\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION LSA are utilized or not, we consistently witness the\n",
            "performance improvement of the baselines when combined with word\n",
            "embedding (comparing systems X and X+WED where X is some baseline\n",
            "system). The best out-of-domain performance is achieved when word\n",
            "embeddings are employed i...\n",
            "/n\n",
            "Doc ID: fadb7cd6-b912-45a1-95e7-6d87683d2ace\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION Table2.7 presents the evaluation results on thebc\n",
            "development for the feature- based system where B is the baseline\n",
            "feature set consisting of FET and word clusters (WC) (Nguyen and\n",
            "Grishman,2014a). System P R F1 B 51.2 49.4 50.3 B+HEAD 55.8 52.4 54.0\n",
            "B+PHRASE 50.7 46.2 48.4 ...\n",
            "/n\n",
            "Doc ID: 9f0705e1-026c-4d2b-8bef-df57c18e3f49\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION where (HEAD) is also the best word level method employed in\n",
            "(Nguyen and Gr- ishman, 2014a). In order to enable a fairer and\n",
            "clearer evaluation, when doing comparison, we use both the three best\n",
            "embedding combinations in the feature- based method and the best\n",
            "embedding combin...\n",
            "/n\n",
            "Doc ID: d7cfadbc-fedc-4e5c-a52b-b00e8c23647e\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION in Section2.2.1.3. 2.2.4 Analysis This section analyzes the\n",
            "output of the systems to gain more insights into their operation. W\n",
            "ord Embeddings for the T ree-kernel based Method We focus on the\n",
            "comparison of the best model in (Plank and Moschitti,2013) (row 11 in\n",
            "Table2.6) (c...\n",
            "/n\n",
            "Doc ID: c03c731a-c117-4567-863b-ed3a4efc0f79\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION diers” and “herself ” in the sentence “The W ashington Post\n",
            "is reporting she shot several Iraqi soldiers before she was captured\n",
            "and she was shot herself , too.”. However, as the syntactical\n",
            "structure of X1 is more similar to X2’s, and is remarkably different\n",
            "from X3 as well...\n",
            "/n\n",
            "Doc ID: 345f4f35-3f24-4418-99d5-5929ee589f97\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION kernel function, consequently helping the tree kernel-based\n",
            "method work correctly in this case. 2.3 Related work Word embeddings\n",
            "are only applied to RE recently. Socher et al.,2012b use word\n",
            "embeddings as input for matrix-vector recursive neural networks in\n",
            "relation classifi...\n",
            "/n\n",
            "Doc ID: da9a749f-83f8-48fc-a3b4-21f1383f4730\n",
            "Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF RELATION\n",
            "EXTRACTION by (Plank and Moschitti,2013), instance weighting is not\n",
            "very useful for DA of RE. 2.4 Conclusion In order to improve the\n",
            "generalization (DA) for relation extractors, we propose several\n",
            "methods to incorporate word embeddings into the feature-based and the\n",
            "tree kernel-based a...\n",
            "/n\n",
            "Doc ID: 07ff7723-ad6d-498d-91ca-a6c1e1683284\n",
            "Text: Chapter 3 Deep Learning for Entity Mention Detection The\n",
            "previous chapter has introduced the application of word embeddings to\n",
            "improve the robustness of relation extractors. In the rest of this\n",
            "dissertation, we will totally focus on developing deep learning models\n",
            "for IE tasks. We start by the entity mention detection task in this\n",
            "chapter and de...\n",
            "/n\n",
            "Doc ID: 05764c0d-b1dd-40e8-b6cc-76a0f08549d9\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION (i) The\n",
            "first problem is the performance loss of the mention detectors when\n",
            "they are trained on some domain (the source domain) and applied to\n",
            "other domains (the target domains). The problem might originate from\n",
            "various mismatches between\n",
            "thesourceandthetargetdomains(domainshifts)suchasthevoc...\n",
            "/n\n",
            "Doc ID: 59af677f-ac11-49aa-9f6e-60c18e26a1fc\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION can\n",
            "alleviate the lexical sparsity, induce more general feature\n",
            "representation, thus generalizing well across domains (Nguyen and\n",
            "Grishman,2015b). This also helps RNNs to quickly and effectively adapt\n",
            "to new languages which just require word embeddings as the only new\n",
            "knowledge we need to obt...\n",
            "/n\n",
            "Doc ID: 25729dcb-603e-4937-95f7-e162795414a3\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION 3.1 Models\n",
            "We formalize the mention detection problem as a sequential labeling\n",
            "task. Given a sentenceW = [ w1;w2;:::;w n], where wi is the i-th word\n",
            "and n is the length of the sentence, we want to predict the label\n",
            "sequenceY = [ y1;y2;:::;y n] for X, where yi is the label for wi. The\n",
            "labels y...\n",
            "/n\n",
            "Doc ID: c4a7cc64-7387-4fee-9d29-e735135f65a0\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION Given the\n",
            "new input representation, we describe the RNNs to be investigated in\n",
            "this work below. 3.1.1 The Basic Models In standard recurrent neural\n",
            "networks, at each time step (word position in sentence) i, we have\n",
            "three main vectors: the input vectorxi 2RmI , the hidden vector hi 2\n",
            "RmH and t...\n",
            "/n\n",
            "Doc ID: 442bd5d3-d68d-43d4-8695-f45debd1401b\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION from the\n",
            "previous stepshi\u00001. The rationale for this topology is to introduce\n",
            "the label from the preceding step as a feature for current prediction:\n",
            "hi = \b( Uxi + Voi\u00001) (3.3) In the formula above,\b is the sigmoid\n",
            "activation function:\b(t) = 1 1+e\u0000t and O, U, andV are the same weight\n",
            "matrices f...\n",
            "/n\n",
            "Doc ID: 382d6ad0-5e0e-4f52-beb7-0b2550629c02\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION In this\n",
            "work, we use a variant of LSTM, called theGated Recurrent Units (GRUs)\n",
            "by (Cho et al.,2014a). GRU is shown to be simpler than LSTM in terms\n",
            "of computation and implementation but still achieves comparable\n",
            "performance (Józefowicz et al.,2015). The introduction of GRUs into\n",
            "the models EL...\n",
            "/n\n",
            "Doc ID: 33153e92-e7cf-4453-954c-e7cb4dff75ff\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION hi = zi\n",
            "⊙^oi + (1 \u0000zi) ⊙ti\u00001 ti\u00001 = Toi\u00001 ^oi = \b( Woxi + Uo(ri ⊙ti\u00001)) zi =\n",
            "\b( Wzxi + Uzti\u00001) ri = \b( Wrxi + Urti\u00001) (3.5) where T 2RmH\u0002mO . 3.1.3\n",
            "The Bidirectional Networks One of the limitations of the four basic\n",
            "models presented above is their inca- pacity to incorporate the future\n",
            "contex...\n",
            "/n\n",
            "Doc ID: fd3e67a0-137e-47d9-a511-74de275cdf18\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION The\n",
            "bidirectional networks involve three passes over the sentence, in\n",
            "which the first two passes are designated to encode the sentence while\n",
            "the third pass is responsible for decoding. The procedure for the\n",
            "sentenceX = [ x1;x2;:::;x n] is below: (i) Run the first RNN\u0000\u0000\u0000!RNN\n",
            "from left to right...\n",
            "/n\n",
            "Doc ID: 23fd4080-c353-4412-bcb5-29bc6ce4b1c1\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION i).\n",
            "Consequently, the concatenated vectorhi = [ \u0000 !hi; \u0000hi] constitutes a\n",
            "distributed representation that is specific to the word at positioni\n",
            "but still encapsulates the context information over the whole sentence\n",
            "at the same time. This effectively provides the networks a much richer\n",
            "represen...\n",
            "/n\n",
            "Doc ID: 66dcc0d3-0085-44a3-adb5-03636ee466cf\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION h1 h2 h3\n",
            "hn\u00001 hn o0 o1 o2 o3 on\u00001 on x1 x2 x3 xn\u00001 xn l0 l1 l2 l3 ln\u00001 ln\n",
            "rn+1rnrn\u00001r3r2r1 h1 h2 h3 hn\u00001 hn o1 o2 o3 on\u00001 on x1 x2 x3 xn\u00001 xn l0\n",
            "l1 l2 l3 ln\u00001 ln rn+1rnrn\u00001r3r2r1  1  2  3  n\u00001  n  1  2  3  n\u00001  n\n",
            "Figure 3.2: The bidirectional models. The model on the right is\n",
            "from(Mesnil et a...\n",
            "/n\n",
            "Doc ID: 7e127df5-ac0d-4c84-a16c-572578fd07f8\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION running\n",
            "the networks over the whole sentences and takingargmax over the output\n",
            "sequence: yi = argmax( oi): (3.7) 3.2 W ord Representation Following\n",
            "(Collobert et al.,2011), we pre-train word embeddings from a large\n",
            "corpus and employ them to initialize the word representations in the\n",
            "models. O...\n",
            "/n\n",
            "Doc ID: 9fdd3b05-c765-45ec-818d-f6b2e70a9382\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION words,\n",
            "thereby being more flexible than CBOW that applies a single weight for\n",
            "all the context words. CBOW, Skip-gram and C-CBOW are illustrated in\n",
            "Figure3.3. wt\u00002 wt\u00001 wt+1 wt+2 wt SUM INPUTPROJECTIONOUTPUT wt\u00002 wt\u00001\n",
            "wt+1 wt+2 wt INPUTPROJECTIONOUTPUT wt\u00002 wt\u00001 wt+1 wt+2 wt\n",
            "INPUTPROJECTIONOUT...\n",
            "/n\n",
            "Doc ID: ef62a1c8-9144-4212-9e62-30070f184c43\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION Domain\n",
            "#Docs #Sents #Mentions news 332 6487 22460 bc 60 3720 9336 cts 39 5900\n",
            "9924 wl 119 2447 6538 un 49 2746 6507 Total 599 21300 54765 Table\n",
            "3.1:ACE 2005 Dataset Regarding the robustness across languages, we\n",
            "further evaluate the RNN mod- els on the CoNLL 2002 dataset for Dutch\n",
            "Named Entity...\n",
            "/n\n",
            "Doc ID: 72f7167e-8f78-4349-9b75-d1c4824b35dd\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION tional\n",
            "Language Technologies) (6 billion tokens) while the entire Dutch\n",
            "Wikipedia pages (310 million tokens) are extracted to train the Dutch\n",
            "word embeddings. We utilize theword2vec toolkit6 (modified to add the\n",
            "C-CBOW model) to learn the word representations. Following (Baroni et\n",
            "al.,2014), ...\n",
            "/n\n",
            "Doc ID: fd2400c2-9c7e-4086-8caa-cdfd94b0de02\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION Rd Re\n",
            "ELMAN ELMAN_GRU ELMAN 80.99 81.42 JORDAN 81.14 81.68 ELMAN_GRU 80.53\n",
            "81.16 JORDAN_GRU 80.98 82.37 Rd Re JORDAN JORDAN_GRU ELMAN 79.12 79.64\n",
            "JORDAN 79.21 80.85 ELMAN_GRU 79.80 80.41 JORDAN_GRU 79.76 81.02 Table\n",
            "3.3:The bidirectional models’ performance -Elman vs Jordan: In the\n",
            "encoding p...\n",
            "/n\n",
            "Doc ID: 4ca7b726-20f5-4d11-9ccf-c423766f8470\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION 3.3.4\n",
            "Comparison to other Bidirectional RNN W ork Mesnil et al.,2013 also\n",
            "present a RNN system with bidirectional modeling for the slot filling\n",
            "task. As described in Section3.1.3, the major difference between the\n",
            "bidirectional models in this work and (Mesnil et al.,2013)’s is the\n",
            "recurrence i...\n",
            "/n\n",
            "Doc ID: c77c997b-cc48-4458-9dc8-ae11644b04d0\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION of the\n",
            "BASIC and BIDIRECT models on the development set (trained onnews) when\n",
            "the CBOW, SKIP-GRAM and C-CBOW techniques are utilized to obtain word\n",
            "embeddings from the same English corpus. We also report the\n",
            "performance of the models when they are initialized with theword2vec\n",
            "word embeddings ...\n",
            "/n\n",
            "Doc ID: ac365f47-db09-4b98-9805-e5a834845bbf\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION skip-gram\n",
            "model on a much larger corpus). Finally, we achieve the best perfor-\n",
            "mance when we apply the C-CBOW technique in the BIDIRECT model. From\n",
            "now on, for consistency, we use the C-CBOW word embeddings in all the\n",
            "remaining experiments in this chapter. 3.3.6 Cross-Domain Experiments\n",
            "This ...\n",
            "/n\n",
            "Doc ID: 15c11e0f-7808-430a-b863-e33eac04941b\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION for MD is\n",
            "another important dimension, however, out of the scope of the current\n",
            "work. We note that the performance of the MEMM system reported in this\n",
            "work is obtained from the actual system in (Florian et al.,2006) and\n",
            "the feature set of the MEMM8 system also includes the four features we\n",
            "ar...\n",
            "/n\n",
            "Doc ID: 4f1d811d-6ec7-4eb0-b7a1-37e2dd75edaf\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION MEMM\n",
            "BIDIRECT BIDIRECT-MEMM bc cts wl un bc cts wl un bc cts wl un bc 75.20\n",
            "86.60 70.25 72.38 75.49 87.51 70.75 73.04 0.29 0.91† 0.50† 0.66† cts\n",
            "66.91 89.76 68.74 69.72 68.23 91.24 68.82 70.27 1.32† 1.48† 0.08 0.55†\n",
            "wl 74.94 86.53 77.07 75.90 74.73 86.79 76.35 75.37 -0.21 0.26 -0.72\n",
            "-0.53 un ...\n",
            "/n\n",
            "Doc ID: 81ca9dba-49aa-4fa9-a261-b40d6355d54d\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION are able\n",
            "improve the state-of-the-art performance for Dutch. Very recently,\n",
            "while we are preparing this work, (Gillick et al.,2015) introduce a\n",
            "multilingual language processing system based on bytes and also report\n",
            "the performance on this dataset. Table3.8 compares the systems. System\n",
            "P R F1 ...\n",
            "/n\n",
            "Doc ID: 16d23a03-bd1e-46e2-9698-9b4e9fa0d135\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION 3.4\n",
            "Related W ork Both named entity recognition (Ando and Zhang, 2005;\n",
            "Bikel et al., 1997; Borthwick et al.,1997; Cherry and Guo,2015;\n",
            "Florian et al.,2003; Lin and Wu, 2009; Miller et al.,2004; Passos et\n",
            "al.,2014; Ratinov and Roth,2009; Ritter et al., 2011; Sang and\n",
            "Meulder,2003; Suzuki and I...\n",
            "/n\n",
            "Doc ID: 9055db8c-55e0-4772-a603-c7393efac205\n",
            "Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION 3.5\n",
            "Conclusion We systematically investigate various RNNs to solve the MD\n",
            "problem which suggests that bidirectional modeling is a very helpful\n",
            "mechanism for this task. In particular, the bidirectional model\n",
            "outperforms a very strong baseline of the feature-based exponential\n",
            "models in the cros...\n",
            "/n\n",
            "Doc ID: 8afd767b-8adb-4e49-8d77-845fd3c6c72b\n",
            "Text: Chapter 4 Deep Learning for Relation Extraction\n",
            "Thischapterpresentsseveraldeeplearningmodelsforrelationextraction.\n",
            "There are two major parts in this chapter. The first part introduces a\n",
            "convolutional neu- ral network that do not require feature engineering\n",
            "for relation extraction while the second part aims at the other\n",
            "extreme, exploring the com...\n",
            "/n\n",
            "Doc ID: 4eaf4fba-e1b3-4d00-a7bd-bcd45cf3312d\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.1\n",
            "Convolutional Neural Networks for Relation Extraction The relation\n",
            "extraction (RE) task can be divided into two steps: detecting if a\n",
            "relation mention corresponding to some entity mention pair of interest\n",
            "represents some relation and classifying the detected relation\n",
            "mentions into some predefi...\n",
            "/n\n",
            "Doc ID: ab72e920-a9fc-4dd1-89e9-09f7b5bbaf26\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION loss when they\n",
            "are applied to out-of-domain data (Blitzer et al.,2006; Daume, 2007;\n",
            "McClosky et al., 2010), causing the collapse of the RE systems based\n",
            "on them. In this section, we target an independent RE system that both\n",
            "avoids com- plicated feature engineering and minimizes the reliance on\n",
            "the...\n",
            "/n\n",
            "Doc ID: ad7f0dcd-4208-4471-8dad-033cf9576981\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION parsing (Yih et\n",
            "al., 2014), search query retrieval (Shen et al.,2014a), sentence\n",
            "modeling and classification (Kalchbrenner et al.,2014; Kim,2014), name\n",
            "tagging and semantic role labeling (Collobert et al.,2011). For\n",
            "relation classification and extraction, there are two prior works on\n",
            "CNNs for rela...\n",
            "/n\n",
            "Doc ID: e59c7e93-5a10-4a08-aa76-a2b3bb76f286\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION tation as do\n",
            "(Liu et al.,2013) and (Zeng et al.,2014), our model (adapted for RC\n",
            "where entity heads are given) avoids usage of manual linguistic\n",
            "resources and supervised NLP toolkits constructed externally,\n",
            "utilizing word embeddings that can be trained automatically in an\n",
            "unsupervised framework as...\n",
            "/n\n",
            "Doc ID: 772b2b34-43ce-4d65-8662-be30da3a54ee\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION In the morning,\n",
            "the <e1>President</e1> traveled to <e2>Detroit</e2>  in the morning,\n",
            "the president traveled to detroit entity 1 entity 2 input sentence\n",
            "with marked entities word embedding matrix position embeddings matrix\n",
            "table look-up       Convolutional layer  with multiple window sizes\n",
            "...\n",
            "/n\n",
            "Doc ID: f607e791-77de-4d90-8ac4-d3a11034617f\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION relation\n",
            "mention where wi is the i-th word in the mention. Also, let wi1 and\n",
            "wi2 be the two heads of the two entity mentions of interest. Before\n",
            "entering the network, each wordwi is first transformed into a\n",
            "vectorembi by looking up the word embedding tableEMB that can be\n",
            "initialized either by a ra...\n",
            "/n\n",
            "Doc ID: c0b5cc7a-a773-478f-abb7-bd836ae4ce13\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION k, a filter is\n",
            "seen as a weight matrixf = [ f1;f2;:::; fk] (fi is a column vector of\n",
            "size me + 2 md). The core of this layer is obtained from the\n",
            "application of the convolutional operator on the two matricesX and f\n",
            "to produce a score sequence s = [ s1;s2;:::;s n\u0000k+1]: si = g( k\u00001∑ j=0\n",
            "f⊤ j+1x⊤ j+i...\n",
            "/n\n",
            "Doc ID: 28e33df9-6553-4a79-9ddd-b9e64ebb8086\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION important or\n",
            "relevant features from the score sequence. Concretely, for each\n",
            "filterf, its score sequences is passed through themax function to\n",
            "produce a single number: pk f = max fsg= max fs1;s2;:::s n\u0000w+1gwhich\n",
            "can be interpreted as estimating the possibility some augmentedk-gram\n",
            "of the hidden cl...\n",
            "/n\n",
            "Doc ID: cc13fd97-5418-4b81-a507-88eaebea747b\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.1.2\n",
            "Experiments 4.1.2.1 Hyperparameters and Resources For all the\n",
            "experiments below, we use:tanh for the non-linear function, 150\n",
            "filters for each window size in the model and position embedding\n",
            "vectors with dimensionality of md = 50 4. Regarding the other\n",
            "parameters, we use the same values as d...\n",
            "/n\n",
            "Doc ID: b2931f12-6c6d-476e-ac53-decdb5d133e1\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION corresponding\n",
            "relation class for this entity pair. There are 9 ordered relationships\n",
            "(with two directions) and an undirectedOther class, resulting in 19\n",
            "classes. A pair is counted as correct if the order of the entities in\n",
            "the relationship is correct. For the ACE 2005 dataset, documents are\n",
            "annota...\n",
            "/n\n",
            "Doc ID: b8aebc89-da13-40c5-bd33-1ff5b11d92d3\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION ACE 2005\n",
            "(87,512) SemEval 2010 (10,717) Relation % Relation % ORG-AFF 2.8\n",
            "Cause-Effect 12.4 PER-SOC 1.2 Component-Whole 11.7 ART 1.0 Entity-\n",
            "Destination 10.6 PART-WHOLE 1.4 Entity-Origin 9.1 GEN-AFF 1.1 Product-\n",
            "Producer 8.8 PHYS 2.1 Member-Collection 8.6 Other 90.4 Message-Topic\n",
            "8.4 Content-Contain...\n",
            "/n\n",
            "Doc ID: b73b61c4-cfa0-46c5-911e-e93586d74634\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION nonstatic.rand\n",
            "static.word2vec nonstatic.word2vec # window sizes P R F P R F P R F 1\n",
            "2 69.56 41.64 52.04 74.66 41.03 52.90 72.74 49.49 58.87 2 3 68.47\n",
            "42.73 52.57 74.19 42.16 53.73 72.50 50.75 59.66 3 4 68.17 43.39 52.94\n",
            "73.60 41.90 53.35 72.56 49.81 58.97 4 5 66.83 43.46 52.55 73.52 42.60\n",
            "53.89 7...\n",
            "/n\n",
            "Doc ID: 52f03da8-3713-41c1-9bd3-a702b45c5337\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION setting which\n",
            "is in turn followed by thenonstatic.rand model. This suggests the\n",
            "undeniable benefits of initializing the word embeddings by some\n",
            "“universal” pre- trained values and updating the embeddings to reflex\n",
            "RE specific embeddings when training the models (Collobert et\n",
            "al.,2011; Kim,2014). F...\n",
            "/n\n",
            "Doc ID: 4321ee84-b57d-460c-b384-c93bfc03d39a\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION the MaxEnt\n",
            "framework with L2 regularization in the Mallet toolkit8 to train these\n",
            "feature-based models (as (Jiang and Zhai,2007a; Nguyen and\n",
            "Grishman,2014a; Sun et al.,2011)). Table4.3 shows the performance of\n",
            "the three baseline systems and our proposed CNN via 5-fold cross\n",
            "validation on the ACE 2...\n",
            "/n\n",
            "Doc ID: b9cdc7ba-50f7-4dc8-9e8d-f82f5ef7ee9e\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION come at the\n",
            "expense of elaborate feature engineering as well as much more expen-\n",
            "sive feature extraction. In particular, the feature extractors of\n",
            "these feature-based systems require: (i) the perfect entity and\n",
            "mention type information hand-labeled laboriously by human annotators;\n",
            "(ii) the extensi...\n",
            "/n\n",
            "Doc ID: 8a9c1fa2-4b10-48e3-b240-fdea7d3dbee6\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION as well as the\n",
            "more recent systems based on convolutional neural networks (Zeng et\n",
            "al.,2014) (O-CNN), recursive neural networks (RNN), matrix-vector\n",
            "recursive neural networks (MVRNN) (Socher et al.,2012b) or log-\n",
            "quadratic factor-based compositional embedding model (FCM) (Yu et\n",
            "al.,2014)10. As we c...\n",
            "/n\n",
            "Doc ID: 956b46f9-0293-47cc-85d1-c910395da395\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION Classifier\n",
            "Feature Sets F SVM POS, WordNet, morpho- logical features, thesauri,\n",
            "Google k-grams 77.6 MaxEnt POS, WordNet, morpho- logical features,\n",
            "noun compound system, the- sauri, Googlek-grams 77.6 SVM POS, WordNet,\n",
            "prefixes and other morphological features, dependency parse, Levin\n",
            "classes, Prop...\n",
            "/n\n",
            "Doc ID: e42ac928-0c4f-4f9e-94c2-bb94ac8fab2b\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 0 0:5 1 1:5 2\n",
            "2:5 3 50 60 70 80 1 + log 10( #positive #negative) F-measure W ords W\n",
            "ords-HM-W ed Our CNN Figure 4.2: F measures vs positive/negative\n",
            "ratios and see how the system performance responds to this variation.\n",
            "Figure4.2 shows the curves. This is a 5-fold cross validation\n",
            "experiment and al...\n",
            "/n\n",
            "Doc ID: 907de055-5bf7-492d-9d79-6cd277fa2dc1\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION advantages. 4.2\n",
            "Combining Neural Networks and Log-linear Models to Improve Relation\n",
            "Extraction Aswehavediscussed in Chapter 2, the feature-based method\n",
            "forRE extensively leveraged linguistic analysis and knowledge\n",
            "resources to construct the feature repre- sentations, involving the\n",
            "combination ofdi...\n",
            "/n\n",
            "Doc ID: 38bf3d86-6034-4b1a-91cb-04c27af659e5\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION (RNN) for RE is\n",
            "that the former aim to generalize the short and consecutive con- text\n",
            "(i.e, thek-grams) of the relation mentions (Lei et al.,2015; Nguyen\n",
            "and Grish- man, 2015a) while the latter adaptively accumulate the\n",
            "context information in the whole sentence via the memory units,\n",
            "thereby encodi...\n",
            "/n\n",
            "Doc ID: 932fa3dd-e1ea-4cb5-b2a0-b461c23f0d43\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.2.1 Models\n",
            "Relation mentions consist of sentences marked with two entity mentions\n",
            "of interest. In this section, we examine two different representations\n",
            "for the sentences in RE: (i) the standard representation, called SEQ\n",
            "that takes all the words in the sentences into account and (ii) the\n",
            "depend...\n",
            "/n\n",
            "Doc ID: deec3bb6-c331-443a-b1ec-ba7dbb22037a\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION - The real-\n",
            "valued embedding vectors for entity typesenti and chunkschunki to\n",
            "embed the entity type and chunking information forwi. These vectors\n",
            "are gener- ated by looking up the entity type and chunk embedding\n",
            "tables (also initialized ran- domly) (i.e,ENT and CHUNK respectively)\n",
            "for the entity ty...\n",
            "/n\n",
            "Doc ID: 3de5d684-8f6e-4740-83ec-8aad9babd45f\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION f is a weight\n",
            "matrixf = [ f1;f2;:::; fk] where fi is a vector to be learnt during\n",
            "training as the model parameters. The core of CNNs is the application\n",
            "of the convolutional operator on the input matrixX and the filter\n",
            "matrixf to produce a score sequence (also called the hidden vector)s =\n",
            "[ s1;s2;:...\n",
            "/n\n",
            "Doc ID: 25ecac5a-e63c-4c68-bd3f-9d45f4db351f\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION sequence\n",
            "\u0000\u0000\u0000RNN([xn;xn\u00001;:::;x 1]) = [  \u0000hn; \u0000\u0000hn\u00001;:::;  \u0000h1]13, and (iii) the\n",
            "bidirectional mechanism that performs RNNs in both directions to\n",
            "produce the forward and backward hidden vector sequences, and then\n",
            "concatenate them at each position to generate the new hidden vector\n",
            "sequence [h1;h2;:...\n",
            "/n\n",
            "Doc ID: 3b35ae81-a587-4fdf-9654-186ec10438fc\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION we also use\n",
            "Gated Recurrent Units (Cho et al., 2014a) (GRU) to alleviate this\n",
            "problem (as in Section3.1.2). 4.2.1.2 The Combined Models We first\n",
            "present three different methods to assemble CNNs and RNNs: ensem-\n",
            "bling, stacking and voting, to be investigated in this work. The\n",
            "combination of the neu...\n",
            "/n\n",
            "Doc ID: 53c005fe-1c28-4fd6-bb9e-ee471a6e1e8c\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION variant, as the\n",
            "length of the hidden vectors = [ s1;s2;:::;s n\u0000k+1] in the CNN model\n",
            "depends on the specified window sizek for the corresponding feature\n",
            "map f, we need to pad the input matrixX with ⌊k 2 ⌋zero column vectors\n",
            "on both sides to ensure the same fixed lengthn for all the hidden\n",
            "vectors:...\n",
            "/n\n",
            "Doc ID: f26a1b45-0632-444a-92b8-475b3f56b986\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION models and the\n",
            "log-linear model. Let us take the ensembling model in Section 4.2.1.2\n",
            "as an example. The corresponding hybrid model in this case would be:\n",
            "Phybrid(yjX) = 1 ZPC(yjX)PR(yjX)Plogin(yjX), assumingPlogin(yjX) is\n",
            "the distribu- tion of the log-linear model andZis the normalization\n",
            "constant...\n",
            "/n\n",
            "Doc ID: d8f77fe6-7a71-41b6-8eac-d57965993cf4\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.2.2.1 T\n",
            "raining We train the models by minimizing the negative log-likelihood\n",
            "function us- ing the stochastic gradient descent algorithm with\n",
            "shuffled mini-batches and the AdaDeltaupdaterule(Zeiler, 2012).\n",
            "Thegradientsarecomputedviaback-propagation\n",
            "whileregularizationisexecutedbyadropoutonthehid...\n",
            "/n\n",
            "Doc ID: 59879f26-85ce-48f1-9e32-7fc24d51669c\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.2.3.2 Dataset\n",
            "We evaluate our models on two datasets: the ACE 2005 dataset for\n",
            "relation ex- traction and the SemEval-2010 Task 8 dataset (Hendrickx\n",
            "et al.,2010) for relation classification. The ACE 2005 corpus comes\n",
            "with 6 different domains: broadcast conversation (bc), broadcast\n",
            "news(bn), telep...\n",
            "/n\n",
            "Doc ID: 30495406-4bdd-465f-bbd7-f955ebf1c585\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION (inherited from\n",
            "(Socher et al.,2012b) and encoded by the real-valued vectors for each\n",
            "word). The other settings are also adopted from the past studies\n",
            "(Socher et al.,2012b; Xu et al.,2015). 4.2.3.3 RNN Architectures This\n",
            "section evaluates the performance of various RNN architectures for RE\n",
            "on the ...\n",
            "/n\n",
            "Doc ID: 213da236-21a0-4b2f-b368-8523ea18415f\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION (i) Assuming\n",
            "the same choices for the other three corresponding factors, GRU is\n",
            "more effective than FF, SEQ is better than DEP most of the time, and\n",
            "HEAD outperforms MAX (except in the case where SEQ and GRU are\n",
            "applied) for RE with RNNs. Note that the outperformance of SEQ over\n",
            "DEP can be partly ...\n",
            "/n\n",
            "Doc ID: 052473d1-f81f-4cea-b237-cb2d0c5b59ed\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION els\n",
            "corresponding to theRNN-CNN variant are FORWARD-CNN, BACKWARD- CNN,\n",
            "BIDIRECT-CNN while the three combined models corresponding to the CNN-\n",
            "RNN variant are CNN-FORWARD, CNN-BACKWARD, CNN-BIDIRECT. The notations\n",
            "for the other methods are self-explained. The model performance on the\n",
            "development se...\n",
            "/n\n",
            "Doc ID: a5494902-31f4-4dcd-968f-e03a2ed1e384\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION in this\n",
            "framework is to assemble the CNN model and the FORWARD model. In fact,\n",
            "the combination of the CNN and FORWARD models helps to improve the\n",
            "performance of the separate models in both variants of this method\n",
            "(referring to the models CNN-FORWARD and FORWARD-CNN). Finally, the\n",
            "voting method is ...\n",
            "/n\n",
            "Doc ID: 1782b830-526e-4f45-8019-a2a61e4a9b13\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION Model Neural\n",
            "Networks Hybrid Models Hybrid-Voting Models P R F1 P R F1 P R F1 CNN\n",
            "68.35 59.16 63.42 66.44 64.51 65.46 69.07 63.70 66.27 BIDIRECT 69.16\n",
            "59.97 64.24 68.04 59.00 63.19 71.13 60.29 65.26 FORWARD 69.33 60.45\n",
            "64.59 66.11 63.86 64.96 72.69 61.26 66.49 BACKWARD 65.60 63.05 64.30\n",
            "66.03 62.0...\n",
            "/n\n",
            "Doc ID: 594bc1b2-dff4-46b0-904d-70ecdd6d28be\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION 4.2.3.6\n",
            "Comparing to the State of the art The state-of-the-art system on the\n",
            "ACE 2005 for the unseen domains has been the feature-rich\n",
            "compositional embedding model (FCM) and the hybrid FCM model from\n",
            "(Gormley et al., 2015). In this section, we compare the proposed\n",
            "hybrid-voting systems with these...\n",
            "/n\n",
            "Doc ID: e7c31514-389d-4ed7-8ae4-df9b632b9c8e\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION all domains (up\n",
            "to 2% improvement on the average absolute F score),yielding the state-\n",
            "of-the-art performance for the unseen domains in this dataset .\n",
            "4.2.3.7 Relation Classification Experiments We further evaluate the\n",
            "proposed systems for the relation classification task on the SemEval\n",
            "dataset. Ta...\n",
            "/n\n",
            "Doc ID: e1b451bc-9ac6-4502-8c21-2723ae388401\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION Classifier F\n",
            "SVM (Hendrickx et al.,2010) 82.2 RNN (Socher et al.,2012b) 77.6 MVRNN\n",
            "(Socher et al.,2012b) 82.4 CNN (Zeng et al.,2014) 82.7 CR-CNN (Santos\n",
            "et al.,2015a) 84.1† FCM (Gormley et al.,2015) 83.0 Hybrid FCM (Gormley\n",
            "et al.,2015) 83.4 DepNN (Liu et al.,2015) 83.6 SDP-LSTM (Xu et\n",
            "al.,2015) 8...\n",
            "/n\n",
            "Doc ID: 0ece3fcb-a600-45ec-b72c-87552658aefc\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION relations. A\n",
            "closer investigation reveals two facts: (i) the PHYS relation mentions\n",
            "that are only correctly predicted by BIDIRECT involve long distances\n",
            "between two entity mentions, such as the PHYS relation between “Some”\n",
            "(a person entity) and “desert” (a location entity) in the following\n",
            "sentenc...\n",
            "/n\n",
            "Doc ID: b2437893-b86b-4e31-b61c-c9c0c1a71416\n",
            "Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION recursive NNs\n",
            "that recur over the tree structures while (Xu et al.,2015) investi-\n",
            "gate recurrent NNs. Regarding CNNs, (Zeng et al.,2014) examine CNNs\n",
            "via the sequential representation of sentences, (Santos et al.,2015a)\n",
            "explore a ranking loss function with data cleaning while (Zeng et\n",
            "al.,2015) pr...\n",
            "/n\n",
            "Doc ID: 9c967b3c-3e2f-47d3-8388-cadec8827294\n",
            "Text: Chapter 5 Deep Learning for Event Detection This chapter focuses\n",
            "on the problem of event detection (ED) or trigger predic- tion, i.e,\n",
            "identifying instances of specified types of events in text. Associated\n",
            "with each event mention is a phrase, the event trigger (most often a\n",
            "single verb or nom- inalization), which evokes that event. Our task,\n",
            "more...\n",
            "/n\n",
            "Doc ID: 714344c1-37eb-418e-b138-a069740417b1\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION crucial component\n",
            "in the overall task of event extraction, which also involves event\n",
            "argument discovery. In order to develop deep learning models for event\n",
            "detection, we first show that a customization of the CNN architecture\n",
            "in Section4.1 can produce a highly effective model with less\n",
            "requirement for...\n",
            "/n\n",
            "Doc ID: 457f5438-3cd8-4dad-8abf-24b90914f29e\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION tional neural\n",
            "networks (CNN) to automatically learn features from sentences, and to\n",
            "minimize the dependence on supervised toolkits and resources for\n",
            "features. The CNN models in this section are very similar to those of\n",
            "Section4.1, but we need to customize them to capture the special\n",
            "structures for ED....\n",
            "/n\n",
            "Doc ID: b013c09d-37e8-4dca-87af-677f8fb6dc41\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION fixed window size\n",
            "by trimming longer sentences and padding shorter sentences with a\n",
            "special token when necessary. Let2n+ 1 be the fixed window size, and W\n",
            "= [ w0;w1;:::;w n;:::;w 2n\u00001;w2n] be some trigger candidate where the\n",
            "current token is positioned in the middle of the window (tokenwn).\n",
            "Before ent...\n",
            "/n\n",
            "Doc ID: 2c3ad66c-46cb-407c-920e-b5ac2b73630c\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION of size d\u0002(2n+ 1)\n",
            "(d is the dimensionality of the concatenated vectors of the tokens).\n",
            "The matrix representationxis then passed through a convolution layer,\n",
            "a max pooling layer and a softmax at the end to perform classification\n",
            "(as in Section4.1). In the convolution layer, we have a set of feature\n",
            "map...\n",
            "/n\n",
            "Doc ID: f049a42c-2ff1-4754-8b75-de20c90c9151\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION update rule\n",
            "(Zeiler,2012). During the training, we also optimize the weights of\n",
            "the three embedding tables at the same time to reach an effective\n",
            "state. 5.1.2 Experiments 5.1.2.1 Dataset, Hyperparameters and\n",
            "Resources As the benefit of multiple window sizes in the convolution\n",
            "layer has been demon- str...\n",
            "/n\n",
            "Doc ID: 1843c279-b515-4516-a037-5060c9695970\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION problem. In order\n",
            "to evaluate the effectiveness of the position embeddings and the\n",
            "entity type embeddings, Table5.1 reports the performance of the\n",
            "proposed CNN on the development set when these embeddings are either\n",
            "included or excluded from the systems. With the large margins of\n",
            "performance, it is ve...\n",
            "/n\n",
            "Doc ID: 96016a63-2b30-4183-bc82-04b88d886e5b\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION test set. Table 5.2\n",
            "presents the overall performance of the systems with gold- standard\n",
            "entity mention and type information4. Methods P R F Sentence-level in\n",
            "(Hong et al.,2011) 67.6 53.5 59.7 MaxEnt with local features in (Li et\n",
            "al.,2013b) 74.5 59.1 65.9 Jointbeamsearchwithlocalfeaturesin(Lietal.,\n",
            "201...\n",
            "/n\n",
            "Doc ID: 17c8ad88-aed2-4757-af69-c5727f660f69\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION Except for CNN1,\n",
            "all the systems reported in Table 5.2 employ the gold- standard\n",
            "(perfect) entities mentions and types from manual annotation which\n",
            "might not be available in reality. Table5.3 compares the performance\n",
            "of CNN1 and the feature-based systems in a more realistic setting,\n",
            "where entity menti...\n",
            "/n\n",
            "Doc ID: 2df7039a-2961-4eff-9046-aa00928c72c4\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION a significant\n",
            "performance loss when trained on the source domain and applied to the\n",
            "target domains. We refer the reader to Chapters 1 and 2 to know more\n",
            "about the domain adaptation setting. To make it clear, we address the\n",
            "unsupervised DA problem in this section, i.e no training data in the\n",
            "target dom...\n",
            "/n\n",
            "Doc ID: 7484b315-bc88-4ba0-b2d0-90d6b1640575\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION System In-\n",
            "domain(bn+nw)bc cts wlP R F P R F P R F P R F MaxEnt 74.5 59.466.0\n",
            "70.1 54.561.3 66.4 49.956.9 59.4 34.943.9 Joint beam search in (Li et\n",
            "al.,2013b)Joint+Local 73.5 62.767.7 70.3 57.263.1 64.9 50.857.0 59.5\n",
            "38.446.7 Joint+Local+Global 72.9 63.267.7 68.8 57.562.6 64.5 52.357.7\n",
            "56.4 38.545.7 CN...\n",
            "/n\n",
            "Doc ID: f9a6b072-2bb8-415b-9cdf-7a0b64382ad6\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION 5.2 Non-consecutive\n",
            "Convolutional Neural Networks for Event Detection The prior CNN models\n",
            "for ED are characterized by the temporal convolution operators that\n",
            "linearly map the vectors for thek-grams in the sentences into the\n",
            "feature space. Such k-gram vectors are obtained by concatenating the\n",
            "vectors ...\n",
            "/n\n",
            "Doc ID: 3290f216-17a6-40fd-a4e4-ababbe0811b7\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION gation over all the\n",
            "possible non-consecutivek-grams is made efficient with dynamic\n",
            "programming. Notethatourworkisrelatedto(Leietal.,\n",
            "2015)whoemploythenon-consecutive convolution for the sentence and news\n",
            "classification problems. Our work is different from Lei et al.,2015 in\n",
            "that we model the relative ...\n",
            "/n\n",
            "Doc ID: 84a161fd-a7c3-4ee5-82d4-3a0212169abc\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION vectors X = (\n",
            "x0;x1;:::;x 2n) that will be used as input in the following CNN\n",
            "models. 5.2.1.1 The T raditional CNN Giventhe windowsize k,\n",
            "thetraditional CNN models (as in the previous section 5.1) for ED\n",
            "consider the following set of2n+ 1 consecutive k-gram vectors: C = fui\n",
            ": 0 \u0014i\u00142ng (5.2) Vectorui i...\n",
            "/n\n",
            "Doc ID: 79cad7da-5b93-455c-b211-ca92a202c5d6\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION Afterward, pk f is\n",
            "often transformed by a non-linear functiong7 to generate the\n",
            "transformed scoreg(pk f ), functioning as the extracted feature for\n",
            "the initial trigger candidate W. We can then repeat this process for\n",
            "different window sizesk and filtersf, gen- erating multiple\n",
            "featuresg(pk f ) to captu...\n",
            "/n\n",
            "Doc ID: c1dc9aac-d169-4b52-8613-571ada432248\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION N instead of C. In\n",
            "particular, the convolution score set in this case would be S(N) =\n",
            "ffTv: v2Ng, while the aggregating score would be: pk f = max S(N) =\n",
            "max fs: s2S(N)g (5.6) 5.2.1.3 Implementation Note that the maximum\n",
            "operation in Equation5.5 only requires O(n) opera- tions while the\n",
            "naive implemen...\n",
            "/n\n",
            "Doc ID: 90ef862c-f3a6-4950-9fc6-b96ab5a16a1d\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION We can solve this\n",
            "DP problem by the following recursive formulas8: Dj t = max fDj\n",
            "t\u00001;Dj\u00001 t\u00001 + fT j xtg (5.9) The computation time for this procedure\n",
            "isO(kn) and remains linear in the sequence length. 5.2.1.4 T raining\n",
            "We train the networks using stochastic gradient descent with shuffled\n",
            "mini- batch...\n",
            "/n\n",
            "Doc ID: 00d12e0e-3e4a-4134-a61f-9ce113e4f46f\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION (MaxEnt); the\n",
            "structured perceptron model for joint beam search with local fea-\n",
            "tures (Joint+Local), and with both local and global features in (Li et\n",
            "al.,2013b) (Joint+Local+Global); and the sentence-level and cross-\n",
            "entity models in (Hong et al., 2011). 2) The neural network models,\n",
            "i.e, the CNN mode...\n",
            "/n\n",
            "Doc ID: 804cea38-49fb-4e69-8628-fc04a21ef3e0\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION the state-of-the-\n",
            "art system that only relies on the context information within the\n",
            "sentences of the trigger candidates. In addition, althoughNC-CNN only\n",
            "employs the sentence-level information, it is still better than the\n",
            "other models that further exploit the document-level information for\n",
            "prediction (...\n",
            "/n\n",
            "Doc ID: e07c40b6-b33e-4bf2-b815-e5f28aa780ee\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION We notice that the\n",
            "performance of the systemsMaxEnt, Joint+Local, B-RNN, CNN and\n",
            "Joint+Local+Global is obtained from the actual systems in the original\n",
            "work (Li et al.,2013b; Nguyen and Grishman,2015b; Nguyen et\n",
            "al.,2016a). The performance ofDM-CNN, on the other hand, is from our\n",
            "re-implementation of ...\n",
            "/n\n",
            "Doc ID: ff136d53-7122-40ec-9c00-4f1d038ecc60\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION as the cross-\n",
            "sentence or cross-event information (Gupta and Ji,2009; Hong et al.,\n",
            "2011; Ji and Grishman,2008; Li et al.,2015; Liao and Grishman,2010a,\n",
            "2010b, 2011; McClosky et al.,2011; Patwardhan and Rilof,2009). Some\n",
            "recent work on the feature-based approach has also investigated event\n",
            "trigger detec...\n",
            "/n\n",
            "Doc ID: f8568d89-9ebc-4feb-9547-01f2db84e6b6\n",
            "Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION domains of the CNN.\n",
            "In addition, we extend such CNN architecture to employ non-consecutive\n",
            "convolutions, yielding the state-of-the-art performance for ED on both\n",
            "the general setting and the domain adaptation setting. 150\n",
            "/n\n",
            "Doc ID: be6240c4-9a50-4f85-9538-f7a92fdfd634\n",
            "Text: Chapter 6 Memory-augmented Networks for Joint Inference in\n",
            "Information Extraction We can view the tasks in the information\n",
            "extraction (IE) pipeline in Figure 1.2 as sequences of prediction\n",
            "tasks. For instance, for trigger prediction or event detection, a\n",
            "document can be seen as a sequence of words in which a prediction is\n",
            "performed for every wor...\n",
            "/n\n",
            "Doc ID: 61d2d779-a94a-4910-b849-c208756e11eb\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Given this view, the previous chapters and work\n",
            "on deep learning for informa- tion extraction have only concerned\n",
            "solving the predictions in the sequences for IE separately or\n",
            "independently. An illustration is given in Figure6.1. Figure 6.1: A\n",
            "sequence of predicti...\n",
            "/n\n",
            "Doc ID: c4b5e6c2-0c65-4ce7-8914-e148cd6f19f3\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION (type) Die and “fired” for the event type\n",
            "“Attack”. It is often simple to recognize the event type “Die” for\n",
            "“kil led” based on the word itself, but it is more challenging to\n",
            "identify the event type for “fired” as this word is more ambiguous\n",
            "(i.e, having multiple ...\n",
            "/n\n",
            "Doc ID: ed69c0b7-628d-4ebc-bf63-994569a5bf41\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Figure 6.2: Memory-augmented neural networks.\n",
            "step i is expected to memorize or summarize the outputs that we have\n",
            "made so far (i.e, from step 1 toi). 3. When we make a prediction for\n",
            "the step i+ 1 , we will use the memory from the previous step (i.e,\n",
            "stepi) in ad...\n",
            "/n\n",
            "Doc ID: cd7f4bc9-2bdb-420b-aac3-78f75409f93a\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION 6.2 Event Extraction with Memory-augmented\n",
            "Neural Networks 6.2.1 Event Extraction T ask We focus on the EE task\n",
            "of the Automatic Context Extraction (ACE) evalua- tion1. ACE defines\n",
            "an event as something that happens or leads to some change of state.\n",
            "We employ the ...\n",
            "/n\n",
            "Doc ID: edd1c8c5-7a27-438d-87af-81fb108f1543\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Given an English text document, an event\n",
            "extraction system needs to recognize event triggers with specific\n",
            "types and their corresponding arguments with the roles for each\n",
            "sentence. Following the previous work (Chen et al.,2015; Li et\n",
            "al.,2013b; Liao and Grishman,2...\n",
            "/n\n",
            "Doc ID: 67478d62-4aee-4a0f-a1b3-b78722b5ff51\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Figure 6.3: Prediction tasks for event\n",
            "extraction. for every word (i.e, from wordW1 to wordW5) in this\n",
            "sentence while the rectangles of the second and the third row\n",
            "correspond to the argument prediction tasks for the entity mentionsW2\n",
            "and W5 respectively. For inst...\n",
            "/n\n",
            "Doc ID: 02743d56-932d-4577-a032-be2ad5715485\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION causing the ignorance of long-range\n",
            "dependencies among the tasks. One of such interdependencies is the\n",
            "correlations among the event types within the same sen- tences that\n",
            "have been demonstrated at the beginning of this chapter. Another\n",
            "important interdependency in...\n",
            "/n\n",
            "Doc ID: b687bf12-6266-46cb-ad56-b700138e0009\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Figure 6.4: Memory-augmented neural networks\n",
            "for event extraction. the next predictions to capture the\n",
            "interdependencies. A detailed joint model for EE will be presented in\n",
            "the next section. Note that we often call the memory- augmented\n",
            "networks for EE as the join...\n",
            "/n\n",
            "Doc ID: 5883fa53-a313-48c4-95ec-c4c5c980b455\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION be the entity mentions3 in this sentence (k is\n",
            "the number of the entity mentions and can be zero). Each entity\n",
            "mention comes with the offsets of the head and the entity type. We\n",
            "further assume thati1;i2;:::;i k be the indexes of the last words of\n",
            "the mention heads...\n",
            "/n\n",
            "Doc ID: 3859b70b-b498-4e70-ab1d-9a0c386e84b3\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION a died when a tank fired in Baghdad Sentence\n",
            "Encoding Trigger Prediction Argument Role Prediction Memory\n",
            "Vectors/Matrices word embeddings entity type embeddings depdendecy\n",
            "tree relations input sentence indexes of trigger and entity mention\n",
            "candidates local argumen...\n",
            "/n\n",
            "Doc ID: e4c11b0f-cf6d-4e5f-b51b-085333a12aea\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION neural networks for EE (Chen et al.,2015;\n",
            "Nguyen and Grishman,2015b). The reason is we predict the whole\n",
            "sentences for triggers and argument roles jointly, thus having no\n",
            "fixed positions for anchoring in the sentences. The transformation\n",
            "from the tokenwi to the ve...\n",
            "/n\n",
            "Doc ID: eb9ac17c-6682-4390-9254-688269b9abc1\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION (from 1 ton) with a greater focus on positioni.\n",
            "Finally, we useGated Recurrent Units for the non-linear function \b to\n",
            "mitigate the vanishing gradient problem (Bengio et al.,1994; Cho et\n",
            "al.,2014a; Chung et al.,2014). 6.2.3.2 Prediction In order to jointly\n",
            "predict ...\n",
            "/n\n",
            "Doc ID: 93a65197-0063-426f-8ffa-67f80f7970e9\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Garg i and Garg/trg i for the current step.\n",
            "Note thatti should be the event type ifwi is a trigger word for some\n",
            "event of interest, or “Other” in the other cases.aij, in constrast,\n",
            "should be the argument role of the entity mentionej with respect towi\n",
            "if wi is a tr...\n",
            "/n\n",
            "Doc ID: a6d0047b-dec4-4f90-ae66-0b8862db0bbf\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION “Other” for allj = 1 to k and go to the next\n",
            "stage immediately. Otherwise, we loop over the entity\n",
            "mentionse1;e2;:::;e k. For each entity mentionej with the head index\n",
            "ofij, we predict the argument roleaij with respect to the trigger word\n",
            "wi using the following pr...\n",
            "/n\n",
            "Doc ID: fd541214-7222-44a1-a9a3-dfaca7a5cbe3\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION a) = Farg a (Rarg ij ) where a is an argument\n",
            "role. Eventually, the predicted argument role forwi and ej is aij =\n",
            "argmaxa(Parg ij;a). Note that the binary vector VECij enriches the\n",
            "feature representation Rarg ij for argument labeling with the discrete\n",
            "structures d...\n",
            "/n\n",
            "Doc ID: a11ba458-53cb-4dc0-8d9c-d00e6e0a4314\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION possible argument roles). At timei, Garg i\n",
            "summarizes the argument roles that the entity mentions has played with\n",
            "some event in the past. In particular,Garg i [j][a] = 1 if and only\n",
            "ifej has the role ofawith some event before timei. Garg i is computed\n",
            "from Garg i\u0000...\n",
            "/n\n",
            "Doc ID: 0bd3314c-0275-4757-8463-22a5afde4b23\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION where I is the indicator function. We apply the\n",
            "stochastic gradient descent algorithm with mini-batches and the\n",
            "AdaDelta update rule (Zeiler, 2012). The gradients are computed using\n",
            "back- propagation. During training, besides the weight matrices, we\n",
            "also optimize ...\n",
            "/n\n",
            "Doc ID: ec20f803-3dbe-43ab-90e0-cfca9a51cae8\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION units in the hidden layers for the RNNs.\n",
            "Regarding the prediction phase, we employ the context window of 2 for\n",
            "the local features, and the feed-forward neural networks with one\n",
            "hidden layer forFtrg, Farg and Fbinary (the size of the hidden layers\n",
            "are 600, 600 and ...\n",
            "/n\n",
            "Doc ID: 7f03e03a-3549-499a-bf5f-3bea7093d54d\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION 6.3.1.1 Memory V ector/Matrices This section\n",
            "evaluates the effectiveness of the memory vector and matrices\n",
            "presented in Section 6.2.3.2. In particular, we test the joint model\n",
            "on different cases where the memory vector for triggers Gtrg and the\n",
            "memory matrices for...\n",
            "/n\n",
            "Doc ID: ba53e4ae-e815-4cc9-8de4-df0baecc48ba\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION task. Finally, Garg/trg and Garg do not\n",
            "contribute much to the trigger labeling performance in general (except\n",
            "in the case where Gt, Garg/trg and Garg are all applied). These\n",
            "observations suggest that the dependencies among trigger types and\n",
            "among argument roles a...\n",
            "/n\n",
            "Doc ID: 2d76b712-a2ba-4793-b858-7f09a52f5438\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Word EmbeddingsTrigger Argument RANDOM 59.9\n",
            "50.1 SKIP-GRAM 66.7 57.1 CBOW 66.5 53.8 WORD2VEC 66.9 56.4 C-CBOW 68.0\n",
            "58.1 Table 6.2:Performance of the word embedding techniques. trained\n",
            "word embeddings for this purpose. Second, SKIP-GRAM, WORD2VEC and CBOW\n",
            "have comp...\n",
            "/n\n",
            "Doc ID: 2d63491c-8597-4c16-8236-a871b1f8cc2c\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION and various discrete local and global features\n",
            "by (Li et al.,2013b) (Li’s structure). Note that the pipelined system\n",
            "in (Chen et al.,2015) is also the best-reported system based on neural\n",
            "networks for EE. Table6.3 compares these state-of-the- art systems\n",
            "with the ...\n",
            "/n\n",
            "Doc ID: 8855264b-d8c5-43b4-b2a5-2c6757f96971\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION the joint model with RNNs and memory features\n",
            "in this work. In addition, as JRNN significantly outperforms the joint\n",
            "model with discrete features in (Li et al., 2013b) (an improvement of\n",
            "1.8% and 2.7% for trigger and argument role labeling respectively), we\n",
            "can co...\n",
            "/n\n",
            "Doc ID: aefe66f3-b961-4d94-9f1a-bd9be1f091f3\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Stage Model 1/1 1/N all Embedding+T 68.1 25.5\n",
            "59.8 Trigger CNN 72.5 43.1 66.3 DMCNN 74.3 50.9 69.1 JRNN 75.6 64.8\n",
            "69.3 Embedding+T 37.4 15.5 32.6 Argument CNN 51.6 36.6 48.9 DMCNN 54.6\n",
            "48.7 53.5 JRNN 50.0 55.2 55.4 Table 6.4:System performance on single\n",
            "event sent...\n",
            "/n\n",
            "Doc ID: aa834f5d-15ad-430a-b7ca-2463784315f4\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION we use the typical knowledge base of Wikipedia\n",
            "in this work, the problem becomes linking entity mentions in documents\n",
            "to their corresponding pages in Wikipedia. For instance, consider the\n",
            "following text: Chelsea have long-standing rivalries with North London\n",
            "clubs...\n",
            "/n\n",
            "Doc ID: 4bab93de-4f5b-4bfe-a334-5a54af5d61cd\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION entity mention (disambiguation). The previous\n",
            "deep learning models have only solved entity linking by independently\n",
            "disambiguating entity mentions in docu- ments (Francis-Landau et\n",
            "al.,2016) (the local approach for EL). Figure6.6 demon- strates the\n",
            "prediction task...\n",
            "/n\n",
            "Doc ID: 8bb01ce5-2a4b-4bed-8248-255e5b1bc240\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION to suggest an unique entity (i.e, “Liverpool”\n",
            "can be any any sport clubs in this sentence based on the phrase “cup\n",
            "competitions”). However, if we refer the the previous entity mentions\n",
            "(i.e, ‘Chelsea”, “North London”, “Arsenal”, “T ottenham Hotspur”, and\n",
            "“Leeds Un...\n",
            "/n\n",
            "Doc ID: 1f248a3c-fea7-4a97-86e2-da39f4a680b0\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION The experiment results show that the proposed\n",
            "model outperforms the current state-of-the-art models on the evaluated\n",
            "datasets. To our knowledge, this is also the first work investigating\n",
            "the EL problem in the domain adaptation setting. Figure 6.7: Memory-\n",
            "augmented...\n",
            "/n\n",
            "Doc ID: 5ab8fe40-e4fd-42a8-ade4-694c333b6b3d\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION of words to capture the contexts or topics\n",
            "ofenti at multiple granularities. For the target candidate\n",
            "pagespageij, we use thetitle til ij and body content bdy ij to\n",
            "represent them (pageij = ( tilij;bdyij)). For convenience, we also\n",
            "denotepage\u0003 i = (til\u0003 i;bdy\u0003 i) ...\n",
            "/n\n",
            "Doc ID: e7a7e855-3b6d-48ed-a457-6dc9fc3bcb84\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION entity mentionenti, and (iii) the global\n",
            "component that runs recurrent neural net- works on the entity\n",
            "mentionsfent1;ent2;:::; entkgto generate the global features\n",
            "ϕglobal(ent1;ent2;:::; enti;P1;P2;:::;P i). 6.4.2.1 Encoding Let W be\n",
            "some context word sequence of ...\n",
            "/n\n",
            "Doc ID: 99d2e24c-c240-461a-ae34-34e6e07bf728\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION concatenation vector of the given word vectors.\n",
            "For convenience, let\u0016sufi, \u0016ctxi, \u0016doci, \u0016tilij, \u0016bdyij, \u0016til \u0003 i and\n",
            "\u0016bdy \u0003 i be the distributed representations ofsufi, ctxi, doci, tilij,\n",
            "bdyij, til\u0003 i and bdy\u0003 i obtained by the convolu- tion procedure\n",
            "above, res...\n",
            "/n\n",
            "Doc ID: 33952feb-a86b-4e52-a8e4-9201570f5655\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION the representation vectors at multiple\n",
            "granularities ofenti and pageij. In particular: FCNN(enti;pageij) = [\n",
            "cos( \u0016sufi; \u0016tilij);cos( \u0016ctxi; \u0016tilij);cos( \u0016doci; \u0016tilij); cos(\n",
            "\u0016sufi; \u0016bdyij);cos( \u0016ctxi; \u0016bdyij);cos( \u0016doci; \u0016bdyij)] (6.5) The\n",
            "intuition for this comp...\n",
            "/n\n",
            "Doc ID: 4937e9a8-8ace-4bd5-b1ec-3005e6797394\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Each vectorhb i in this sequence encodes or\n",
            "summarizes the information about the content of the previous target\n",
            "entities (i.e, beforei) in the document due to the property of RNN.\n",
            "Given the hidden vector sequence, when predicting the target entity\n",
            "for the entity m...\n",
            "/n\n",
            "Doc ID: fcc45ed4-3fd3-4319-baba-3ac91bee904b\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Figure 6.8: Joint model for learning local and\n",
            "global features for a document with 3 entity mentions: “Chelsea”,\n",
            "“Arsenal” and “Liverpool”. Each of the entity mentions has two entity\n",
            "candidate pages (either a football club or a city).The orange\n",
            "rectangles denote t...\n",
            "/n\n",
            "Doc ID: 599fd290-6edb-49a6-99f3-dc4068917135\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION NIST. It is also used in (Fahrni and\n",
            "Strube,2014 and Durrett and Klein,2014). ii) CoNLL-YAGO (Hoffart et\n",
            "al., 2011): This corpus is originally from the CoNLL 2003 shared task\n",
            "of named entity recognition for English. iii) WP (Heath and\n",
            "Bizer,2011): This dataset con...\n",
            "/n\n",
            "Doc ID: 8774bdbf-833d-4804-83b0-6c19b75bbb68\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Regarding the input contexts for the entity\n",
            "mentions and the target candidates, we utilize the window size of 10\n",
            "for the immediate contextctxi, and only extract the first 100 words in\n",
            "the documents fordoci and bdyij. Finally, we pre-train the word\n",
            "embedings on the...\n",
            "/n\n",
            "Doc ID: 6e57f8c5-21fb-44d5-99de-5f365811ff69\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION ferent cases where the global-mention and\n",
            "global-entity features are included or excluded from the model. Global\n",
            "Features Dataset ACE CoNLL WP No 86.1 89.3 84.0 global-mention 86.8\n",
            "90.2 84.2 global-entity 86.9 90.7 84.2 global-mention + global-entity\n",
            "86.2 90.6 84....\n",
            "/n\n",
            "Doc ID: ec546cf5-4bec-47e7-9494-287cfd568854\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION in (Durrett and Klein,2014) and the AIDA-light\n",
            "system with two-stage mapping in (Nguyen et al.,2014c)10. Table 6.6\n",
            "shows the performance of the systems on the test sets with the\n",
            "reference knowledge base of the June 2016 Wikipedia dump. We also\n",
            "include the performa...\n",
            "/n\n",
            "Doc ID: 7833475c-5de6-4c1c-b42e-46e6528e87ca\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION 6.4.5 Domain Adaptation Experiments The purpose\n",
            "of this section is to further evaluate the models in the domain\n",
            "adaptation setting to investigate their cross-domain robustness for\n",
            "EL. We refer the reader to Chapters 1 and 2 to learn more about the\n",
            "domain adaptatio...\n",
            "/n\n",
            "Doc ID: bcaaf9a5-9b4e-446b-999e-1cc905bd7859\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Evaluation Table6.7 compares Global-RNN with\n",
            "the neural network EL model in (Francis- Landau et al.,2016), the best\n",
            "reported model on the ACE dataset in the litera- ture12. In this\n",
            "table, the models are trained on the source domain news, and evaluated\n",
            "onnews itsel...\n",
            "/n\n",
            "Doc ID: c04f18df-8e87-47bc-bc6c-72db609a4b0d\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Analysis In order to better understand the\n",
            "performance gap in the domain adaptation experiments for EL, we\n",
            "visualize the representation vectors of the entity mentions in\n",
            "different domains. In particular, afterGlobal-RNN is trained, we\n",
            "retrieve the representation v...\n",
            "/n\n",
            "Doc ID: 9197c805-15e2-434e-945d-a55dbc6cebc5\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION explaining the performance loss in the domain\n",
            "adaption experiments. It is not clear in Figure6.9 why the models\n",
            "perform much worse on the target domainswl andun\n",
            "thantheotherdomains(i.e, bc andcts). Wefurtherinvestigate this problem\n",
            "by computing the similarities be...\n",
            "/n\n",
            "Doc ID: eaf81e69-39ee-4ff9-a3c8-1e2b3a70fb07\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Domain context title interaction bc 10.7 2.0\n",
            "34.4 cts 11.4 2.0 32.6 wl 9.2 0.8 30.3 un 9.5 1.4 31.1 Table\n",
            "6.8:Similarities to the source domainnews. 6.5 Related W ork As the\n",
            "memory-augmented neural networks for information extraction are new,\n",
            "we only focus on the ...\n",
            "/n\n",
            "Doc ID: 63e27b23-f3ec-4c3d-923f-a9e423c518ec\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION Mutual Information measures (Ratinov et\n",
            "al.,2011), integer linear programming (Cheng and Roth,2013), PageRank\n",
            "(Alhelbawy and Gaizauskas,2014; Pershina et al.,2015), stacked\n",
            "generalization (He et al.,2013a), to name a few. The entity linking\n",
            "techniques and systems ...\n",
            "/n\n",
            "Doc ID: 811e31f6-d9ef-4a3a-addf-8050ccd55ed8\n",
            "Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT INFERENCE IN\n",
            "INFORMATION EXTRACTION formance for both tasks on the benchmark\n",
            "datasets. 196\n",
            "/n\n",
            "Doc ID: c2f8141c-820d-4b37-a025-b6ddf0fbbbb6\n",
            "Text: Chapter 7 Conclusion and F uture W ork This dissertation departs\n",
            "from the traditional feature-based methods and de- velops new deep\n",
            "learning models for information extraction tasks. The major motivation\n",
            "for such deep learning models are the ability to generalize over\n",
            "vocabu- lary (i.e, mitigate the unseen word/feature problems) and the\n",
            "automatic...\n",
            "/n\n",
            "Doc ID: e11fdfa6-ece7-46a9-8d9b-e23dc5fe4e38\n",
            "Text: CHAPTER 7. CONCLUSION AND FUTURE WORK memory-augmented neural\n",
            "networks maintain memories to capture the long range dependencies in\n",
            "information extraction tasks. We apply this general framework in two\n",
            "tasks of event extraction and entity linking, yielding the systems\n",
            "with sate-of- the-art performance for such tasks. We envision much\n",
            "future resear...\n",
            "/n\n",
            "Doc ID: 0e6dcec4-3bf7-4c78-85af-689167fd2599\n",
            "Text: CHAPTER 7. CONCLUSION AND FUTURE WORK The second direction\n",
            "considers the multitask deep learning frameworks for in- formation\n",
            "extraction. The main idea is to explore deep learning models that can\n",
            "simultaneously solve several information extraction tasks to improve\n",
            "the perfor- mance of the individual tasks (joint learning). Deep\n",
            "learning facilita...\n",
            "/n\n",
            "Doc ID: 30d9b8b1-a319-4e41-8366-3d7a08ff683d\n",
            "Text: Bibliography Agichtein, Eugene and Gravano, Luis (2000).\n",
            "“Snowball: Extracting Relations from Large Plain-Text Collections”.\n",
            "In:Proceedings of the Fifth ACM Conference on Digital Libraries. Ahn,\n",
            "David (2006). “The Stages of Event Extraction”. In:Proceedings of the\n",
            "W ork- shop on Annotating and Reasoning about Time and Events .\n",
            "Alhelbawy, Ayman a...\n",
            "/n\n",
            "Doc ID: b7712541-2255-48da-a208-56dca2f6e3b4\n",
            "Text: BIBLIOGRAPHY Baroni, Marco and Zamparelli, Roberto (2010).\n",
            "“Nouns are Vectors, Adjectives are Matrices: Representing Adjective-\n",
            "Noun Constructions in Semantic Space”. In: Proceedings of the\n",
            "Conference on Empirical Methods in Natural Language Processing\n",
            "(EMNLP). Baroni, Marco, Dinu, Georgiana, and Kruszewski, Germán\n",
            "(2014). “Don’t count, predict! ...\n",
            "/n\n",
            "Doc ID: 9eb6e3c2-43fb-4aaa-8a7e-2cc9a9f40cb6\n",
            "Text: BIBLIOGRAPHY Blacoe, W. and Lapata, M. (2012). “A Comparison of\n",
            "Vector-based Representa- tions for Semantic Composition”.\n",
            "In:Proceedings of the Conference on Empir- ical Methods in Natural\n",
            "Language Processing (EMNLP). Blitzer, John, McDonald, Ryan, and\n",
            "Pereira, Fernando (2006). “Domain Adapta- tion with Structural\n",
            "Correspondence Learning”. In:Pr...\n",
            "/n\n",
            "Doc ID: fbdff178-ad4e-4ab5-91d5-6fbdbb373a4b\n",
            "Text: BIBLIOGRAPHY Brown, P. F., deSouza, P. V., Mercer, R. L.,\n",
            "Pietra, V. J. D., and Lai, J. C. (1992). “Class-Based n-gram Models of\n",
            "Natural Language”. In:Computational Linguistics. Bunescu, Razvan and\n",
            "Mooney, Raymond (2005a). “A Shortest Path Dependency Kernel for\n",
            "Relation Extraction”. In:Proceedings of the Conference on Empirical\n",
            "Methods in Natura...\n",
            "/n\n",
            "Doc ID: 3a03e5a4-8526-409e-bac0-065a00bc2c5f\n",
            "Text: BIBLIOGRAPHY Chan, Yee Seng and Roth, Dan (2010). “Exploiting\n",
            "Background Knowledge for Relation Extraction”. In:Proceedings of the\n",
            "International Conference on Com- putational Linguistics (COLING) .\n",
            "Chen, Yubo, Xu, Liheng, Liu, Kang, Zeng, Daojian, and Zhao, Jun\n",
            "(2015). “Event Extraction via Dynamic Multi-Pooling Convolutional\n",
            "Neural Networks”. I...\n",
            "/n\n",
            "Doc ID: 7df28502-3d19-4ae4-9686-34edbedec0b1\n",
            "Text: BIBLIOGRAPHY Clark, Kevin and Manning, Christopher D. (2016).\n",
            "“Improving Coreference Reso- lution by Learning Entity-Level\n",
            "Distributed Representations”. In:Proceedings of the Annual Meeting of\n",
            "the Association for Computational Linguistics (ACL) . Collins, Michael\n",
            "and Singer, Yoram (1999). “Unsupervised Models for Named En- tity\n",
            "Classification”. ...\n",
            "/n\n",
            "Doc ID: 5e4ff401-2b34-470f-95e3-eb35688bff28\n",
            "Text: BIBLIOGRAPHY Daume, Hal, Kumar, A., and Saha, A. (2010). “Co-\n",
            "regularization Based Semi- supervised Domain Adaptation”.\n",
            "In:Proceedings of the Conference on Neural Information Processing\n",
            "Systems (NIPS). Duchi, John, Hazan, Elad, and Singer, Yoram (2011).\n",
            "“Adaptive Subgradient Meth- ods for Online Learning and Stochastic\n",
            "Optimization”. In:Journal o...\n",
            "/n\n",
            "Doc ID: 9beb2597-e5be-4c67-ab45-88180225145b\n",
            "Text: BIBLIOGRAPHY Florian, Radu, Pitrelli, John, Roukos, Salum, and\n",
            "Zitouni, Imed (2010). “Improv- ing Mention Detection Robustness to\n",
            "Noisy Input”. In:Proceedings of the Con- ference on Empirical Methods\n",
            "in Natural Language Processing (EMNLP) . Francis-Landau, Matthew,\n",
            "Durrett, Greg, and Klein, Dan (2016). “Capturing Se- mantic Similarity\n",
            "for Entity...\n",
            "/n\n",
            "Doc ID: 4cda3213-0d9b-464f-a967-936e5144de6b\n",
            "Text: BIBLIOGRAPHY Grishman, Ralph, Westbrook, David, and Meyers, Adam\n",
            "(2005). “NYU’s English ACE 2005 System Description”. In:The ACE 2005\n",
            "Evaluation W orkshop. Grishman, R. (2012). “Information Extraction:\n",
            "Capabilities and Challenges”. In: International Winter School in\n",
            "Language and Speech T echnologies, Rovira i Virgili University, Spain.\n",
            "Gupta, Pr...\n",
            "/n\n",
            "Doc ID: d02211a8-8f22-4cb4-b5d1-84f77470220f\n",
            "Text: BIBLIOGRAPHY Szpakowicz, Stan (2010). “SemEval-2010 Task 8:\n",
            "Multi-Way Classification of Semantic Relations Between Pairs of\n",
            "Nominals”. In:Proceedings of the Inter- national W orkshop on Semantic\n",
            "Evaluation (SemEval). Hochreiter, Sepp and Schmidhuber, Jurgen (1997).\n",
            "“Long Short-Term Memory”. In: Neural Computation.\n",
            "Hoffart,Johannes,Yosef,MohamedA...\n",
            "/n\n",
            "Doc ID: 06e14d49-98b5-4ec4-af35-c7e9defeceef\n",
            "Text: BIBLIOGRAPHY American Chapter of the Association for\n",
            "Computational Linguistics Conference (HL T-NAACL). Ji, Heng and\n",
            "Grishman, Ralph (2005). “Improving Name Tagging by Reference\n",
            "Resolution and Relation Detection”. In:Proceedings of the Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) . Ji,\n",
            "Heng, Westbrook, David, and Grishma...\n",
            "/n\n",
            "Doc ID: 2c2a399c-b1b5-41b3-9098-99b393dcbd23\n",
            "Text: BIBLIOGRAPHY Jiang, Jing and Zhai, ChengXiang (2007c). “A Two-\n",
            "stage Approach to Domain Adaptation for Statistical Classifiers”. In:\n",
            "Proceedings of the Conference on Information and Knowledge Management\n",
            "(CIKM) . Józefowicz, Rafal, Zaremba, Wojciech, and Sutskever, Ilya\n",
            "(2015). “An Empirical Exploration of Recurrent Network Architectures”.\n",
            "In:Proc...\n",
            "/n\n",
            "Doc ID: 5ee1eb38-f9a0-4284-a1b7-72c3d035362c\n",
            "Text: BIBLIOGRAPHY Kulkarni, Sayali, Singh, Amit, Ramakrishnan,\n",
            "Ganesh, and Chakrabarti, Soumen (2009). “Collective Annotation of\n",
            "Wikipedia Entities in Web Text”. In:Pro- ceedings of the Association\n",
            "for Computing Machinery’s (ACM) Special Interest Group (SIG) on\n",
            "Knowledge Discovery and Data Mining (SIGKDD) . Lafferty, John,\n",
            "McCallum, Andrew, and Perei...\n",
            "/n\n",
            "Doc ID: e58e4b39-d1d1-4fec-a8bc-2ebc8bcf41c3\n",
            "Text: BIBLIOGRAPHY Li, Qi, Ji, Heng, Hong, Yu, and Li, Sujian (2014b).\n",
            "“Constructing Information Net- works Using One Single Model”.\n",
            "In:Proceedings of the Conference on Empirical Methods in Natural\n",
            "Language Processing (EMNLP). Li, Xiang, Nguyen, Thien Huu, Cao, Kai,\n",
            "and Grishman, Ralph (2015). “Improving Event Detection with Abstract\n",
            "Meaning Represent...\n",
            "/n\n",
            "Doc ID: 7bab34c1-701f-48b8-9fed-d22fc2ce43c4\n",
            "Text: BIBLIOGRAPHY Proceedings of the Annual Meeting of the\n",
            "Association for Computational Lin- guistics (ACL). Liu, Shulin, Liu,\n",
            "Kang, He, Shizhu, and Zhao, Jun (2016). “A Probabilistic Soft Logic\n",
            "Based Approach to Exploiting Latent and Global Information in Event\n",
            "Classification”. In:Proceedings of the Association for the Advancement\n",
            "of Arti- ficial I...\n",
            "/n\n",
            "Doc ID: ca106acd-add9-4d2a-98e0-71cb172fbd08\n",
            "Text: BIBLIOGRAPHY Miller, Scott, Guinness, Jethran, and Zamanian,\n",
            "Alex (2004). “Name Tagging with Word Clusters and Discriminative\n",
            "Training”. In:Proceedings of the North American Chapter of the\n",
            "Association for Computational Linguistics Conference (HL T-NAACL).\n",
            "Milne, David and Witten, Ian H. (2008). “Learning to Link with\n",
            "Wikipedia”. In: Proceedings ...\n",
            "/n\n",
            "Doc ID: 1238501c-b3c7-43a7-ace6-a48c1126fe80\n",
            "Text: BIBLIOGRAPHY Moschitti, Alessandro (2006). “Efficient\n",
            "Convolution Kernels for Dependency and Constituent Syntactic Trees”.\n",
            "In:Proceedings of the European Conference on Machine Learning and\n",
            "Principles and Practice of Knowledge Discovery in Databases (ECML\n",
            "PKDD) . Moschitti, Alessandro (2008). “Kernel Methods, Syntax and\n",
            "Semantics for Rela- tional...\n",
            "/n\n",
            "Doc ID: 4a178b14-faa5-448f-8403-2b67e5de23f8\n",
            "Text: BIBLIOGRAPHY Nguyen, Thien Huu and Grishman, Ralph (2015a).\n",
            "“Relation Extraction: Perspec- tive from Convolutional Neural\n",
            "Networks”. In:The NAACL W orkshop on V ec- tor Space Modeling for NLP\n",
            "(VSM) . Nguyen, Thien Huu and Grishman, Ralph (2015b). “Event\n",
            "Detection and Domain Adaptation with Convolutional Neural Networks”.\n",
            "In:Proceedings of the An...\n",
            "/n\n",
            "Doc ID: 0685c495-43f8-48d2-bae6-5638cbf49b1b\n",
            "Text: BIBLIOGRAPHY Nguyen, Thien Huu and Grishman, Ralph (2016e).\n",
            "“Modeling Skip-Grams for Event Detection with Convolutional Neural\n",
            "Networks”. In:Proceedings of the Conference on Empirical Methods in\n",
            "Natural Language Processing (EMNLP) . Nguyen, Thien Huu, Fauceglia,\n",
            "Nicolas, Muro, Mariano Rodriguez, Hassanzadeh, Oktie, Gliozzo, Alfio\n",
            "Massimiliano, a...\n",
            "/n\n",
            "Doc ID: 660c7378-ce6b-424d-b09b-5e3a641853c4\n",
            "Text: BIBLIOGRAPHY Patwardhan, Siddharth and Rilof, Ellen (2009). “A\n",
            "Unified Model of Phrasal and Sentential Evidence for Information\n",
            "Extraction”. In:Proceedings of the Confer- ence on Empirical Methods\n",
            "in Natural Language Processing (EMNLP) . Pedersen, Ted (2008).\n",
            "“Empiricism is Not a Matter of Faith”. In:Computational Linguistics 3\n",
            ". Pershina, Maria...\n",
            "/n\n",
            "Doc ID: 4e603dec-8b86-456a-8ea8-d0b1511dd985\n",
            "Text: BIBLIOGRAPHY Raghunathan, Karthik, Lee, Heeyoung, Rangarajan,\n",
            "Sudarshan, Chambers, Nate, Surdeanu, Mihai, Jurafsky, Dan, and\n",
            "Manning, Christopher (2010). “A Multi- Pass Sieve for Coreference\n",
            "Resolution”. In:EMNLP. Ratinov, Lev and Roth, Dan (2009). “Design\n",
            "Challenges and Misconceptions in Named Entity Recognition”.\n",
            "In:Proceedings of the Conferen...\n",
            "/n\n",
            "Doc ID: 53a0808d-e8fe-4556-86b4-baf85a2fa39a\n",
            "Text: BIBLIOGRAPHY Roth, Dan and Yih, Wen-tau (2004). “A Linear\n",
            "Programming Formulation for Global Inference in Natural Language\n",
            "Tasks”. In:Proceedings of the Conference on Computational Natural\n",
            "Language Learning (CoNLL) . Roth, D. and Yih, W. (2007). “Global\n",
            "Inference for Entity and Relation Identifi- cation via a Linear\n",
            "Programming Formulation”. In:...\n",
            "/n\n",
            "Doc ID: bededaa3-4ee1-4c18-a8b9-d6f0fdf9911a\n",
            "Text: BIBLIOGRAPHY Shen, Wei, Wang, Jianyong, Luo, Ping, and Wang, Min\n",
            "(2012). “LINDEN: Linking Named Entities with Knowledge Base via\n",
            "Semantic Knowledge”. In:Proceedings of the International W orld Wide W\n",
            "eb Conference (WWW). Shen,Yelong,He,Xiaodong,Gao,Jianfeng,Deng,Li,andM\n",
            "esnil,Gregoire(2014a). “Learning Semantic Representations Using\n",
            "Convolutional...\n",
            "/n\n",
            "Doc ID: 4d7773c7-8cf0-4f64-af74-2d381196b9b5\n",
            "Text: BIBLIOGRAPHY Srivastava,N.,Hinton,G.,Krizhevsky,A.,andSalakhutdi\n",
            "nov,R.(2014).“Dropout: A Simple Way to Prevent Neural Networks from\n",
            "Overfitting”. In:Journal of Machine Learning Research 15(1):1929-1958.\n",
            "Sterckx, Lucas, Demeester, Thomas, Deleu, Johannes, and Develder,\n",
            "Chris (2014). “Using Active Learning and Semantic Clustering for Noise\n",
            "Reducti...\n",
            "/n\n",
            "Doc ID: 6e4e9968-2de4-47a4-9ec4-d7bffaa7c0d4\n",
            "Text: BIBLIOGRAPHY Suzuki, Jun and Isozaki, Hideki (2008). “Semi-\n",
            "Supervised Sequential Labeling and Segmentation Using Giga-Word Scale\n",
            "Unlabeled Data”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) . Turian, Joseph,\n",
            "Ratinov, Lev-Arie, and Bengio, Yoshua (2010). “Word Represen- tations:\n",
            "A Simple and General...\n",
            "/n\n",
            "Doc ID: 7743ef02-c932-4738-b412-6a6b0750c3dc\n",
            "Text: BIBLIOGRAPHY Xiao, Min and Guo, Yuhong (2013). “Domain\n",
            "Adaptation for Sequence Labeling Tasks with a Probabilistic Language\n",
            "Adaptation Model”. In:Proceedings of the International Conference on\n",
            "Machine Learning (ICML) . Xu, Yan, Mou, Lili, Li, Ge, Chen, Yunchuan,\n",
            "Peng, Hao, and Jin, Zhi (2015). “Classifying Relations via Long Short\n",
            "Term Memory Ne...\n",
            "/n\n",
            "Doc ID: 24eb4c90-7416-4960-8a65-e758acec3dc6\n",
            "Text: BIBLIOGRAPHY Memory Neural Networks”. In:Proceedings of the IEEE\n",
            "W orkshop on Spoken Lanuage T echnology. Yates, A. and Etzioni, O.\n",
            "(2007). “Unsupervised Resolution of Objects and Re- lations on the\n",
            "Web”. In:Proceedings of the North American Chapter of the Association\n",
            "for Computational Linguistics Conference (HL T-NAACL). Yih, Wen-tau,\n",
            "He, Xiaod...\n",
            "/n\n",
            "Doc ID: d3f427f9-6380-455b-b7a7-4ae7f9a767fc\n",
            "Text: BIBLIOGRAPHY Zeng, Daojian, Liu, Kang, Chen, Yubo, and Zhao, Jun\n",
            "(2015). “Distant Super- vision for Relation Extraction via Piecewise\n",
            "Convolutional Neural Networks”. In: Proceedings of the Conference on\n",
            "Empirical Methods in Natural Language Processing (EMNLP).\n",
            "Zhang,Min,Zhang,Jie,Su,Jian,andZhou,Guodong(2006).“ACompositeKernel to\n",
            "Extract Relatio...\n",
            "/n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chunks(text, chunk_size=512):\n",
        "    \"\"\"\n",
        "    Creates chunks of text with approximately chunk_size tokens using tiktoken.\n",
        "    \"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")  # Or your desired model\n",
        "    tokens = encoding.encode(text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_chunk_len = 0\n",
        "    for token in tokens:\n",
        "        current_chunk.append(token)\n",
        "        current_chunk_len += 1\n",
        "        if current_chunk_len >= chunk_size:\n",
        "            chunks.append(encoding.decode(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_chunk_len = 0\n",
        "    if current_chunk:  # Add any remaining tokens\n",
        "        chunks.append(encoding.decode(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "# Custom NodeParser to create chunks of desired size\n",
        "from llama_index.core.node_parser import NodeParser\n",
        "from llama_index.core.node_parser.node_utils import build_nodes_from_splits\n",
        "from pydantic import Field # Import Field for custom attribute\n",
        "from llama_index.core.schema import TextNode\n",
        "\n",
        "class CustomNodeParser(NodeParser):\n",
        "    chunk_size: int = Field(default=512, description=\"Chunk size in tokens\") # Define chunk_size with Field\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs) # Pass kwargs to superclass\n",
        "\n",
        "    def get_nodes_from_documents(self, documents):\n",
        "        \"\"\"\n",
        "        Creates nodes from documents, splitting text into chunks of desired size.\n",
        "        \"\"\"\n",
        "        nodes = []\n",
        "        for doc in documents:\n",
        "            chunks = create_chunks(doc.text, self.chunk_size)\n",
        "            # Fix: Use build_nodes_from_splits for proper node creation\n",
        "            # Instead of passing doc_id directly, set it after node creation\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                node = TextNode(text=chunk, id_=f\"{doc.id_}-{i}\")\n",
        "                nodes.append(node)\n",
        "        return nodes\n",
        "\n",
        "    # Implement the _parse_nodes method\n",
        "    def _parse_nodes(self, text):\n",
        "        \"\"\"This is a placeholder for custom parsing logic.\n",
        "        It will not split text by default.\"\"\"\n",
        "        return [text]\n",
        "\n",
        "# Create an instance of the custom NodeParser\n",
        "node_parser = CustomNodeParser(chunk_size=1024)\n",
        "\n",
        "# Create semantic chunks\n",
        "chunks = node_parser.get_nodes_from_documents(document)\n",
        "\n",
        "# Print the first few chunks (for demonstration)\n",
        "for i, chunk in enumerate(chunks[:10]):\n",
        "    print(f\"Chunk {i+1}:\\n{chunk.text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swwwDWysGRRr",
        "outputId": "a4e5c98b-2d05-4bf1-865b-a49c7f83103a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 1:\n",
            "DEEP LEARNING FOR INFORMATION EXTRACTION\n",
            "by\n",
            "Thien Huu Nguyen\n",
            "A dissertation submitted in partial fulfillment\n",
            "of the requirements for the degree of\n",
            "Doctor of Philosophy\n",
            "Department of Computer Science\n",
            "New York University\n",
            "May, 2017\n",
            "Professor Ralph Grishman\n",
            "\n",
            "Chunk 2:\n",
            "© Thien Huu Nguyen\n",
            "All Rights Reserved, 2017\n",
            "\n",
            "Chunk 3:\n",
            "Dedication\n",
            "To my beloved mother\n",
            "iii\n",
            "\n",
            "Chunk 4:\n",
            "Acknowledgments\n",
            "PeoplehavedifferentstoriestotellintheirPhDtime. MyPhDjourneybeganat\n",
            "a day of Fall 2012. I was supposed to meet my advisor, Professor Ralph Grishman,\n",
            "for the first time in his office. However, on my road to his office that day, I\n",
            "accidentally ran into him in the Broadway avenue. It was the first time I talked to\n",
            "Ralph in person after the many discussions via emails. The unexpected meeting\n",
            "with Ralph impressed me so much that I forgot my nerve and worry of the first\n",
            "days I entered United States to pursue a PhD degree. Ralph was so nice and\n",
            "approachable that I could immediately feel the trust and confidence, the values\n",
            "I have relied on throughout my PhD. The more I work with Ralph, the more\n",
            "fortunate I find myself. Ralph gave me the courage and freedom to explore deep\n",
            "learning for information extraction at the very early days of the field. He provided\n",
            "me with valuable advice and suggestion whenever I need to deal with research\n",
            "challenges and career decisions. It is his advice and enthusiasm that make me\n",
            "more determined to purse an academic career that I have always dreamed of. His\n",
            "responsibility on works and positive attitudes on research would be the principles\n",
            "I employ in the rest of my life. Ralph is the first and foremost person I would like\n",
            "to thank in my academic career.\n",
            "iv\n",
            "\n",
            "Chunk 5:\n",
            "ACKNOWLEDGMENTS\n",
            "I own special thanks to Professor Kyunghyun Cho, an outstanding advisor\n",
            "and a great friend who taught me much about deep learning and its potentials\n",
            "to transform our life. Kyunghyun has always been generous on spending his time\n",
            "discussing with me and providing me with great helps and encouragement. I also\n",
            "would like to thank the members of the Proteus project at New York University of\n",
            "which I am always proud to be a part. Dr. Adam Meyers gave me much insights\n",
            "into linguists. Yifan He and Lisheng Fu were always willing to discuss with me on\n",
            "new ideas. Xiang Li was a great listener who encouraged me whenever I have any\n",
            "problem in research and life. Masha Pershina had been a great collaborator on\n",
            "several projects. Kai Cao was always generous to share with me research resources.\n",
            "Bonan Min and Wei Xu were the great academic brother and sister who showed\n",
            "me great tips and advice. I have also learned much useful information from the\n",
            "discussion with Professor Satoshi Sekine and Dr. Angus Grieve-Smith.\n",
            "During my PhD, I was fortunate to have two outstanding internships with two\n",
            "different groups at IBM T.J. Watson Research Center. Some parts in this disser-\n",
            "tation were conducted during such internships. My first internship was associated\n",
            "with the group on Statistical Multilingual Information Extraction from Text where\n",
            "I had the opportunity to work with Dr. Radu Florian, Dr. Avirup Sil, Dr. Geor-\n",
            "giana Dinu, Dr. Salim Rukous, Dr. Vittorio Castelli and many other great people.\n",
            "I have obtained much research experience and received much support from that\n",
            "internship. I learned to implement my first recurrent neural networks there. I\n",
            "would like to especially thank Dr. Radu Florian for providing me so much guid-\n",
            "ance and support even after I completed the internship. My second internship was\n",
            "v\n",
            "\n",
            "Chunk 6:\n",
            "ACKNOWLEDGMENTS\n",
            "within the Knowledge Induction team, working with Dr. Mariano Rodriguez muro,\n",
            "Dr. Oktie Hassanzadeh, Dr. Achille Fokoue, Dr. Mohammad Sadoghi Hamedani,\n",
            "Dr. Alfio M Gliozzo and Dr. Lisa Amini. This was another fruitful internship at\n",
            "IBM with one paper and one patent published that I would not be able to make\n",
            "without such great mentors. I also would like to thank Dr. Barbara Plank who\n",
            "collaborated with me and taught me how to write a good paper.\n",
            "Last, but certainly not least, I would like to thank my parents and my wife\n",
            "for their tremendous emotional support of my PhD study. Their infinite love and\n",
            "unconditional care have served as the strong basis that I could always resort to\n",
            "in my life. Their trust, encouragement and sympathy have been the major forces\n",
            "that drive me forward and conquer new challenges.\n",
            "My PhD study was gratefully supported by Vietnam Education Foundation,\n",
            "the Ph.D Fellowship from IBM, and the Dean’s Dissertation Fellowship and the\n",
            "Henry MacCracken Fellowship from the Graduate School of Arts and Science at\n",
            "New York University.\n",
            "vi\n",
            "\n",
            "Chunk 7:\n",
            "Abstract\n",
            "The explosion of data has made it crucial to analyze the data and distill im-\n",
            "portant information effectively and efficiently. A significant part of such data\n",
            "is presented in unstructured and free-text documents. This has prompted the\n",
            "development of the techniques for information extraction that allow computers\n",
            "to automatically extract structured information from the natural free-text data.\n",
            "Information extraction is a branch of natural language processing in artificial in-\n",
            "telligence that has a wide range of applications, including question answering,\n",
            "knowledge base population, information retrieval etc. The traditional approach\n",
            "for information extraction has mainly involved hand-designing large feature sets\n",
            "(feature engineering) for different information extraction problems, i.e, entity men-\n",
            "tion detection, relation extraction, coreference resolution, event extraction, and\n",
            "entity linking. This approach is limited by the laborious and expensive effort re-\n",
            "quired for feature engineering for different domains, and suffers from the unseen\n",
            "word/feature problem of natural languages.\n",
            "This dissertation explores a different approach for information extraction that\n",
            "uses deep learning to automate the representation learning process and generate\n",
            "more effective features. Deep learning is a subfield of machine learning that uses\n",
            "vii\n",
            "\n",
            "Chunk 8:\n",
            "ABSTRACT\n",
            "multiple layers of connections to reveal the underlying representations of data. I\n",
            "develop the fundamental deep learning models for information extraction problems\n",
            "and demonstrate their benefits through systematic experiments.\n",
            "First, I examine word embeddings, a general word representation that is pro-\n",
            "duced by training a deep learning model on a large unlabelled dataset. I introduce\n",
            "methods to use word embeddings to obtain new features that generalize well across\n",
            "domains for relation extraction. This is done for both the feature-based method\n",
            "and the kernel-based method of relation extraction.\n",
            "Second, I investigate deep learning models for different problems, including\n",
            "entity mention detection, relation extraction and event detection. I develop new\n",
            "mechanisms and network architectures that allow deep learning to model the struc-\n",
            "tures of information extraction problems more effectively. Some extensive exper-\n",
            "iments are conducted on the domain adaptation and transfer learning settings to\n",
            "highlight the generalization advantage of the deep learning models for information\n",
            "extraction.\n",
            "Finally, I investigate the joint frameworks to simultaneously solve several infor-\n",
            "mation extraction problems and benefit from the inter-dependencies among these\n",
            "problems. I design a novel memory augmented network for deep learning to prop-\n",
            "erly exploit such inter-dependencies. I demonstrate the effectiveness of this net-\n",
            "work on two important problems of information extraction, i.e, event extraction\n",
            "and entity linking.\n",
            "viii\n",
            "\n",
            "Chunk 9:\n",
            "T able of contents\n",
            "Dedication iii\n",
            "Acknowledgments iv\n",
            "Abstract vii\n",
            "List of Figures xiv\n",
            "List of T ables xvi\n",
            "1 Introduction 1\n",
            "1.1 Information Extraction . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
            "1.1.1 Entity Mention Detection . . . . . . . . . . . . . . . . . . . 7\n",
            "1.1.2 Relation Extraction . . . . . . . . . . . . . . . . . . . . . . . 8\n",
            "1.1.3 Coreference Resolution . . . . . . . . . . . . . . . . . . . . . 9\n",
            "1.1.4 Entity Linking . . . . . . . . . . . . . . . . . . . . . . . . . 10\n",
            "1.1.5 Event Extraction . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
            "1.2 Machine Learning Background . . . . . . . . . . . . . . . . . . . . . 12\n",
            "1.2.1 Feature Engineering . . . . . . . . . . . . . . . . . . . . . . 16\n",
            "ix\n",
            "\n",
            "Chunk 10:\n",
            "TABLE OF CONTENTS\n",
            "1.2.2 Representation Learning . . . . . . . . . . . . . . . . . . . . 20\n",
            "1.3 Prior Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
            "1.4 Outline of Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n",
            "2 W ord Embeddings for Domain Adaptation of Relation Extraction 31\n",
            "2.1 The Feature-based Approach . . . . . . . . . . . . . . . . . . . . . . 32\n",
            "2.1.1 Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
            "2.1.2 Word Representations . . . . . . . . . . . . . . . . . . . . . 36\n",
            "2.1.3 Feature Set . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n",
            "2.1.4 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n",
            "2.2 The Kernel-based Approach . . . . . . . . . . . . . . . . . . . . . . 44\n",
            "2.2.1 Relation Extraction Approaches . . . . . . . . . . . . . . . . 47\n",
            "2.2.2 Word Embeddings & Tree Kernels. . . . . . . . . . . . . . . 50\n",
            "2.2.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n",
            "2.2.4 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n",
            "2.3 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n",
            "2.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n",
            "3 Deep Learning for Entity Mention Detection 65\n",
            "3.1 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n",
            "3.1.1 The Basic Models . . . . . . . . . . . . . . . . . . . . . . . . 69\n",
            "3.1.2 Gated Recurrent Units . . . . . . . . . . . . . . . . . . . . . 70\n",
            "3.1.3 The Bidirectional Networks . . . . . . . . . . . . . . . . . . 72\n",
            "3.1.4 Training and Inference . . . . . . . . . . . . . . . . . . . . . 74\n",
            "x\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m-NLWc_JHI7u",
        "outputId": "d1dde18b-fdcb-480a-ae22-12626929d17b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.2.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall llama-index-vector-stores-chroma -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9w6YivmUw8Y",
        "outputId": "4a1311ef-f186-428a-8ace-d94fe467c11e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping llama-index-vector-stores-chroma as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyJjDfcGU2dd",
        "outputId": "c41527d2-18d5-421e-eddb-d7aa9febefdc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.25)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.2.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.15)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package\n",
        "\n",
        "# Import necessary libraries\n",
        "from llama_index.vector_stores import ChromaVectorStore # import after upgrading llama-index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3GXYxDqjVgAu",
        "outputId": "58555651-27ad-4704-c946-327e231b4a43"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.25)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.2.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.15)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "\u001b[33mWARNING: Skipping llama-index-vector-stores-chroma as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'ChromaVectorStore' from 'llama_index.vector_stores' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-b847f3dc6be2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mllama_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_stores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChromaVectorStore\u001b[0m \u001b[0;31m# import after upgrading llama-index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'ChromaVectorStore' from 'llama_index.vector_stores' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-chroma # Install the necessary package to add vector_stores to llama_index\n",
        "# Install the necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package\n",
        "\n",
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd-PHuhFVkEw",
        "outputId": "a222da40-7cc4-4294-9121-6e6ac9ab0ab5"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-chroma\n",
            "  Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl.metadata (696 bytes)\n",
            "Requirement already satisfied: chromadb>=0.5.17 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.6.3)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.12.25)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.18.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.19.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.29.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: llama-index-vector-stores-chroma\n",
            "Successfully installed llama-index-vector-stores-chroma-0.4.1\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.25)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.2.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.15)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Found existing installation: llama-index-vector-stores-chroma 0.4.1\n",
            "Uninstalling llama-index-vector-stores-chroma-0.4.1:\n",
            "  Successfully uninstalled llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-vector-stores-chroma\n",
        "from typing import Collection\n",
        "from pathlib import Path\n",
        "from chromadb import PersistentClient\n",
        "from chromadb.api.types import Documents, Embeddings, Metadatas, IDs\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore  # Correct import\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvc9GSzWV6fJ",
        "outputId": "aec7c2a0-f28b-4309-c538-bc9b87c49f14"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-vector-stores-chroma\n",
            "  Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl.metadata (696 bytes)\n",
            "Requirement already satisfied: chromadb>=0.5.17 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.6.3)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-chroma) (0.12.25)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.11)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2025.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.2)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.1.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.18.3)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.46.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.19.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.29.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
            "Using cached llama_index_vector_stores_chroma-0.4.1-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: llama-index-vector-stores-chroma\n",
            "Successfully installed llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chroma_db = \"./chroma_db\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "Path(chroma_db).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    # Initialize ChromaDB\n",
        "    chroma_client = PersistentClient(path=str(chroma_db))\n",
        "    vector_store = ChromaVectorStore(chroma_client, collection_name=\"chunks\")\n",
        "\n",
        "    print(\"Chroma DB installed and initialized successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Chroma DB encountered an error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaDIMt4tWVC7",
        "outputId": "08bebd54-9ae6-4a18-c432-7982685ec939"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chroma DB installed and initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install --upgrade llama-index\n",
        "!pip uninstall llama-index-vector-stores-chroma -y # uninstall the conflicting package\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM7TXCgNYAws",
        "outputId": "1eae1b23-b78e-463b-f9a3-45c6c7e1b41f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.25)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.25 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.25)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.9)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.25)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.11.14)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.2.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.10.6)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (9.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13.0,>=0.12.25->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.15)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.13.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.4.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud<0.2.0,>=0.1.13->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.14.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.4 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.6)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.25->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (3.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2025.1)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.4->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.25->llama-index) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.17.0)\n",
            "Found existing installation: llama-index-vector-stores-chroma 0.4.1\n",
            "Uninstalling llama-index-vector-stores-chroma-0.4.1:\n",
            "  Successfully uninstalled llama-index-vector-stores-chroma-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.ingestion import IngestionPipeline  # Correct import for IngestionPipeline\n",
        "from llama_index.core.node_parser.text import SentenceSplitter  # Correct import for SentenceSplitter\n",
        "from llama_index.core.node_parser.text import TokenTextSplitter  # Correct import for TokenTextSplitter\n",
        "\n",
        "# Ensure you have the vector_store object properly initialized\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        TokenTextSplitter(chunk_size=512),  # TokenTextSplitter now requires a chunk_size parameter\n",
        "        SentenceSplitter(chunk_size=512, chunk_overlap=0),  # Corrected parameter name\n",
        "    ],\n",
        "    vector_store=vector_store,\n",
        ")\n",
        "\n",
        "print(\"Ingestion pipeline initialized successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAlr2QlxWlo0",
        "outputId": "4b9b667c-a6a6-4fb9-d0b7-f2c4dd0c694a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingestion pipeline initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "  nodes = pipeline.run(documents=document)\n",
        "  if not nodes:\n",
        "    print(\"no nodes were created\")\n",
        "    exit()\n",
        "  print(f\"{len(nodes)} document nodes created in chroma db\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S48ay-fnXeQz",
        "outputId": "7eef77aa-cbe4-4ae3-f126-642f565744d6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278 document nodes created in chroma db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  nodes = pipeline.run(documents=document)\n",
        "  if not nodes:\n",
        "    print(\"no nodes were created\")\n",
        "    exit()\n",
        "  print(f\"{len(nodes)} document nodes created in chroma db\")\n",
        "\n",
        "  # Print all nodes:\n",
        "  for i, node in enumerate(nodes):\n",
        "    print(f\"Node {i + 1}:\")\n",
        "    print(f\"  Text: {node.text}\")  # Print the text content of the node\n",
        "    print(f\"  ID: {node.id_}\")    # Print the unique ID of the node\n",
        "    print(\"-\" * 20)  # Add a separator for better readability\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLVJIN3a49B",
        "outputId": "65017de2-1c04-4b81-cea2-b80f1e59b011"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "278 document nodes created in chroma db\n",
            "Node 1:\n",
            "  Text: DEEP LEARNING FOR INFORMATION EXTRACTION\n",
            "by\n",
            "Thien Huu Nguyen\n",
            "A dissertation submitted in partial fulfillment\n",
            "of the requirements for the degree of\n",
            "Doctor of Philosophy\n",
            "Department of Computer Science\n",
            "New York University\n",
            "May, 2017\n",
            "Professor Ralph Grishman\n",
            "  ID: b337f773-3037-4d32-a1c9-379c5750cc50\n",
            "--------------------\n",
            "Node 2:\n",
            "  Text: © Thien Huu Nguyen\n",
            "All Rights Reserved, 2017\n",
            "  ID: 5e389575-25fd-4914-869f-3b4a4978dab4\n",
            "--------------------\n",
            "Node 3:\n",
            "  Text: Dedication\n",
            "To my beloved mother\n",
            "iii\n",
            "  ID: 9b0314f9-b100-4cdb-a4f2-4d9c0ece7b06\n",
            "--------------------\n",
            "Node 4:\n",
            "  Text: Acknowledgments\n",
            "PeoplehavedifferentstoriestotellintheirPhDtime. MyPhDjourneybeganat\n",
            "a day of Fall 2012. I was supposed to meet my advisor, Professor Ralph Grishman,\n",
            "for the first time in his office. However, on my road to his office that day, I\n",
            "accidentally ran into him in the Broadway avenue. It was the first time I talked to\n",
            "Ralph in person after the many discussions via emails. The unexpected meeting\n",
            "with Ralph impressed me so much that I forgot my nerve and worry of the first\n",
            "days I entered United States to pursue a PhD degree. Ralph was so nice and\n",
            "approachable that I could immediately feel the trust and confidence, the values\n",
            "I have relied on throughout my PhD. The more I work with Ralph, the more\n",
            "fortunate I find myself. Ralph gave me the courage and freedom to explore deep\n",
            "learning for information extraction at the very early days of the field. He provided\n",
            "me with valuable advice and suggestion whenever I need to deal with research\n",
            "challenges and career decisions. It is his advice and enthusiasm that make me\n",
            "more determined to purse an academic career that I have always dreamed of. His\n",
            "responsibility on works and positive attitudes on research would be the principles\n",
            "I employ in the rest of my life. Ralph is the first and foremost person I would like\n",
            "to thank in my academic career.\n",
            "iv\n",
            "  ID: 85034ab2-dfe2-48e8-8542-f7eded8e29d9\n",
            "--------------------\n",
            "Node 5:\n",
            "  Text: ACKNOWLEDGMENTS\n",
            "I own special thanks to Professor Kyunghyun Cho, an outstanding advisor\n",
            "and a great friend who taught me much about deep learning and its potentials\n",
            "to transform our life. Kyunghyun has always been generous on spending his time\n",
            "discussing with me and providing me with great helps and encouragement. I also\n",
            "would like to thank the members of the Proteus project at New York University of\n",
            "which I am always proud to be a part. Dr. Adam Meyers gave me much insights\n",
            "into linguists. Yifan He and Lisheng Fu were always willing to discuss with me on\n",
            "new ideas. Xiang Li was a great listener who encouraged me whenever I have any\n",
            "problem in research and life. Masha Pershina had been a great collaborator on\n",
            "several projects. Kai Cao was always generous to share with me research resources.\n",
            "Bonan Min and Wei Xu were the great academic brother and sister who showed\n",
            "me great tips and advice. I have also learned much useful information from the\n",
            "discussion with Professor Satoshi Sekine and Dr. Angus Grieve-Smith.\n",
            "During my PhD, I was fortunate to have two outstanding internships with two\n",
            "different groups at IBM T.J. Watson Research Center. Some parts in this disser-\n",
            "tation were conducted during such internships. My first internship was associated\n",
            "with the group on Statistical Multilingual Information Extraction from Text where\n",
            "I had the opportunity to work with Dr. Radu Florian, Dr. Avirup Sil, Dr. Geor-\n",
            "giana Dinu, Dr. Salim Rukous, Dr. Vittorio Castelli and many other great people.\n",
            "I have obtained much research experience and received much support from that\n",
            "internship. I learned to implement my first recurrent neural networks there. I\n",
            "would like to especially thank Dr. Radu Florian for providing me so much guid-\n",
            "ance and support even after I completed the internship. My second internship was\n",
            "v\n",
            "  ID: 30d43134-3c9c-4419-95aa-8251f17c6c53\n",
            "--------------------\n",
            "Node 6:\n",
            "  Text: ACKNOWLEDGMENTS\n",
            "within the Knowledge Induction team, working with Dr. Mariano Rodriguez muro,\n",
            "Dr. Oktie Hassanzadeh, Dr. Achille Fokoue, Dr. Mohammad Sadoghi Hamedani,\n",
            "Dr. Alfio M Gliozzo and Dr. Lisa Amini. This was another fruitful internship at\n",
            "IBM with one paper and one patent published that I would not be able to make\n",
            "without such great mentors. I also would like to thank Dr. Barbara Plank who\n",
            "collaborated with me and taught me how to write a good paper.\n",
            "Last, but certainly not least, I would like to thank my parents and my wife\n",
            "for their tremendous emotional support of my PhD study. Their infinite love and\n",
            "unconditional care have served as the strong basis that I could always resort to\n",
            "in my life. Their trust, encouragement and sympathy have been the major forces\n",
            "that drive me forward and conquer new challenges.\n",
            "My PhD study was gratefully supported by Vietnam Education Foundation,\n",
            "the Ph.D Fellowship from IBM, and the Dean’s Dissertation Fellowship and the\n",
            "Henry MacCracken Fellowship from the Graduate School of Arts and Science at\n",
            "New York University.\n",
            "vi\n",
            "  ID: 35b04ef1-d6c0-41fe-b858-6aae7c873ba5\n",
            "--------------------\n",
            "Node 7:\n",
            "  Text: Abstract\n",
            "The explosion of data has made it crucial to analyze the data and distill im-\n",
            "portant information effectively and efficiently. A significant part of such data\n",
            "is presented in unstructured and free-text documents. This has prompted the\n",
            "development of the techniques for information extraction that allow computers\n",
            "to automatically extract structured information from the natural free-text data.\n",
            "Information extraction is a branch of natural language processing in artificial in-\n",
            "telligence that has a wide range of applications, including question answering,\n",
            "knowledge base population, information retrieval etc. The traditional approach\n",
            "for information extraction has mainly involved hand-designing large feature sets\n",
            "(feature engineering) for different information extraction problems, i.e, entity men-\n",
            "tion detection, relation extraction, coreference resolution, event extraction, and\n",
            "entity linking. This approach is limited by the laborious and expensive effort re-\n",
            "quired for feature engineering for different domains, and suffers from the unseen\n",
            "word/feature problem of natural languages.\n",
            "This dissertation explores a different approach for information extraction that\n",
            "uses deep learning to automate the representation learning process and generate\n",
            "more effective features. Deep learning is a subfield of machine learning that uses\n",
            "vii\n",
            "  ID: 3bac6b80-bc37-4fc9-a725-abc2fa04c1a6\n",
            "--------------------\n",
            "Node 8:\n",
            "  Text: ABSTRACT\n",
            "multiple layers of connections to reveal the underlying representations of data. I\n",
            "develop the fundamental deep learning models for information extraction problems\n",
            "and demonstrate their benefits through systematic experiments.\n",
            "First, I examine word embeddings, a general word representation that is pro-\n",
            "duced by training a deep learning model on a large unlabelled dataset. I introduce\n",
            "methods to use word embeddings to obtain new features that generalize well across\n",
            "domains for relation extraction. This is done for both the feature-based method\n",
            "and the kernel-based method of relation extraction.\n",
            "Second, I investigate deep learning models for different problems, including\n",
            "entity mention detection, relation extraction and event detection. I develop new\n",
            "mechanisms and network architectures that allow deep learning to model the struc-\n",
            "tures of information extraction problems more effectively. Some extensive exper-\n",
            "iments are conducted on the domain adaptation and transfer learning settings to\n",
            "highlight the generalization advantage of the deep learning models for information\n",
            "extraction.\n",
            "Finally, I investigate the joint frameworks to simultaneously solve several infor-\n",
            "mation extraction problems and benefit from the inter-dependencies among these\n",
            "problems. I design a novel memory augmented network for deep learning to prop-\n",
            "erly exploit such inter-dependencies. I demonstrate the effectiveness of this net-\n",
            "work on two important problems of information extraction, i.e, event extraction\n",
            "and entity linking.\n",
            "viii\n",
            "  ID: 4a525897-7818-4046-a762-7c47a53dfb6d\n",
            "--------------------\n",
            "Node 9:\n",
            "  Text: T able of contents\n",
            "Dedication iii\n",
            "Acknowledgments iv\n",
            "Abstract vii\n",
            "List of Figures xiv\n",
            "List of T ables xvi\n",
            "1 Introduction 1\n",
            "1.1 Information Extraction . . . . . . . . . . . . . . . . . . . . . . . . . 4\n",
            "1.1.1 Entity Mention Detection . . . . . . . . . . . . . . . . . . . 7\n",
            "1.1.2 Relation Extraction . . . . . . . . . . . . . . . . . . . . . . . 8\n",
            "1.1.3 Coreference Resolution . . . . . . . . . . . . . . . . . . . . . 9\n",
            "1.1.4 Entity Linking . . . . . . . . . . . . . . . . . . . . . . . . . 10\n",
            "1.1.5 Event Extraction . . . . . . . . . . . . . . . . . . . . . . . . 11\n",
            "1.2 Machine Learning Background . . . . . . . . . . . . . . . . . . . . . 12\n",
            "1.2.1 Feature Engineering . . . . . . . . . . . . . . . . . . . . . . 16\n",
            "ix\n",
            "  ID: afb53416-1e40-400b-aaea-de3b78237676\n",
            "--------------------\n",
            "Node 10:\n",
            "  Text: TABLE OF CONTENTS\n",
            "1.2.2 Representation Learning . . . . . . . . . . . . . . . . . . . . 20\n",
            "1.3 Prior Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n",
            "1.4 Outline of Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n",
            "2 W ord Embeddings for Domain Adaptation of Relation Extraction 31\n",
            "2.1 The Feature-based Approach . . . . . . . . . . . . . . . . . . . . . . 32\n",
            "2.1.1 Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n",
            "2.1.2 Word Representations . . . . . . . . . . . . . . . . . . . . . 36\n",
            "2.1.3 Feature Set . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n",
            "2.1.4 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n",
            "2.2 The Kernel-based Approach . . . . . . . . . . . . . . . . . . . . . . 44\n",
            "2.2.1 Relation Extraction Approaches . . . . . . . . . . . . . . . . 47\n",
            "2.2.2 Word Embeddings & Tree Kernels. . . . . . . . . . . . . . . 50\n",
            "2.2.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n",
            "2.2.4 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n",
            "2.3 Related work . . . . . . . . . . . .\n",
            "  ID: 14bbe5cf-d1f8-4c2e-b0cb-b3b8225db171\n",
            "--------------------\n",
            "Node 11:\n",
            "  Text: 61\n",
            "2.3 Related work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n",
            "2.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n",
            "3 Deep Learning for Entity Mention Detection 65\n",
            "3.1 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n",
            "3.1.1 The Basic Models . . . . . . . . . . . . . . . . . . . . . . . . 69\n",
            "3.1.2 Gated Recurrent Units . . . . . . . . . . . . . . . . . . . . . 70\n",
            "3.1.3 The Bidirectional Networks . . . . . . . . . . . . . . . . . . 72\n",
            "3.1.4 Training and Inference . . . . . . . . . . . . . . . . . . . . . 74\n",
            "x\n",
            "  ID: bab2f9cb-1ce5-47d9-9241-5c02a915552a\n",
            "--------------------\n",
            "Node 12:\n",
            "  Text: TABLE OF CONTENTS\n",
            "3.2 Word Representation . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n",
            "3.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n",
            "3.3.1 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n",
            "3.3.2 Resources and Parameters . . . . . . . . . . . . . . . . . . . 78\n",
            "3.3.3 Model Architecture Evaluation . . . . . . . . . . . . . . . . 79\n",
            "3.3.4 Comparison to other Bidirectional RNN Work . . . . . . . . 81\n",
            "3.3.5 Word Embedding Evaluation . . . . . . . . . . . . . . . . . 81\n",
            "3.3.6 Cross-Domain Experiments . . . . . . . . . . . . . . . . . . 83\n",
            "3.3.7 Named Entity Recognition for Dutch . . . . . . . . . . . . . 85\n",
            "3.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n",
            "3.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n",
            "4 Deep Learning for Relation Extraction 89\n",
            "4.1 Convolutional Neural Networks for Relation Extraction. . . . . . . 90\n",
            "4.1.1 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n",
            "4.1.2 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n",
            "4.2 Combining Neural Networks and Log-linear Models to Improve Re-\n",
            "lation\n",
            "  ID: f2139e2d-3a86-4c1f-a6d1-b6596369cc45\n",
            "--------------------\n",
            "Node 13:\n",
            "  Text: . 98\n",
            "4.2 Combining Neural Networks and Log-linear Models to Improve Re-\n",
            "lation Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\n",
            "4.2.1 Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n",
            "4.2.2 The Hybrid Models . . . . . . . . . . . . . . . . . . . . . . . 115\n",
            "4.2.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n",
            "4.2.4 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\n",
            "4.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n",
            "4.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n",
            "xi\n",
            "  ID: 1b6df39d-1e6f-4289-b6bb-ce8df637b4e2\n",
            "--------------------\n",
            "Node 14:\n",
            "  Text: TABLE OF CONTENTS\n",
            "5 Deep Learning for Event Detection 129\n",
            "5.1 Convolutional Neural Networks for Event Detection. . . . . . . . . 130\n",
            "5.1.1 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n",
            "5.1.2 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\n",
            "5.2 Non-consecutive Convolutional Neural Networks for Event Detection140\n",
            "5.2.1 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\n",
            "5.2.2 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\n",
            "5.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n",
            "5.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\n",
            "6 Memory-augmented Networks for Joint Inference in Informa-\n",
            "tion Extraction 151\n",
            "6.1 General Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\n",
            "6.2 Event Extraction with Memory-augmented Neural Networks . . . . 155\n",
            "6.2.1 Event Extraction Task . . . . . . . . . . . . . . . . . . . . . 155\n",
            "6.2.2 Prior Deep Learning Work for Event Extraction. . . . . . . 156\n",
            "6.2.3 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159\n",
            "6.2.4 Word Representation . . . . . . . . . . . . . . . . . . . . . .\n",
            "  ID: 169ccd70-adff-4f2d-baf5-305fdaf5c34f\n",
            "--------------------\n",
            "Node 15:\n",
            "  Text: . . . . . . . . . . . . . . . . . . . . 168\n",
            "6.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168\n",
            "6.3.1 Resources, Parameters and Dataset . . . . . . . . . . . . . . 168\n",
            "6.3.2 Sentences with Multiple Events . . . . . . . . . . . . . . . . 174\n",
            "6.4 Entity Linking with Memory-augmented Neural Networks. . . . . . 175\n",
            "6.4.1 Entity Linking . . . . . . . . . . . . . . . . . . . . . . . . . 175\n",
            "6.4.2 Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\n",
            "xii\n",
            "  ID: ae1717ce-61b6-4807-9e2a-97165a61b6e8\n",
            "--------------------\n",
            "Node 16:\n",
            "  Text: TABLE OF CONTENTS\n",
            "6.4.3 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n",
            "6.4.4 Comparing to the Previous Work . . . . . . . . . . . . . . . 188\n",
            "6.4.5 Domain Adaptation Experiments . . . . . . . . . . . . . . . 190\n",
            "6.5 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\n",
            "6.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n",
            "7 Conclusion and F uture W ork 197\n",
            "Bibliography 200\n",
            "xiii\n",
            "  ID: a15287ed-c489-41db-8f43-ccdac2a0f82a\n",
            "--------------------\n",
            "Node 17:\n",
            "  Text: List of Figures\n",
            "1.1 Information extraction system. . . . . . . . . . . . . . . . . . . . . . . 6\n",
            "1.2 Information extraction pipeline. . . . . . . . . . . . . . . . . . . . . . . 7\n",
            "1.3 Feed-forward Neural Networks. . . . . . . . . . . . . . . . . . . . . . . 23\n",
            "2.1 \u000b vs F-measure on PET+HEAD+PHRASE . . . . . . . . . . . . . . . 56\n",
            "3.1 The ELMAN and JORDAN models . . . . . . . . . . . . . . . . . . . . 70\n",
            "3.2 The bidirectional models. The model on the right is from(Mesnil et al.,\n",
            "2013) with the forward and backward context size of 1.l0;rn+1 are the\n",
            "zero vectors.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n",
            "3.3 Methods to Train Word Embeddings . . . . . . . . . . . . . . . . . . . 77\n",
            "4.1 Convolutional Neural Network for Relation Extraction.. . . . . . . . . 94\n",
            "4.2 F measures vs positive/negative ratios . . . . . . . . . . . . . . . . . . . . 107\n",
            "5.1 Convolutional Neural Network for Event Detection.. . . . . . . . . . . 133\n",
            "6.1 A sequence of prediction tasks in information extraction.. . . . . . . . 152\n",
            "6.2 Memory-augmented neural networks. . . . . . . . . . . . . . . . . . . . 154\n",
            "xiv\n",
            "  ID: f7734819-b57c-4979-9e30-5bea721872bf\n",
            "--------------------\n",
            "Node 18:\n",
            "  Text: List of Figures\n",
            "6.3 Prediction tasks for event extraction. . . . . . . . . . . . . . . . . . . . 157\n",
            "6.4 Memory-augmented neural networks for event extraction.. . . . . . . . 159\n",
            "6.5 ThejointEE modelfor theinputsentence“ a man died when a tank fired\n",
            "in Baghdad ” with local context windowd = 1 . We only demonstrate\n",
            "the memory matricesGarg/trg\n",
            "i in this figure. Green corresponds to the\n",
            "trigger candidate “died” at the current step while violet and red are for\n",
            "the entity mentions “man” and “Baghdad” respectively.. . . . . . . . . 161\n",
            "6.6 Prediction tasks for entity linking.. . . . . . . . . . . . . . . . . . . . . 177\n",
            "6.7 Memory-augmented neural networks for entity linking. . . . . . . . . . 179\n",
            "6.8 Joint model for learning local and global features for a document with\n",
            "3 entity mentions: “Chelsea”, “Arsenal” and “Liverpool”. Each of the\n",
            "entity mentions has two entity candidate pages (either a football club or\n",
            "a city).The orange rectangles denote the CNN-induced representation\n",
            "vectors \u0016sufi, \u0016ctxi, \u0016doci, \u0016tilij and \u0016bdyij. The circles in red and green are\n",
            "the ranking scores for the target candidates, in which the green circles\n",
            "correspond to the correct target entities. Finally, the circles in grey are\n",
            "the hidden vectors (i.e, the global vectors) of the RNNs running over\n",
            "the entity mentions. We only show the global entity vectors in this\n",
            "figure to improve the visualization.. . . . . . . . . . . . . . . . . . . . 185\n",
            "6.9 t-SNEvisualizationontherepresentationvectors ctxi ofdifferentdomains. 192\n",
            "xv\n",
            "  ID: 2643abce-0167-4696-9ed6-1fa4558a7bba\n",
            "--------------------\n",
            "Node 19:\n",
            "  Text: List of T ables\n",
            "2.1 Lexical feature groups ordered by importance. . . . . . . . . . . . . . . 38\n",
            "2.2 In-domain and Out-of-domain performance for different embedding fea-\n",
            "tures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n",
            "2.3 Domain adaptation results with word representations.. . . . . . . . . . 41\n",
            "2.4 Domain adaptation results with regularization.. . . . . . . . . . . . . . 43\n",
            "2.5 Performance on the bc dev set for PET. . . . . . . . . . . . . . . . . . 55\n",
            "2.6 In-domain (first column) and out-of-domain performance (columns two\n",
            "to four) on ACE 2005. Systems of the rows not in gray come from\n",
            "(PlankandMoschitti, 2013)(thebaselines). WEDmeansHEAD+PHRASE. 57\n",
            "2.7 Performance of the feature-based method (dev). . . . . . . . . . . . . . 59\n",
            "2.8 Tree kernel-based in (Plank and Moschitti, 2013) vs feature-based in\n",
            "(Nguyen and Grishman, 2014a). All the comparisons between the tree\n",
            "kernel-based method and the feature-based method in this table are\n",
            "significant withp< 0:05. . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n",
            "3.1 ACE 2005 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n",
            "3.2 The basic models’ performance . . . . . . . . . . . . . . . . . . . . . . 79\n",
            "xvi\n",
            "  ID: ea6db41f-da35-4e30-bb48-395cea916616\n",
            "--------------------\n",
            "Node 20:\n",
            "  Text: List of Tables\n",
            "3.3 The bidirectional models’ performance . . . . . . . . . . . . . . . . . . 80\n",
            "3.4 Comparison to (Mesnil et al., 2013). . . . . . . . . . . . . . . . . . . . 81\n",
            "3.5 Comparison of methods for word embeddings. . . . . . . . . . . . . . . 82\n",
            "3.6 System’s performance on the cross-domain setting. Cells marked with\n",
            "†designate the BIDIRECT models that significantly outperform (p <\n",
            "0:05) the MEMM model on the specified domains.. . . . . . . . . . . . 84\n",
            "3.7 Comparison between MEMM and BIDIRECT. Cells marked with †des-\n",
            "ignate the statistical significance (p <0:05). The columns and rows\n",
            "correspond to the source and target domains respectively. BIDIRECT-\n",
            "MEMM implies performance substraction. . . . . . . . . . . . . . . . . 85\n",
            "3.8 Performance on Dutch CoNLL 2002. . . . . . . . . . . . . . . . . . . . 86\n",
            "4.1 ACE 2005 and SemEval 2010 relation class distributions.. . . . . . . . 100\n",
            "4.2 System performance on various window size combinations and architec-\n",
            "tures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n",
            "4.3 Performance of relation extraction systems. . . . . . . . . . . . . . . . 103\n",
            "4.4 Performance of relation classification systems. . . . . . . . . . . . . . . 106\n",
            "4.5 Performance (F1 scores) of RNNs on the dev set.. . . . . . . . . . . . 119\n",
            "4.6 Performance of the combination methods. . . . . . . . . . . . . . . . . 121\n",
            "4.7 Performance of the hybrid models on the ACE 2005 development set..\n",
            "  ID: cfb09ce0-10f6-44ed-a38b-740276f0fa7f\n",
            "--------------------\n",
            "Node 21:\n",
            "  Text: 121\n",
            "4.7 Performance of the hybrid models on the ACE 2005 development set.. 123\n",
            "4.8 Comparison to the state of the art on the ACE 2005 dataset. The\n",
            "cells marked with †designates the models that are significantly better\n",
            "than the other neural network models (\u001a< 0:05) on the corresponding\n",
            "domains. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n",
            "xvii\n",
            "  ID: 2e5aca18-a353-40bc-a994-f0ae01d282eb\n",
            "--------------------\n",
            "Node 22:\n",
            "  Text: List of Tables\n",
            "4.9 Performance of relation classification systems. The “†” refers to special\n",
            "treatment of theOther class. . . . . . . . . . . . . . . . . . . . . . . . 126\n",
            "4.10 The performance breakdown per relation for CNN and BIDIRECT on\n",
            "the development set. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\n",
            "5.1 Performance on the development set. . . . . . . . . . . . . . . . . . . . 135\n",
            "5.2 Performance with gold-standard entity mentions and types.ybeyond\n",
            "sentence level.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n",
            "5.3 Performance with predicted entity mentions and types.. . . . . . . . . 137\n",
            "5.4 In-domain (first column) and Out-of-domain performance for event de-\n",
            "tection (columns two to four). Cells marked with †designate CNN\n",
            "models that significantly outperform (p< 0:05) all the reported feature-\n",
            "based methods on the specified domain.. . . . . . . . . . . . . . . . . 139\n",
            "5.5 Performance with gold-standard entity mentions and types.ybeyond\n",
            "sentence level.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\n",
            "5.6 Performance on the source domain and on the target domains. Cells\n",
            "marked with †designates that NC-CNN significantly outperforms (p<\n",
            "0:05) all the compared methods on the specified domain.. . . . . . . . 147\n",
            "6.1 Performance of the memory vector/matrices on the development set.\n",
            "No means not using the memory vector/matrices.. . . . . . . . . . . . 170\n",
            "6.2 Performance of the word embedding techniques.. . . . . . . . . . . . . 172\n",
            "6.3 Overall performance on the blind test data. “†” designates the systems\n",
            "that employ\n",
            "  ID: d5b084f9-3247-40f5-aae5-740b07089bbe\n",
            "--------------------\n",
            "Node 23:\n",
            "  Text: Overall performance on the blind test data. “†” designates the systems\n",
            "that employ the evidences beyond sentence level.. . . . . . . . . . . . 173\n",
            "xviii\n",
            "  ID: bd6e3210-616c-4f54-9c32-6a68a201a65a\n",
            "--------------------\n",
            "Node 24:\n",
            "  Text: List of Tables\n",
            "6.4 System performance on single event sentences (1/1) and multiple event\n",
            "sentences (1/N). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\n",
            "6.5 Performance of the global features on the development set.No means\n",
            "not using the global features. . . . . . . . . . . . . . . . . . . . . . . . 188\n",
            "6.6 Performance of the systems. Cells marked with †designate theGlobal-\n",
            "RNN models that significantly outperform theLocal CNN model (\u001a<\n",
            "0:05). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n",
            "6.7 Cross-domain performance. Cells marked with †designate the Glob-\n",
            "RNN models that significantly outperform theLocal CNN model (\u001a<\n",
            "0:05). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n",
            "6.8 Similarities to the source domainnews. . . . . . . . . . . . . . . . . . . 194\n",
            "xix\n",
            "  ID: b827800f-8437-4f46-8b5d-1660c53a2841\n",
            "--------------------\n",
            "Node 25:\n",
            "  Text: Chapter 1\n",
            "Introduction\n",
            "Entities and events are the central objects in the languages we produce in\n",
            "discussionandcommunicationeveryday. Forinstance, thearticlesfrom newsmight\n",
            "describe some recent attacks (events) while we might talk about celebrities or\n",
            "politicians(entities)inourcasualdiscussion. Itisthereforecrucialforcomputersto\n",
            "recognizesuchentitiesandeventssothattheycancomeclosertotheunderstanding\n",
            "of human languages. This is essentially the target of Information Extraction (IE), a\n",
            "branchofresearchinNaturalLanguageProcessing(NLP),thataimsforidentifying\n",
            "entities, events and the inter-connections between them within text. The ultimate\n",
            "goalistotransferinformationintextintoamoreaccessibleformforothercomputer\n",
            "applications such as question answering, information retrieval, knowledge base\n",
            "population, knowledge reasoning, to name a few.\n",
            "In order to solve the problems of IE, the traditional systems have employed dif-\n",
            "ferent pipelines to generate feature representations (feature sets) that are then fed\n",
            "into machine learning models to perform classification or labeling. These feature\n",
            "1\n",
            "  ID: 2c7a27df-1f88-413a-953d-0f9917ca1910\n",
            "--------------------\n",
            "Node 26:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "pipelines often involve various NLP supervised modules and resources to extract\n",
            "different linguistic characteristics, hopefully capturing important features for the\n",
            "IE tasks. The determination of which NLP modules and resources are used and\n",
            "which features should be extracted is called “feature engineering”. For convenience,\n",
            "we will also call these traditional feature engineering models as the “feature-based”\n",
            "models. There are three major problems with this feature-based approach:\n",
            "1. Feature engineering for IE is a manual and expensive process that requires\n",
            "much linguistic intuition as well as domain expertise. The feature represen-\n",
            "tations are often customized for some specific domains, thus necessitating\n",
            "additional investigations whenever a new domain of data is presented.\n",
            "2. Despite much effort on hand-designing feature representations for IE, the\n",
            "resulting feature sets might be not necessarily optimal. This issue can be seen\n",
            "in three aspects. First, as our understanding about the IE tasks and their\n",
            "domains (domain knowledge) is often incomplete, the feature designer might\n",
            "still miss some important features for his tasks. Second, it is challenging to\n",
            "realizeandcapturetheinteractionsbetweenthedesignedfeatures, potentially\n",
            "causing the information redundancy in the feature sets. Third, the NLP\n",
            "supervised modules and resources for feature generation might involve errors,\n",
            "leading to errors of the features they generate. All these aspects would\n",
            "eventually impair the performance of the IE systems.\n",
            "3. Thefeature-basedmodelssufferfromthedatasparsityorunseenword/feature\n",
            "problem. In this problem, some important words/features of the machine\n",
            "2\n",
            "  ID: 934ddc0f-ee81-40e4-b80e-ffdc21a95680\n",
            "--------------------\n",
            "Node 27:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "learning models do not appear in the new data to which we want to apply\n",
            "the models, causing the failure of the models on such new data. The unseen\n",
            "word/feature problem is stem from the representations of words as symbolic\n",
            "items and the computation of the feature values as the discrete compositions\n",
            "of words. Such discrete nature implies the hard matches of feature appear-\n",
            "ance that is very likely to fail in the context of the new data.\n",
            "This dissertation introduces a new approach for IE problems that is based on\n",
            "Deep Learning to address the three aforementioned problems of the feature-based\n",
            "models. Deep learning or artificial neural networks (NN) is a branch of machine\n",
            "learning whose major advantage is the capacity to automatically induce effective\n",
            "feature representations from data. In the deep learning models for IE, multiple\n",
            "layers of hidden vectors are put on top of word embeddings, the general represen-\n",
            "tations of words that can capture their hidden syntactic and semantic properties.\n",
            "Word embeddings replace the hard matches of words in the feature-based approach\n",
            "with the soft matchesof continuouswordvectorswhile the multiplelayersof hidden\n",
            "vectors further abstracts the word embeddings to automatically obtain underlying\n",
            "feature representations from data. Consequently, word embeddings mitigate the\n",
            "unseen word/feature problem of the feature-based models while the whole deep\n",
            "learning models help to avoid feature engineering and/or provide effective feature\n",
            "representations. To the best of my knowledge, this dissertation is among the first\n",
            "works that develop the fundamental deep learning models for information extrac-\n",
            "tion.\n",
            "In the next section of this chapter, I will first describe the IE problem in details\n",
            "3\n",
            "  ID: 235d6180-b34e-4bd9-a83b-495a57dc0ee3\n",
            "--------------------\n",
            "Node 28:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "and then review some background on machine learning and deep learning that is\n",
            "necessaryforthenextchapters. Afterward, Iwillpresentsomeoftherepresentative\n",
            "previous works for IE. Finally, I will sketch an outline for this dissertation.\n",
            "1.1 Information Extraction\n",
            "Information Extraction is the process of extracting structured information from\n",
            "unstructured text (i.e, online news, government documents, social media text, med-\n",
            "ical alerts and records, etc). The structured information is often organized in the\n",
            "table format of databases. In information extraction, we are mainly interested in\n",
            "two following types of databases:\n",
            "• Relation Database: storing entities and the semantic relations (connections)\n",
            "between those entities.\n",
            "• Event Database: recording events and the entities that participate in such\n",
            "events.\n",
            "For this dissertation, we only focus on the entities, relations and events that\n",
            "are mentioned explicitly in text. The possible reasoning or inference over these\n",
            "objects at the database level should be considered as the next important steps and\n",
            "is beyond the scope of the current work.\n",
            "Practically, given a set of documents, we want to distill the entities, relations\n",
            "and events of interest, and utilize them to populate relation and event databases.\n",
            "An illustration of this process is shown in Figure1.1. The left side of this figure\n",
            "4\n",
            "  ID: 5a19c692-baec-4a95-89a6-f39f3aa84293\n",
            "--------------------\n",
            "Node 29:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "presents a piece of unstructured text from some set of documents while the right\n",
            "side demonstrates the relation and event databases we want to create from the left\n",
            "side’s text. As we can see in the figure, the relation database contains the semantic\n",
            "relation “leaderOf ” between Giuliani (the former mayor of New York City) and\n",
            "New York City (a city in the United States). The event database, on the other\n",
            "hand, includes a “divorce” event in July between Giuliani (again, the former mayor\n",
            "of New York City) and Donna Hanover (the second wife of Giuliani). All these\n",
            "information and facts are mentioned explicitly in the text of Figure1.1 and our IE\n",
            "task is to automatically extract them.\n",
            "The construction of relation and event databases from a set of documents can\n",
            "be divided into several tasks that altogether constitute the information extraction\n",
            "pipeline (Grishman, 2012). This pipeline involves the tasks of Entity Mention\n",
            "Detection, Relation Extraction, Coreference Resolution, Entity Linking, Trigger\n",
            "Prediction and Argument Prediction. The tasks and the flow of information in the\n",
            "information extraction pipeline is demonstrated in Figure1.2.\n",
            "In the following, we always assume that documents have been split into sen-\n",
            "tences and sentences are already segmented into words. Sentence splitting and\n",
            "word segmentation are the preprocessing steps that can be done very well for En-\n",
            "glish using the current toolkits such as NTLK1 or Stanford CoreNLP2.\n",
            "In order to describe the IE tasks in more details, let us consider the text in\n",
            "Figure 1.1 as an example:\n",
            "1. http://www.nltk.org\n",
            "2. http://stanfordnlp.github.io/CoreNLP\n",
            "5\n",
            "  ID: 3e141be1-dc57-4c68-8eb8-b476d7c2e1a9\n",
            "--------------------\n",
            "Node 30:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "Figure 1.1: Information extraction system.\n",
            "“Giuliani finally settled his divorce from Donna Hanover in July after\n",
            "20 years of marriage. Five months later, Giuliani proposed to Nathan,\n",
            "a former nurse, who gave him tremendous emotional support through\n",
            "his cancer treatment and as he led New York City during the Sept. 11,\n",
            "2001, terror attacks.”\n",
            "6\n",
            "  ID: d265d6f1-a6d4-4fee-989f-10a5fb0fd74b\n",
            "--------------------\n",
            "Node 31:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "Figure 1.2: Information extraction pipeline.\n",
            "1.1.1 Entity Mention Detection\n",
            "In the IE pipeline, the first task to build the relation database is Entity Mention\n",
            "Detection (EMD) that is supposed to locate and classify entity mentions in text\n",
            "into predefined classes (types). Entity mentions are continuous sequences of words\n",
            "inthesentencesthatmentionsomeobjects(entities)inreality. Entitymentionscan\n",
            "appear in various forms, including names, pronouns (i.e, “he”, “she”, “it”, “her”,\n",
            "“who”etc), and nominals (i.e, nouns, noun phrases, etc). In our text example above,\n",
            "7\n",
            "  ID: 486e8082-f0d6-4517-8ab1-defc6d13e70b\n",
            "--------------------\n",
            "Node 32:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "for entity names, an EMD system should be able to recognize “Giuliani”, “Donna\n",
            "Hanover” and “Nathan” as person names, “New Y ork City” as a city name, and\n",
            "“July” and “Sept. 11, 2011 ” as times3. Besides, an EMD system should realize\n",
            "that the pronouns “he”, “his”, “him” and “who” as well as the nominal “a former\n",
            "nurse” are also entity mentions for some persons in this text. An reduced format\n",
            "of EMD is Named Entity Recognition where we only need to extract entity names\n",
            "(i.e, ignoring pronouns and nominals).\n",
            "Note that for each entity mention, we often designate a single word (called the\n",
            "head word) that is most responsible for the its meaning in the corresponding word\n",
            "sequence. For instance, the head word of the entity mention “a former nurse ” is\n",
            "“nurse” while the head word for the pronoun entity mentions (i.e, “he”, “his”, etc)\n",
            "are the pronouns itself. There is one exception for names as we consider their head\n",
            "words as involving every word in their word sequences, thus possibly spanning\n",
            "several consecutive words in the sentences. “Donna Hanover ” is an example for\n",
            "named entity mentions that have more than one head words (i.e, “Donna” and\n",
            "“Hanover”). In the applications, it is often sufficient for the EMD systems to\n",
            "recognize only the head words of the entity mentions.\n",
            "1.1.2 Relation Extraction\n",
            "Given the entity mentions from the previous step of EMD, in the next step of\n",
            "Relation Extraction for the relation database, we want to detect and classify the\n",
            "3. In the applications, the detection of times is often done separately from the detection of\n",
            "other entity types, thus differentiating times from entity mentions in terms of concepts. However,\n",
            "in this dissertation, for convenience, we will consider times as a type of entity mentions unless a\n",
            "clarification is needed.\n",
            "8\n",
            "  ID: b697e3b4-a86f-49e5-a62a-395758bfd795\n",
            "--------------------\n",
            "Node 33:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "semantic relationships between two entity mentions within in the same sentences.\n",
            "For convenience, we often call any pairs of entity mentions appearing in the same\n",
            "sentences as relation mentions. In our example text, a relation extraction system\n",
            "is expected to identify the relation of type “leader of ” between the entity mention\n",
            "“he” (for a person) and the entity mention “New Y ork City” (for a city) in the\n",
            "phrase “as he led New Y ork City during Sept. 11, 2001, terror attacks.”. Note that\n",
            "the relation classes of interest for classification (i.e, “leader of ”) are often given as\n",
            "an input by some user.\n",
            "1.1.3 Coreference Resolution\n",
            "From the relation extraction component, we know that “he” is the leader of\n",
            "“New Y ork City”. However, who is “he” in this case? By looking at the previous\n",
            "context of the phrase “as he led New Y ork City during Sept. 11, 2001, terror\n",
            "attacks.” in the example text, we know that the pronoun “he” is referring to the\n",
            "entity mention “Giuliani” appearing at the beginning of its sentence (i.e, “Five\n",
            "months later, Giuliani proposed to Nathan … ”). This is essentially the task we\n",
            "want to perform in Coreference Resolution (i.e, recognizing the coreference of the\n",
            "pronounce “he” and the entity mention “Giuliani”. More generally, the goal of\n",
            "Coreference Resolution is to group entity mentions corresponding to the same\n",
            "entity in a document into the same cluster. We generate one cluster for each\n",
            "entity, forming a set of entity clusters for each document.\n",
            "9\n",
            "  ID: 349a53ec-5001-41b6-9ca3-cbe9a58362b6\n",
            "--------------------\n",
            "Node 34:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "1.1.4 Entity Linking\n",
            "The name “Giuliani” provides some identity information for the the pronouns\n",
            "“he”, “his”, and “him”, and their corresponding entity cluster. However, it is not\n",
            "sufficient to determine an unique person (entity) in reality that is necessary to\n",
            "find the entry for this entity in the database. This problem is due to our analysis\n",
            "of multiple documents that might contain several entities with the same name\n",
            "“Giuliani”. In order to overcome this problem, we need to do Entity Linking or\n",
            "Entity Disambiguation that seeks to link entity mentions or entities in documents\n",
            "into some real world entities. For instance, in our text example, an entity linking\n",
            "system should understand that “Giuliani” is the former mayor of New York City\n",
            "while “Donna Hanover ” is his second wife based on the context of such entity\n",
            "mentions.\n",
            "In practice, we often model the real world by some graph (called knowledge\n",
            "base) whose nodes represent entities in reality and edges capture the connections\n",
            "among the entities. Each node of the knowledge base might contain different in-\n",
            "formation about the corresponding entity. Wikipedia4 is a typical example for\n",
            "such modeling effort. Given the knowledge base, Entity Linking is often defined\n",
            "as mapping entity mentions or entities in documents into the corresponding enti-\n",
            "ties (nodes) of the knowledge base. The identifies of the nodes (entities) in the\n",
            "knowledge base now serve as the identities for the entities and entity mentions in\n",
            "the input documents.\n",
            "The combination of all the information gathered in the previous components\n",
            "4. https://en.wikipedia.org/wiki/Main_Page\n",
            "10\n",
            "  ID: 3698071a-3d08-4301-9711-cda539a25edc\n",
            "--------------------\n",
            "Node 35:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "(i.e, Entity Mention Detection, Relation Extraction, Coreference Resolution and\n",
            "Entity Linking) allows us to populate the relation database as we can see in Figure\n",
            "1.1. In the next section, we discuss the necessary steps to fill in the event database.\n",
            "Similartotherelationdatabase, thefirststepfortheeventdatabaseisdetecting\n",
            "entity mentions in the input documents (EMD). This is then followed by a new\n",
            "task of Event Extraction.\n",
            "1.1.5 Event Extraction\n",
            "An event such as marriage, death, election etc can be narrated several times in\n",
            "differentsentencesofadocument. Eachsuchsentenceiscalledaneventmentionfor\n",
            "that event and contains a trigger, the main word expressing the event. The event\n",
            "mentions of an event share the same event type and involve several arguments (i.e,\n",
            "entity mentions) as properties. These properties often concerns the participants\n",
            "of the even mentions and their times and locations. For instance, according to\n",
            "the ACE 2005 guideline5, the first sentence of the example text “Giuliani final ly\n",
            "settled his divorce from Donna Hanover in July after 20 years of marriage ” is\n",
            "an event mention of type “Divorce” whose trigger is “divorce” and arguments are\n",
            "“Giuliani” and “Donna Hanover ” for the participating people and “July” for the\n",
            "time. Consequently, each event in a document is a cluster of coreferring event\n",
            "mentions with the same type while each sentence in a document might correspond\n",
            "to multiple event mentions (possibly from different events) that have different\n",
            "trigger words.\n",
            "5. https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-events-guidelines-\n",
            "v5.4.3.pdf\n",
            "11\n",
            "  ID: 6a59b7c4-5fa3-4d59-804c-f8192596ad5c\n",
            "--------------------\n",
            "Node 36:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "The Event Extraction task is to identify and classify the trigger words into\n",
            "some types of interest as well as locate arguments for the detected event types\n",
            "within the same sentence. Traditionally, event extraction systems have sequen-\n",
            "tially performed the two following steps: (i) recognizing event triggers in sentences\n",
            "(Trigger Prediction, Trigger Labeling or Event Detection), and (ii) assigning roles\n",
            "to the entity mentions as arguments for the recognized event triggers in step (i)\n",
            "(Argument Prediction or Argument Labeling).\n",
            "Finally, we also need to perform coreference resolution and entity linking over\n",
            "the entity mention arguments of the detected event mentions so we can group and\n",
            "link them to the their real world entities (Figure1.2). The resulting event mentions\n",
            "and linked entity mentions can be then inserted into the event knowledge base as\n",
            "in Figure1.1. This concludes our description of the information extraction tasks.\n",
            "In the next section, I will present some background on machine learning and deep\n",
            "learning that is important to our following discussion on IE.\n",
            "1.2 Machine Learning Background\n",
            "Most of the IE tasks can be formulated as a classification problem over some\n",
            "appropriate objects or instances. In this problem, given a set of K predefined\n",
            "classes Y (jYj = K) and an object X, we need to choose a classY 2Y that\n",
            "captures the nature of X. For instance, in relation extraction, the predefined\n",
            "classes Yinvolve the semantic relations of interest (i.e, “leader of ”, “employed by”,\n",
            "etc) while the objects correspond to the relation mentions with sentences and two\n",
            "target entity mentions.\n",
            "12\n",
            "  ID: e4cfc6ed-4589-45ae-b064-0c4c6dbea236\n",
            "--------------------\n",
            "Node 37:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "In order to solve this classification problem for IE, the first step is to design\n",
            "some functionR to transform the initial input objectX into some mathematical\n",
            "representation R(X) that is more convenient for the mathematical analysis later.\n",
            "Practically,R(X) is often a binary of continuous vector that is expected to involve\n",
            "the most representative and important features for the classification task. The\n",
            "design of the transformation functionR is an art whose effectiveness is crucial to\n",
            "the classification performance.\n",
            "Once the feature representationR(X) has been computed, the next step is to\n",
            "use a functionS to mapR(X) into some scoresS(R(X)) whose values can be used\n",
            "to decide the class for the initial instanceX in Y. In most of the cases,S(R(X))\n",
            "is a vector of real-valued numbers that assign a likelihood score for each class in\n",
            "Y. The task of machine learning is to build the functionS to effectively predict\n",
            "the classes for the input instancesX.\n",
            "For information extraction, the score functionSis often parameterized by some\n",
            "parameter \u0012, written asS(R(X);\u0012) or simply asS(X;\u0012) if we do not want to em-\n",
            "phasize the representation functionR. This parameterization converts the problem\n",
            "of determiningS into the problem of finding the suitable value for the parameter\n",
            "\u0012. In machine learning for information extraction, we often seek to find such value\n",
            "(called \u0012\u0003) by minimizing the expected risk:\n",
            "\u0012\u0003 = argmin\u0012E(X;Y)\u0018P(X;Y)[L(S(X;\u0012);Y )] (1.1)\n",
            "In this formula, X and Y are random variables to denote the initial input\n",
            "instances and their correspondingcorrect classes inYwhile P(X;Y ) represents the\n",
            "13\n",
            "  ID: d8ee3618-f337-49e3-b3b0-0033da99f5b9\n",
            "--------------------\n",
            "Node 38:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "joint probability distribution over these two variables. In addition,L(S(X;\u0012);Y )\n",
            "is the cost function or the objective function that evaluates the loss of usingS(X;\u0012)\n",
            "to determine the class forX (the predicted class) given thatY is the correct class\n",
            "for X in this case.\n",
            "Unfortunately, the evaluation of the expectation in Equation1.1 is often in-\n",
            "tractable as we need to enumerate over all the exponentially possible values for\n",
            "(X;Y ). In practice, we can only try to obtain a finite set of samples D =\n",
            "f(X1;Y1);(X2;Y2);:::; (Xn;Yn)gfromP(X;Y ) (i.e,jDj= nand(Xi;Yi) \u0018P(X;Y )\n",
            "for alli 2[1::n]). D is also known as the training dataset in supervised learning.\n",
            "We can then useD to estimate the probability distributionP(X;Y ), leading to\n",
            "the empirical distribution^P(X;Y ) and the approximation of the expected risk by\n",
            "the empirical risk from the Monte Carlo sampling principle:\n",
            "E(X;Y)\u0018P(X;Y)[L(S(X;\u0012);Y )] \u0019E(X;Y)\u0018 ^P(X;Y)[L(S(X;\u0012);Y )]\n",
            "= 1\n",
            "n\n",
            "n∑\n",
            "i=1\n",
            "L(S(Xi;\u0012);Yi)\n",
            "(1.2)\n",
            "Thus, \u0012\u0003 can be computed by:\n",
            "\u0012\u0003 = argmin\u0012E(X;Y)\u0018P(X;Y)[L(S(X;\u0012);Y )]\n",
            "\u0019argmin\u0012\n",
            "1\n",
            "n\n",
            "n∑\n",
            "i=1\n",
            "L(S(Xi;\u0012);Yi)\n",
            "(1.3)\n",
            "Inordertoavoidoverfittingtothetrainingdataset D, weoftenaddaregularizer\n",
            "Ω(\u0012) to the right hand side of Equation1.3 to penalize the large values of\u0012:\n",
            "14\n",
            "  ID: c9a1e0ce-0032-49a2-84b7-f89730e99f4c\n",
            "--------------------\n",
            "Node 39:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "\u0012\u0003 \u0019argmin\u0012\n",
            "[\n",
            "1\n",
            "n\n",
            "n∑\n",
            "i=1\n",
            "L(S(Xi;\u0012);Yi) + \u0015Ω(\u0012)\n",
            "]\n",
            "(1.4)\n",
            "where \u0015 is a tradeoff between the loss on the training datasetD and the com-\n",
            "plexity of the model measured byΩ(\u0012). The regularizerΩ(\u0012) is often some norm\n",
            "of \u0012 such as theL1 norm jj\u0012jj1 or theL2 norm jj\u0012jj2.\n",
            "The optimization problem in Equation1.4 can be solved by techniques in opti-\n",
            "mization theory such as gradient decent, coordinate descent or Newton’s methods\n",
            "(Goodfellow et al.,2016). Once \u0012\u0003 is obtained, we can combine the function (or\n",
            "model) S(X;\u0012\u0003) with our decision rule to predict the class for any new input in-\n",
            "stance X.\n",
            "This framework for classification belongs to the class of the supervised learn-\n",
            "ing methods in machine learning as we assume the correct labelsYi for the input\n",
            "instances Xi in the training datasetD. Two important elements in this framework\n",
            "are the feature representation functionR(X) and the score functionS(R(X)) that\n",
            "will significantly affect the performance of a classification model. The options for\n",
            "these two functions amount to different classification models for information ex-\n",
            "traction. Note that the score functionS(R(X)) is often associated with a decision\n",
            "rule to infer the class for the input instancesX.\n",
            "There are two possible ways to form the representation functionR(X), i.e,\n",
            "feature engineering and representation learning. In feature engineering, R(X) is\n",
            "manually designed by the domain experts who rely on their domain knowledge\n",
            "and linguistic intuition to specify the most important characteristics or features\n",
            "for some IE task. The researchers then determine the toolkits, resources and\n",
            "15\n",
            "  ID: 8152b6e4-5bdb-4302-958d-fb4c594daaab\n",
            "--------------------\n",
            "Node 40:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "mechanisms to compute such characteristics for the input instancesX. Features in\n",
            "this approach often have binary values to indicate the presence or absence of some\n",
            "discrete linguistic structures (i.e, the appearance of some word in some gazetteer,\n",
            "the occurrence of some word or syntactic relation in the context, etc).\n",
            "Feature engineering allows the incorporation of our intuition (for the classifica-\n",
            "tionproblem)intothemodels, generatinghighlyinterpretableclassificationmodels.\n",
            "These advantages cause the prevalence of feature engineering to IE tasks that has\n",
            "significantly advanced our performance for such tasks in the last decade. However,\n",
            "as we discussed at the beginning of this chapter, feature engineering has several\n",
            "limitations due to its use of binary features and manual construction of feature\n",
            "sets. Such limitations are the major motivation of this dissertation that explores\n",
            "the representation learning approach to generate the feature representationR(X).\n",
            "Representation learning uses neural networks to automatically induceR(X) from\n",
            "data and mitigates the unseen word/feature problem of binary features. In the\n",
            "following, I will review methods to build the score functionS(X) in the feature\n",
            "engineering approach as well as present some background on neural networks to\n",
            "facilitate our discussion later.\n",
            "1.2.1 F eature Engineering\n",
            "Once the feature representation vectorR(X) has been hand-designed and com-\n",
            "puted for the input instancesX, we can apply different methods to model the\n",
            "score functionS(R(X)). The two most popular methods forS(R(X)) in informa-\n",
            "tion extraction are Maximum Entropy and Support Vector Machines (SVM). For\n",
            "16\n",
            "  ID: 4d7d556c-dccd-4cfc-8e75-88c1d98a8291\n",
            "--------------------\n",
            "Node 41:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "convenience, we denoted as the size of the vectorR(X) (jR(X)j= d). Note that\n",
            "this sized is fixed for all the representation vectorsR(X) of all the possible input\n",
            "instances X.\n",
            "1.2.1.1 Maximum Entropy\n",
            "In Maximum Entropy (Kambhatla,2004), we parameterizeS(R(X)) by a pa-\n",
            "rameter matrixB (B 2Rd\u0002K) to assign importance weights for the features (ele-\n",
            "ments) in the representation vectorR(X) with respect to different possible classes\n",
            "in Y(jYj= K), i.e, thei-th column ofBcorresponds to the feature weights for the\n",
            "i-th class inY. The product BTR(X) is then added by a bias vectorb (b 2RK)\n",
            "to obtain the likelihood vector6 A = BTR(X) + b of size K for every class inY.\n",
            "The expectation is the higher a likelihood value inA for some class inYis, the\n",
            "more likely this class is the correct class for the inputX. Finally, we normalize the\n",
            "likelihoods inA= [ a1;a2;:::;a K] via thesoftmax function to obtain a probability\n",
            "distribution over the classes inY, severing as our score functionS(R(X)) in this\n",
            "method:\n",
            "S(R(X)) = S(X;\u0012) = softmax(A) =\n",
            "[ea1\n",
            "Z ;ea2\n",
            "Z ;:::; eaK\n",
            "Z\n",
            "]\n",
            "(1.5)\n",
            "where Z is a normalizing constant:\n",
            "Z =\n",
            "K∑\n",
            "i=1\n",
            "eai (1.6)\n",
            "6. W e assumeR(X) and b are column vectors in this case for convenience\n",
            "17\n",
            "  ID: 1ba57734-4c43-4e09-aa93-bc6972f886ec\n",
            "--------------------\n",
            "Node 42:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "The parameter we need to learn in this case is\u0012= [ B;b] while the loss function\n",
            "L(S(X;\u0012);Y ) is often the negative log-likelihood:\n",
            "L(S(X;\u0012);Y ) = \u0000logS(X;\u0012)[Y] = \u0000log\n",
            "[\n",
            "eaY\n",
            "∑K\n",
            "i=1 eai\n",
            "]\n",
            "(1.7)\n",
            "The classY\u0003 for a new instanceX is determined by the class with the highest\n",
            "score inS(X;\u0012):\n",
            "Y\u0003 = argmaxS(X;\u0012) (1.8)\n",
            "1.2.1.2 Support V ector Machines\n",
            "For simplicity, we assume that there are only two classes, denoted by -1 and 1,\n",
            "in Yin this case (i.e,Y= f\u00001;1g). The extension from the binary classification\n",
            "setting to the multiple class setting (i.e,jYj > 2) for Support Vector Machines\n",
            "(SVM) (Cristianini and Taylor,2000) can be done by considering multiple (jYj)\n",
            "binary classification problems. Each of such problem corresponds to a class in\n",
            "Ythat tries to predict whether an input instanceX belongs to that class or not\n",
            "(Cristianini and Taylor,2000).\n",
            "SVM considers each input instanceX as one point in thed-dimensional space\n",
            "defined by its vectorR(X). In this space, the goal of SVM is to find a hyperplane\n",
            "that divides the groups of training instancesXi with Yi = 1 and the groups of\n",
            "training instances Xi with Yi = \u00001. As there might be multiple satisfying hy-\n",
            "perplanes, SVM seeks to find two parallel hyperplanes that separate the instances\n",
            "in the training data D and have the largest distance between them. The final\n",
            "18\n",
            "  ID: bfd05432-1a4d-45a3-930b-5be56803f280\n",
            "--------------------\n",
            "Node 43:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "hyperplane of SVM is then the hyperplane that stands in the middle of the such\n",
            "two hyperplanes. This process translates into the score functionS(R(X)) that are\n",
            "parameterized by a weight vectorB (jBj= jR(X)j) and a biasb (\u0012= [ B;b]):\n",
            "S(R(X)) = BTR(X) \u0000b (1.9)\n",
            "The loss function in this case is the hinge loss function:\n",
            "L(S(X;\u0012);Y ) = max(0;1 \u0000Y(BTR(X) \u0000b)) (1.10)\n",
            "Finally, the decision rule for the prediction classY\u0003 is:\n",
            "Y\u0003 = sgn(S(R(X))) = sgn(BTR(X) \u0000b) (1.11)\n",
            "where sgn is the sign function so that sgn(x) = 1 if x\u00150 and sgn(x) = \u00001 if\n",
            "x< 0.\n",
            "We can replaceL(S(X;\u0012)) in Equation1.4 with that in Equation1.10 to obtain\n",
            "the optimization problem for thesoft-margin version of SVM. As this version of\n",
            "SVM aims at learning a hyperplane, it is only suitable for the problems where the\n",
            "two classes of data can be approximately separated well by hyperplanes (linearly\n",
            "separable).\n",
            "In order to deal with nonlinear separation, we need to incorporate the kernel\n",
            "trick into SVM (Cristianini and Taylor,2000). The general idea is to map the\n",
            "input instances from the original space forR(X) (called X) into another spaceV\n",
            "by some nonlinear transformation so that they become linearly separable inV. We\n",
            "can then apply our original SVM algorithm in the new space. In stead of explicitly\n",
            "19\n",
            "  ID: 828e9599-eb9d-491d-9364-a03da22eed3c\n",
            "--------------------\n",
            "Node 44:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "mapping the instances in the original space, the kernel trick suggests that we only\n",
            "need to build a kernel functionk : X\u0002X! R to compute a score for every pair\n",
            "of instances (X;X′) in X. The expectation is that this score will correspond to\n",
            "the dot product between the images ofX and X′ in the new spaceV, and that the\n",
            "kernel function can implicitly capture the nonlinear transformation. Consequently,\n",
            "we only need to replace all the dot product between two instancesX and X′ in the\n",
            "linear SVM algorithm7 with the kernel functionk(X;X′) so that we can convert\n",
            "the linear SVM algorithm into a nonlinear algorithm for classification. In general,\n",
            "the construction of the kernel function k is much easier than the formation of\n",
            "the direct mapping, leading to the popularity of the kernel methods for nonlinear\n",
            "classification in SVM.\n",
            "1.2.2 Representation Learning\n",
            "In representation learning, we aim at automatically inducing the representation\n",
            "function R(X) from data. The major tools for such autonomous feature learning\n",
            "is neural networks (NN) or deep learning. This section reviews feed-forward neural\n",
            "networks, the most basic network architecture for the deep learning models in this\n",
            "dissertation.\n",
            "1.2.2.1 F eed-forward Neural Networks\n",
            "The first important element in NN is the input instancesX that should be\n",
            "in the form of real-valued vectors, matrices or tensors. In information extraction\n",
            "7. The dot products will naturally appear when we form the dual problem to solve the\n",
            "optimization problem in Equation 1.4 for SVM.\n",
            "20\n",
            "  ID: 51c51853-c407-451e-9e1b-f6730544cb67\n",
            "--------------------\n",
            "Node 45:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "problems, the input instancesX are not readily presented in this format as they\n",
            "often involve sentences, sequences of discrete symbols for words. I will show how to\n",
            "convert the discrete instancesX in IE into the continuos tensors when we discuss\n",
            "the specific IE problems. For convenience, in this section, we will assume that the\n",
            "input instancesX are already given as real-valued column vectors.\n",
            "In order to learn R(X) for X, feed-forward neural networks use a stack of\n",
            "multiple hidden layers that connected to each other via linear and nonlinear trans-\n",
            "formations. Each hidden layer is expected to capture some representation at some\n",
            "abstract level of the inputX. The deeper the hidden layer is, the more abstract\n",
            "the representation is. Formally, let m be the number of hidden layers in some\n",
            "feed-forward network,Hi be the the hidden vector at thei-th layer (1 \u0014i \u0014m)\n",
            "and li be the dimensionality of the column vectorHi. The elements of the hidden\n",
            "vectors are called the hidden units in the literature. The computation ofHi and\n",
            "R(X) in the feed-forward neural network is then given by:\n",
            "Hi+1 = g(UT\n",
            "i+1Hi + Vi+1) for i= 0 to m (1.12)\n",
            "where H0 is the input vectorX, Hm+1 is the representation vectorR(X) we\n",
            "have learned (i.e,H0 = X and Hm+1 = R(X)), andUi 2Rli\u0002li+1 and Vi 2Rli+1 are\n",
            "the parameters to be optimized from data. In this case,l0 = dis the dimensionality\n",
            "of the inputX while lm+1 is the expected dimensionality ofR(X) that should be\n",
            "chosen in advance as a hyperparameter. Finally,g is a differential and nonlinear\n",
            "function whose application on a vector amounts to the applications on each element\n",
            "of that vector (i.e, element-wise):\n",
            "21\n",
            "  ID: 71b243fb-69e7-48d2-bca0-85791292b401\n",
            "--------------------\n",
            "Node 46:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "g([v1;v2;:::;v h]) = [ g(v1);g(v2);:::;g (vh)] (1.13)\n",
            "Some typical nonlinear functions for deep learning includesigmoid, tanh and\n",
            "rectifier:\n",
            "sigmoid(t) = 1\n",
            "1 + e\u0000t (1.14)\n",
            "tanh(t) = 1 \u0000e\u00002t\n",
            "1 + e\u00002t (1.15)\n",
            "rectifier(t) = max(0;t) (1.16)\n",
            "Agraphicalillustrationforfeed-forwardnaturalnetworksisshowninFigure 1.3.\n",
            "As we can see from the figure, the hidden units of thei-th layer are fully connected\n",
            "to those of the (i + 1) -th layer, forming a flow of information as presented in\n",
            "Equation 1.12. This direction of the information flow fromX to R(X) is called\n",
            "the forward pass to differentiate it from thebackward pass (fromR(X) to X) that\n",
            "updates the parameters later.\n",
            "1.2.2.2 T raining\n",
            "From our previous description, feed-forward neural networks learnR(X) for\n",
            "X by treating R(X) as a parameterized function ofX using the parameter\r =\n",
            "[U1;V1;U2;V2;:::;U m+1;Vm+1] and the network architecture in Figure1.3. In feed-\n",
            "forward neural networks, and more generally, in deep learning,\r will be optimized\n",
            "22\n",
            "  ID: e6c34535-bd9b-492e-afbc-f0db519a0878\n",
            "--------------------\n",
            "Node 47:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "H1 H2 Hm Hm+1 = R(X)H0 = X\n",
            "Figure 1.3: Feed-forward Neural Networks.\n",
            "jointly with the parameter\u0012 of the score functionS(R(X)) by solving Equation\n",
            "1.4 over the training dataD. Eventually, it helps to capture the underlying rep-\n",
            "resentation of data via optimization, potentially introducing useful features for\n",
            "the classification tasks for such data. Unfortunately, this joint optimization cre-\n",
            "ates much more complicated functions in Equation1.4 than those in the feature\n",
            "engineering method. In particular, the joint functions for \r and \u0012 in represen-\n",
            "tation learning are often non-convex and contain many local minima while their\n",
            "counterparts in feature engineering are convex and involve only global minimum.\n",
            "In addition, the joint optimization requires to search in a much larger space for\n",
            "the optimal values of parameters, making it a much more expensive computation\n",
            "(Goodfellow et al.,2016).\n",
            "Fortunately, it is now believed and demonstrated in practice that the local min-\n",
            "ima in representation learning often corresponds to the points with small values of\n",
            "the optimization functions in Equation1.4(Goodfellow et al.,2016). Consequently,\n",
            "23\n",
            "  ID: 9b8b283b-236f-4378-8913-62d75fa5798b\n",
            "--------------------\n",
            "Node 48:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "searching for a local minima often provides a practically good solution. Regarding\n",
            "the computation expense, the development ofGraphics Processing Units (GPU)\n",
            "allows us to complete the operations in representation learning (deep learning)\n",
            "much faster via the use of massively parallel graphics processors. This has signifi-\n",
            "cantly accelerated the training process and made it possible to run representation\n",
            "learning models recently.\n",
            "In addition to the use of GPU, deep learning models seek to reduce the com-\n",
            "putation time by solving the optimization problem in Equation1.4 approximately.\n",
            "In particular, rather than using the whole training dataD to evaluate the opti-\n",
            "mization function at a time, deep learning randomly initializes the parameters, and\n",
            "then iteratively consumes a small subset ofDand updates the parameters based on\n",
            "that subset. Typically, updates are estimated from the gradients of the objective\n",
            "function (gradient descent). This online learning method is known as stochastic\n",
            "gradient descent (SGD) (Goodfellow et al.,2016) and the small subsets ofD are\n",
            "called batches or minibatches. The size of a batch is often fixed during training.\n",
            "The SGD algorithm for learning parameters (training) is shown in Algorithm1:\n",
            "Algorithm 1: Stochastic Gradient Descent for Learning Parameters\n",
            "1 Initialize the parameters in representation learning = [ \r;\u0012] randomly\n",
            "while stopping criterion not met do\n",
            "2 Sample a mini batch ofJ training instances from the training datasetD:\n",
            "f(X1;Y 1);(X2;Y 2);:::; (XJ;Y J)g\n",
            "3 Compute the gradientG for the optimization function in Equation1.4\n",
            "over the sampled minibatch:G 1\n",
            "J∇ \n",
            "[∑J\n",
            "i=1 L(S(Xi; );Y i) + \u0015Ω( )\n",
            "]\n",
            "4 Compute update: ∆ = \u0000ϵ⊙G (element-wise multiplication of vectors)\n",
            "5 Apply update:    + ∆ \n",
            "6 end\n",
            "24\n",
            "  ID: 978b3aab-4fbe-4875-aa2d-e04ed7a47dfc\n",
            "--------------------\n",
            "Node 49:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "The parameterϵ is calledthe learning rate that determines the amount or the\n",
            "step we move in each update step. In SDG,ϵ is fixed during the training process\n",
            "and often chosen via some development dataset8. In practice, fixing the learning\n",
            "rate might not work very well as it might slow down the convergence of SGD (i.e,\n",
            "long training time) or render a poor approximation of the optimal values for the\n",
            "parameters  . There have been several efforts to update the learning rateϵduring\n",
            "the training process so that the convergence is achieved faster or the solution is\n",
            "more effective. These methods include AdaGrad (Duchi et al., 2011), AdaDelta\n",
            "(Zeiler, 2012) andAdam (Kingma and Ba,2014).\n",
            "1.2.2.3 Dropout\n",
            "Deep learning models with multiple hidden layers can learn complicated rela-\n",
            "tionships between the inputX and the class outputY via the representation and\n",
            "score functions R(X) and S(R(X)). However, they tend to overfit the training\n",
            "data if such data only has a limited size. The consequence is the poor performance\n",
            "on real test data as the relationships induced from the small training dataset are\n",
            "likely due to the sampling noise. There have been many approaches to address\n",
            "the overfitting problem in machine learning. One of the common methods is to\n",
            "introduce parameter penalties into the objective function as in Equation1.4. In\n",
            "8. Development dataset is similar to the training dataset D as both of them include a\n",
            "set of input instances X and their corresponding classes Y . However, development dataset\n",
            "is disjoint with the the training dataset. The former is used to evaluate the effectiveness of\n",
            "the hyperparameters in the models (i.e, number of hidden layers m, and their dimensionality\n",
            "li, regularizer weight \u0015, etc) while the latter is employed to estimate the parameters in the\n",
            "representation and score functions (i.e R(X) and S(R(X))). The hyperparameters are typically\n",
            "selected by taking the values the produces the highest model performance on the development\n",
            "dataset.\n",
            "25\n",
            "  ID: ba0a287e-d931-4cba-adaf-541a5ccb339a\n",
            "--------------------\n",
            "Node 50:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "deep learning, a more common method to overcome overfitting isdropout that ran-\n",
            "domly drops (i.e, sets to zero) units along with their connections in the network\n",
            "architecture during training. The key idea is to prevent the co-adaptation among\n",
            "the units (Srivastava et al.,2014). Formally, consider the hidden vector Hi in\n",
            "the feed-forward neural network above. In order to inject dropout intoHi, we\n",
            "first sample a binary vectorri of the same size withHi (i.e, jrij= jHij) from the\n",
            "Bernoulli distribution with the meanp:\n",
            "ri \u0018Bernoulli(p) (1.17)\n",
            "This is then combined withHi to generate a new hidden vectoreHi:\n",
            "eHi = ri ⊙Hi (1.18)\n",
            "where ⊙is the element-wise multiplication operation.\n",
            "For dropout, Hi is replaced by eHi in all the following computations in the\n",
            "neural network models. The decision of which hidden layers should be dropped\n",
            "depends on network architectures and the target problems (Zaremba et al.,2014).\n",
            "In information extraction, we often find that dropping the representation vector\n",
            "(i.e, the last layerR(X) in the network architectures) produces good performance.\n",
            "1.3 Prior W ork\n",
            "In this section, I review the most representative work for information extraction\n",
            "that are related to the work in this dissertation. I will only focus on the feature\n",
            "26\n",
            "  ID: 661fa4ef-2d07-4b86-b87f-8993d9e779e1\n",
            "--------------------\n",
            "Node 51:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "engineering approach in this section and leave the related work on representation\n",
            "learning for discussion in the later chapters.\n",
            "Information extraction is an active area of research in natural language pro-\n",
            "cessing in the last decades. A large portion of the previous research effort has\n",
            "been spent on developing effective feature sets for different tasks of IE, i.e, named\n",
            "entity recognition, relation extraction, event extraction etc. For instance, the in-\n",
            "vestigated features for named entity recognition and mention detection include\n",
            "the orthographic features, gazetter features, cache features, word clusters, word\n",
            "embeddings etc (Ando and Zhang,2005; Bikel et al.,1997; Borthwick et al.,1997;\n",
            "Cherry and Guo,2015; Florian et al.,2003; Florian et al.,2004; Florian et al.,2006,\n",
            "2010; Lin and Wu,2009; Miller et al.,2004; Passos et al.,2014; Ratinov and Roth,\n",
            "2009; Ritter et al.,2011; Sam et al.,2011; Sang and Meulder,2003; Suzuki and\n",
            "Isozaki, 2008; Turian et al.,2010). The typical machine learning models for such\n",
            "sequential labeling tasks are Hidden Markov Models (HMMs), Maximum Entropy\n",
            "Markov Models (MEMMs) or Conditional Random Fields (CRFs) (Lafferty et al.,\n",
            "2001). For relation extraction, it is very common to use the Maximum Entropy\n",
            "(MaxEnt) model or SVM (Cristianini and Taylor,2000) to learn the weights for\n",
            "various hand-designed features, including the entity features, syntactic features,\n",
            "and semantic features (Chan and Roth,2010; Grishman et al.,2005; Jiang and\n",
            "Zhai, 2007a; Kambhatla,2004; Nguyen et al.,2014b; Sun et al.,2011; Zhou et al.,\n",
            "2005). This is also the main approach for other IE tasks such as event extraction\n",
            "(Ahn, 2006; Grishman et al.,2005; Gupta and Ji,2009; Hong et al.,2011; Huang\n",
            "and Riloff,2012; Ji and\n",
            "  ID: a3897ffe-bd78-440f-817e-da087d141076\n",
            "--------------------\n",
            "Node 52:\n",
            "  Text: Hong et al.,2011; Huang\n",
            "and Riloff,2012; Ji and Grishman,2008; Li et al.,2015; Liao and Grishman,2010a,\n",
            "27\n",
            "  ID: 762446b7-8b98-4c06-9ed9-67890b08ee5b\n",
            "--------------------\n",
            "Node 53:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "2011; McClosky et al.,2011; Patwardhan and Rilof,2009), entity linking (Bunescu\n",
            "and Pasca,2006; Cassidy et al.,2011; Ji and Grishman,2011; Mendes et al.,2011;\n",
            "Milne and Witten,2008; Shen et al.,2014b; Zheng et al.,2010) or coreference res-\n",
            "olution (Clark and Manning,2016; Durrett and Klein,2013; Raghunathan et al.,\n",
            "2010; Wiseman et al.,2015). In addition, kernel tricks are also applied in SVM for\n",
            "information extraction to avoid explicit feature engineering. For example, string\n",
            "kernels (Bunescu and Mooney, 2005b) and tree kernels (Bunescu and Mooney,\n",
            "2005a; Nguyen et al.,2009; Plank and Moschitti,2013; Qian et al.,2008; Zelenko\n",
            "et al.,2003; Zhang et al.,2006) are the powerful techniques for relation extraction.\n",
            "Another important line of research in information extraction is joint modeling\n",
            "that attempts to perform several IE tasks simultaneously (joint inference). The\n",
            "rationale is to capture the inter-dependencies among these tasks to improve the\n",
            "performance of the individual tasks. In the literature, the inter-dependences are\n",
            "often exploited between trigger prediction and argument prediction in event ex-\n",
            "traction (Li et al.,2013b), entity mention detection and relation extraction (Kate\n",
            "and Mooney,2010; Li and Ji,2014a; Li et al.,2014b; Miwa et al.,2014; Roth and\n",
            "Yih, 2004; Roth and Yih,2007), and among name tagging, coreference resolution\n",
            "and relation extraction (Ji and Grishman,2005; Ji et al.,2005; Singh et al.,2013).\n",
            "All of these work involve some levels of feature engineering that are fed into some\n",
            "structured prediction models (i.e, structured perceptron, graphical models etc) to\n",
            "perform the tasks.\n",
            "Sofar, wehavemainlydiscussedtheIEworkinthesupervisedlearningparadigm\n",
            "that assumes the availability of\n",
            "  ID: bfc0c82f-a7c7-41dc-8499-329af5cc1f0f\n",
            "--------------------\n",
            "Node 54:\n",
            "  Text: assumes the availability of a vast amount of training data (labeled data). This\n",
            "28\n",
            "  ID: d3da5d57-4657-4111-9ba3-c2e69fd0ba40\n",
            "--------------------\n",
            "Node 55:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "assumption does not hold sometime in reality as the training data for some tasks\n",
            "and domains might be very expensive and difficult to obtain. How can we relax\n",
            "this assumption so we can build good models for IE without requiring much train-\n",
            "ing data? This is the key target of semi-supervised learning that employs large\n",
            "amounts of unlabeled data in addition to limited amounts of labeled data to build\n",
            "effective IE systems. The semi-supervised models have been applied to various\n",
            "IE tasks, including named entity recognition via co-training (Collins and Singer,\n",
            "1999; Yangarber et al.,2002), relation extraction (Agichtein and Gravano,2000;\n",
            "Brin, 1998), and event extraction via boostrapting (Liao and Grishman,2010a;\n",
            "Riloff, 1996; Stevenson and Greenwood,2005; Yangarber et al.,2000; Yangarber,\n",
            "2003). In order to go further, unsupervised learning aims at removing the need\n",
            "of training data and only relying on unlabeled data to create IE systems. The\n",
            "main technologies in such unsupervised approach are unsupervised clustering or\n",
            "topic modeling methods to identify the major patterns for IE (Hasegawa et al.,\n",
            "2004; Min et al.,2012; Shinyama and Sekine,2006; Yao et al.,2011; Yates and\n",
            "Etzioni, 2007). In addition, distant supervision is an alternative to avoid training\n",
            "dataset. It aligns the facts in some knowledge bases (i.e, Freebase, YAGO, etc)\n",
            "with large amounts of unlabeled text to automatically generate much training data\n",
            "for IE models. Distant supervision is especially successful in relation extraction\n",
            "that has been one of the main breakthroughs in IE over the last decades (Craven\n",
            "and Kumlien, 1999; Hoffmann et al., 2011; Mintz et al., 2009; Surdeanu et al.,\n",
            "2012). Finally, there have been also studies in active learning that try to request\n",
            "classes or labels of some input instances from users and use these labeled data to\n",
            "29\n",
            "  ID: 89d2f056-7657-4d3f-b8db-505890aa40af\n",
            "--------------------\n",
            "Node 56:\n",
            "  Text: CHAPTER 1. INTRODUCTION\n",
            "guide the learning process. The goal of active learning is to minimize the number\n",
            "of requests from users so an effective IE system can be built quickly without much\n",
            "annotation effort (Becker et al.,2005; Fu and Grishman,2013; Sun and Grishman,\n",
            "2012).\n",
            "Semi-supervised learning, distant supervision and unsupervised learning are\n",
            "beyond the scope of this work that focuses on supervised learning and deep learning\n",
            "for information extraction. Exploring such learning paradigm for IE with deep\n",
            "learning is a very promising research area in the future.\n",
            "1.4 Outline of Thesis\n",
            "The rest of this dissertation is organized as follows: Chapter 1 introduces the\n",
            "useof wordembeddings for domainadaptation of relationextraction. Chapters 3, 4\n",
            "and5developdeeplearningmodelsforentitymentiondetection, relationextraction\n",
            "and event detection respectively. Chapter 6 proposes memory-augmented neural\n",
            "networks for information extraction and demonstrate their applications on event\n",
            "extraction and entity linking. I conclude this dissertation and discuss some future\n",
            "work in Chapter 7.\n",
            "30\n",
            "  ID: 89119e97-980e-4f1c-827f-1ea23a35b854\n",
            "--------------------\n",
            "Node 57:\n",
            "  Text: Chapter 2\n",
            "W ord Embeddings for Domain\n",
            "Adaptation of Relation Extraction\n",
            "The previous research on supervised learning has mainly approached relation\n",
            "extraction (RE) in two directions: (Boschee et al.,2005; Chan and Roth,2010;\n",
            "Grishman et al.,2005; Jiang and Zhai,2007a; Kambhatla,2004; Sun et al.,2011;\n",
            "Zhou et al.,2005) and kernel-based (Bunescu and Mooney,2005a,b; Nguyen et al.,\n",
            "2009; Qian et al.,2008; Zelenko et al.,2003; Zhang et al.,2006). Both approaches\n",
            "attemptto improveperformance byenrichingthe RE representationsfrom multiple\n",
            "sentence analyses and knowledge resources. The fundamental assumption of the\n",
            "supervised systems in such research is that the training data and the data to which\n",
            "the systems are applied are sampled independently and identically from the same\n",
            "distribution. When there is a mismatch between the data distributions (domain\n",
            "shifts), the RE performance of these systems tends to degrade dramatically (Plank\n",
            "and Moschitti, 2013). This is where we need to resort to domain adaptation\n",
            "31\n",
            "  ID: 60fb73dc-70fc-41f3-9f3b-629a21531dfd\n",
            "--------------------\n",
            "Node 58:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "techniques (DA) to adapt a model trained on one domain (the source domain)\n",
            "into a new model which can perform well on new domains (the target domains).\n",
            "To make it clear, we assume the same relation classes (types), thus the same\n",
            "extraction task in both source and target domains but a shift in the underlying\n",
            "data distributions.\n",
            "This chapters introduce methods to incorporate word embeddings into models\n",
            "as domain adaptation techniques for RE. We will examine both approaches (i.e,\n",
            "feature-based and kernel-based) to demonstrate the benefits of word embeddings\n",
            "for DA of RE. Note that we actually design features for DA of RE based on word\n",
            "embeddings in this chapter. However, as word embeddings are automatically in-\n",
            "duced by deep learning models on some unlabeled corpus, we would still consider\n",
            "the techniques in this chapter as semi-automatically learning feature representa-\n",
            "tions from data. The works in this chapter are published in (Nguyen and Grishman,\n",
            "2014a) and (Nguyen et al.,2015c).\n",
            "2.1 The F eature-based Approach\n",
            "The consequences of linguistic variation between training and testing data on\n",
            "NLP tools (domain shifts) have been studied extensively in the last couple of years\n",
            "for various NLP tasks such as Part-of-Speech tagging (Blitzer et al.,2006; Huang\n",
            "and Yates,2010; Schnabel and Schütze,2014), named entity recognition (Daume,\n",
            "2007)andsentimentanalysis(Blitzeretal., 2007, 2011; Daume,2007; Daumeetal.,\n",
            "2010), etc. Unfortunately, there is very little work on domain adaptation for RE.\n",
            "TheonlystudyexplicitlytargetingthisproblembeforethecurrentworkisbyPlank\n",
            "32\n",
            "  ID: 6615cd15-1fe9-43e3-9893-d8550201183a\n",
            "--------------------\n",
            "Node 59:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "and Moschitti,2013 who find that the out-of-domain performance of kernel-based\n",
            "relation extractors can be improved by embedding semantic similarity information\n",
            "generated from word clustering and latent semantic analysis (LSA) into syntactic\n",
            "tree kernels. Although this idea is interesting, it suffers from two major limitations:\n",
            "1. It does not incorporate word cluster information at different levels of gran-\n",
            "ularity. In fact, Plank and Moschitti,2013 only use the 10-bit cluster prefix in\n",
            "their study. We will demonstrate later that the adaptability of relation extrac-\n",
            "tors can benefit significantly from the addition of word cluster features at various\n",
            "granularities.\n",
            "2. It is unclear if this approach can encode real-valued features of words (such\n",
            "as word embeddings (Collobert and Westion,2008; Mnih and Hinton,2007)) into\n",
            "the syntactic trees effectively. As the real-valued features are able to capture latent\n",
            "yet useful properties of words, the augmentation of lexical terms with these features\n",
            "is desirable to provide a more general representation, potentially helping relation\n",
            "extractors perform more robustly across domains.\n",
            "In this work, we propose to avoid these limitations by applying a feature-based\n",
            "approachforREwhichallowsustointegratevariouswordfeaturesofgeneralization\n",
            "into a single system more naturally and effectively.\n",
            "The application of word representations such as word clusters in domain adap-\n",
            "tation of RE (Plank and Moschitti,2013) is motivated by its successes in semi-\n",
            "supervised methods (Chan and Roth,2010; Sun et al.,2011) where word represen-\n",
            "tations help to reduce data-sparseness of lexical information in the training data.\n",
            "In DA terms, since the vocabularies of the source and target domains are usually\n",
            "33\n",
            "  ID: c7ddd690-bc4d-4c91-891a-ce4a657af386\n",
            "--------------------\n",
            "Node 60:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "different, word representations would mitigate the lexical sparsity by providing\n",
            "general features of words that are shared across domains, hence bridge the gap\n",
            "between domains. The underlying hypothesis here is that the absence of lexical\n",
            "target-domain features in the source domain can be compensated by these general\n",
            "features to improve RE performance on the target domains.\n",
            "We extend this motivation by further introducing word embeddings Bengio et\n",
            "al., 2003; Collobert and Westion,2008; Mnih and Hinton,2007; Turian et al.,2010\n",
            "into feature-based methods to adapt RE systems to new domains. Word embed-\n",
            "ding is another type of word representations assisting generalization of terms that\n",
            "do not appear in the training data, but are similar to those in training data with\n",
            "respect to their distributed representations (Bengio et al.,2003). We explore the\n",
            "embedding-based features in a principled way and demonstrate that word embed-\n",
            "ding itself is also an effective representation for domain adaptation of RE. More\n",
            "importantly, we show empirically that word embeddings and word clusters capture\n",
            "different information and their combination would further improve the adaptability\n",
            "of relation extractors.\n",
            "2.1.1 Regularization\n",
            "Giventhe moregeneral representationsprovidedbywordrepresentationsabove,\n",
            "how can we learn a relation extractor from the labeled source domain data that\n",
            "generalizes well to new domains? In traditional machine learning where the chal-\n",
            "lenge is to utilize the training data to make predictions on unseen data points\n",
            "(generated from the same distribution as the training data), the classifier with a\n",
            "34\n",
            "  ID: c7f38101-c071-4c38-ad27-875125bf2a6a\n",
            "--------------------\n",
            "Node 61:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "good generalization performance is the one that not only fits the training data, but\n",
            "also avoids ovefitting over it. This is often obtained via regularization methods\n",
            "to penalize complexity of classifiers. Exploiting the shared interest in generaliza-\n",
            "tion performance with traditional machine learning, in domain adaptation for RE,\n",
            "we would prefer the relation extractor that fits the source domain data, but also\n",
            "circumvents the overfitting problem over this source domain1 so that it could gen-\n",
            "eralize well on new domains. Eventually, regularization methods can be considered\n",
            "naturally as a simple yet general technique to cope with DA problems.\n",
            "To our knowledge, there have not been any studies assessing the impact of\n",
            "regularization on RE in general and on domain adaptation of RE specifically. It is\n",
            "also worth pointing out that some studies in this area do not apply regularization in\n",
            "their models. For example, Sun et al.,2011 use the MaxEnt package of OpenNLP2\n",
            "which did not support regularization.\n",
            "Following Plank and Moschitti,2013, we assume that we only have labeled data\n",
            "in a single source domain but no labeled as well as unlabeled target data. Moreover,\n",
            "weconsiderthesingle-systemDAsettingwhereweconstructasinglesystemableto\n",
            "work robustly with different but related domains (multiple target domains). This\n",
            "setting differs from most previous studies (Blitzer et al.,2006) on DA which have\n",
            "attempted to design a specialized system for every specific target domain. In our\n",
            "view, although this setting is more challenging, it is more practical for RE. In fact,\n",
            "this setting can benefit considerably from our general approach of applying word\n",
            "representations and regularization. Finally, due to this setting, the best way to set\n",
            "1. domain overfitting (Jiang and Zhai, 2007c)\n",
            "2. http://opennlp.apache.org\n",
            "35\n",
            "  ID: da29e97b-77e0-462b-8044-e400b25fed3f\n",
            "--------------------\n",
            "Node 62:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "up the regularization parameter is to impose the same regularization parameter on\n",
            "every feature rather than a skewed regularization (Jiang and Zhai,2007c).\n",
            "2.1.2 W ord Representations\n",
            "Word representations are high-dimensional vectors that are associated with\n",
            "words in an unlabeled corpus. In this work, we consider two types of word repre-\n",
            "sentations and use them as additional features in our DA system, namely Brown\n",
            "word clustering (Brown et al.,1992) and word embeddings. While word clusters\n",
            "can be recognized as an one-hot vector representation over a small vocabulary,\n",
            "word embeddings are dense, low-dimensional, and real-valued vectors (distributed\n",
            "representations). Each dimension of the word embeddings expresses a latent fea-\n",
            "ture of the words, hopefully reflecting useful semantic and syntactic regularities\n",
            "(Turian et al., 2010). We investigate word embeddings induced by two typical\n",
            "language models: Collobert and Weston (2008) embeddings (C&W) (Collobert\n",
            "and Westion,2008; Turian et al.,2010) and Hierarchical log-bilinear embeddings\n",
            "(HLBL) (Mnih and Hinton,2007, 2008; Turian et al.,2010).\n",
            "2.1.3 F eature Set\n",
            "2.1.3.1 Baseline F eature Set\n",
            "Sun et al.,2011 utilize the full feature set from (Zhou et al.,2005) plus some\n",
            "additional features and achieve the state-of-the-art feature-based RE system. Un-\n",
            "fortunately, this feature set includes thehuman-annotated (gold-standard) infor-\n",
            "mation on entity and mention types which is often missing or noisy in reality\n",
            "36\n",
            "  ID: 08e6915b-4f19-41d0-beda-23ec8d4c4f6b\n",
            "--------------------\n",
            "Node 63:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "(Plank and Moschitti, 2013). This issue becomes more serious in our setting of\n",
            "single-system DA where we have a single source domain with multiple dissimilar\n",
            "target domains and an automatic system able to recognize entity and mention\n",
            "types very well in different domains may not be available. Therefore, following\n",
            "the settings of (Plank and Moschitti,2013), we will only assume entity boundaries\n",
            "and not rely on the gold standard information in the experiments. We apply the\n",
            "same feature set as (Sun et al.,2011) but remove the entity and mention type in-\n",
            "formation3. Clearly, evaluating the system on predicted mentions (Giuliano et al.,\n",
            "2007) is also an important topic but out of the scope of this work.\n",
            "2.1.3.2 Lexical F eature Augmentation\n",
            "While Sun et al.,2011 show that adding word clusters to the heads of the two\n",
            "mentions is the most effective way to improve the generalization accuracy, the\n",
            "right lexical features into which word embeddings should be introduced to obtain\n",
            "the best adaptability improvement are unexplored. Also, which dimensionality of\n",
            "which word embedding should we use with which lexical features? In order to\n",
            "answer these questions, following (Sun et al.,2011), we first group lexical features\n",
            "into 4 groups and rank their importance based on linguistic intuition and illustra-\n",
            "tions of the contributions of different lexical features from various feature-based\n",
            "RE systems. After that, we evaluate the effectiveness of these lexical feature groups\n",
            "for word embedding augmentation individually and incrementally according to the\n",
            "3. W e have the same observation as (Plank and Moschitti,2013) that when the gold-standard\n",
            "labels are used, the impact of word representations is limited since the gold-standard information\n",
            "seems to dominate. However, whenever the gold labels are not available or inaccurate, the word\n",
            "representations would be useful for improving adaptability performance. Moreover, in all the\n",
            "cases, regularization methods are still effective for domain adaptation of RE.\n",
            "37\n",
            "  ID: 534466f7-e6b4-4c23-a9e0-07b1befbfca1\n",
            "--------------------\n",
            "Node 64:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "rank of importance. For each of these group combinations, we assess the system\n",
            "performance with different numbers of dimensions for both C&W and HLBL word\n",
            "embeddings. Let M1 and M2 be the first and second entity mentions in the relation\n",
            "mention. Table2.1 describes the lexical feature groups.\n",
            "Rank Group Lexical F eatures\n",
            "1 HM HM1 (head of M1)\n",
            "HM2 (head of M2)\n",
            "2 BagWM WM1 (words in M1)\n",
            "WM2 (words in M2)\n",
            "3 HC heads of chunks in context\n",
            "4 BagWC words of context\n",
            "Table 2.1:Lexical feature groups ordered by importance.\n",
            "2.1.4 Experiments\n",
            "2.1.4.1 T ools and Data\n",
            "Our relation extraction system is hierarchical and includes a relation detector\n",
            "as well as a relation classifier (Bunescu and Mooney,2005b; Sun et al., 2011).\n",
            "We use maximum entropy (MaxEnt) in the MALLET4 toolkit as our machine\n",
            "learning tool. For Brown word clusters, we directly apply the clustering trained\n",
            "by (Plank and Moschitti,2013) to facilitate system comparison later. We evaluate\n",
            "C&W word embeddings with 25, 50 and 100 dimensions as well as HLBL word\n",
            "embeddings with 50 and 100 dimensions that are introduced in (Turian et al.,\n",
            "2010) and can be downloaded here5. The fact that we utilize the large, general\n",
            "4. http://mallet.cs.umass.edu/\n",
            "5. http://metaoptimize.com/projects/wordreprs\n",
            "38\n",
            "  ID: df885a39-7bff-45fc-96fb-a492d568e566\n",
            "--------------------\n",
            "Node 65:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "and unbiased resources generated from the previous works for evaluation not only\n",
            "helps to verify the effectiveness of the resources across different tasks and settings\n",
            "but also supports our setting of single-system DA.\n",
            "We use the ACE 2005 corpus for DA experiments (as in (Plank and Moschitti,\n",
            "2013)). It involves 6 relation types and 6 domains: broadcast news (bn), newswire\n",
            "(nw), broadcast conversation (bc), telephone conversation (cts), weblogs (wl) and\n",
            "usenet (un). We follow the standard practices on ACE (Plank and Moschitti,2013)\n",
            "and usenews (the union ofbn and nw) as the source domain andbc, cts and wl as\n",
            "our target domains. We take half ofbc as the only target development set, and use\n",
            "the remaining data and domains for testing purposes (as they are small already).\n",
            "As noted in (Plank and Moschitti,2013), the distributions of relations as well as\n",
            "the vocabularies of the domains are quite different.\n",
            "2.1.4.2 Evaluation of W ord Embedding F eatures\n",
            "We investigate the effectiveness of word embeddings on lexical features by fol-\n",
            "lowing the procedure described in Section 2.1.3.2. We test our system on two\n",
            "scenarios: In-domain: the system is trained and evaluated on the source domain\n",
            "(bn+nw, 5-fold cross validation); Out-of-domain: the system is trained on the source\n",
            "domain and evaluated on the target development set ofbc (bc dev). Table 2.2\n",
            "presents the F measures of this experiment6 (The cells in bold are the best results,\n",
            "and the suffixED in lexical group names is to indicate the embedding features).\n",
            "From the table, we find that for C&W and HLBL embeddings of 50 and 100\n",
            "6. All the in-domain improvement in rows 2, 6, 7 of T able 2.2 are significant at confidence\n",
            "levels \u001595%.\n",
            "39\n",
            "  ID: f205149f-3617-4023-be50-be2b1fd1cce4\n",
            "--------------------\n",
            "Node 66:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "In-domain (bn+nw) Out-of-domain (bc development set)System C&W,25C&W,50C&W,100HLBL,50HLBL,100C&W,25C&W,50C&W,100HLBL,50HLBL,1001Baseline 51.4 51.4 51.4 51.4 51.4 49.0 49.0 49.0 49.0 49.021+HM_ED54.0(+2.6)54.1(+2.7)55.7(+4.3)53.7(+2.3)55.2(+3.8)51.5(+2.5)52.7(+3.7)52.5(+3.5)50.2(+1.2)50.6(+1.6)31+BagWM_ED52.3(+0.9)50.9(-0.5)51.5(+0.1)51.8(+0.4)52.5(+1.1)48.5(-0.5)48.9(-0.1)48.6(-0.4)48.7(-0.3)49.0(+0.0)41+HC_ED51.3(-0.1)50.9(-0.5)48.3(-3.1)50.8(-0.6)49.8(-1.6)44.9(-4.1)45.8(-3.2)45.8(-3.2)48.7(-0.3)47.3(-1.7)51+BagWC_ED51.5(+0.1)50.8(-0.6)49.\n",
            "  ID: 437eef39-1d9f-4279-bc71-f58fbefca262\n",
            "--------------------\n",
            "Node 67:\n",
            "  Text: 5(+0.1)50.8(-0.6)49.5(-1.9)51.4(+0.0)50.3(-1.1)48.3(-0.7)46.3(-2.7)44.0(-5.0)46.6(-2.4)44.8(-4.2)62+BagWM_ED54.3(+2.9)53.2(+1.8)53.2(+1.8)54.0(+2.6)53.8(+2.4)52.5(+3.5)51.4(+2.4)50.6(+1.6)50.0(+1.0)48.6(-0.4)76+HC_ED53.4(+2.0)52.3(+0.9)52.7(+1.3)54.2(+2.8)53.1(+1.7)50.5(+1.5)50.9(+1.9)48.4(-0.6)50.0(+1.0)48.9(-0.1)87+BagWC_ED53.4(+2.0)52.2(+0.8)50.8(-0.6)53.5(+2.1)53.6(+2.2)49.2(+0.2)50.7(+1.7)49.2(+0.2)47.9(-1.1)49.5(+0.5)\n",
            "Table 2.2:In-domain and Out-of-domain performance for different embedding fea-\n",
            "tures.\n",
            "dimensions, the most effective way to introduce word embeddings is to add embed-\n",
            "dings to the heads of the two mentions (row 2; both in-domain and\n",
            "  ID: fe5853ff-f80b-4e7a-92dd-7217fc89f9b6\n",
            "--------------------\n",
            "Node 68:\n",
            "  Text: add embed-\n",
            "dings to the heads of the two mentions (row 2; both in-domain and out-of-domain)\n",
            "although it is less pronounced for HLBL embedding with 50 dimensions. Inter-\n",
            "estingly, for C&W embedding with 25 dimensions, adding the embedding to both\n",
            "heads and words of the two mentions (row 6) performs the best for both in-domain\n",
            "and out-of-domain scenarios. This is new compared to the word cluster features\n",
            "where the heads of the two mentions are always the best places for augmentation\n",
            "(Sun et al., 2011). It suggests that a suitable amount of embeddings for words\n",
            "in the mentions might be useful for the augmentation of the heads and inspires\n",
            "further exploration. Introducing embeddings to words of mentions alone has mild\n",
            "impact while it is generally a bad idea to augment chunk heads and words in the\n",
            "contexts.\n",
            "Comparing C&W and HLBL embeddings is somehow more complicated. For\n",
            "both in-domain and out-of-domain settings with different numbers of dimensions,\n",
            "C&W embedding outperforms HLBL embedding when only the heads of the men-\n",
            "tions are augmented while the degree of negative impact of HLBL embedding on\n",
            "chunk heads as well as context words seems less serious than C&W’s. Regarding\n",
            "40\n",
            "  ID: e95d6877-a1cb-4767-a7be-8d0219e0fde9\n",
            "--------------------\n",
            "Node 69:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "the incremental addition of features (rows 6, 7, 8), C&W is better for the out-\n",
            "of-domain performance when 50 dimensions are used, whereas HLBL (with both\n",
            "50 and 100 dimensions) is more effective for the in-domain setting. For the next\n",
            "experiments, we will apply the C&W embedding of 50 dimensions to the heads of\n",
            "the mentions for its best out-of-domain performance.\n",
            "2.1.4.3 Domain Adaptation Experiments with W ord Embeddings\n",
            "This section examines the effectiveness of word representations for RE across\n",
            "domains. We evaluate word cluster and embedding (denoted by ED) features by\n",
            "adding them individually as well as simultaneously into the baseline feature set.\n",
            "For word clusters, we experiment with two possibilities: (i) only using a single\n",
            "prefix length of 10 (as Plank and Moschitti,2013 did) (denoted by WC10) and\n",
            "(ii) applying multiple prefix lengths of 4, 6, 8, 10 together with the full string7\n",
            "(denoted by WC). Table2.3 presents the system performance (F measures) for\n",
            "both in-domain and out-of-domain settings8.\n",
            "System In-domain bc cts wl\n",
            "Baseline(B) 51.4 49.7 41.5 36.6\n",
            "B+WC10 52.3(+0.9) 50.8(+1.1) 45.7(+4.2) 39.6(+3)\n",
            "B+WC 53.7(+2.3) 52.8(+3.1) 46.8(+5.3) 41.7(+5.1)\n",
            "B+ED 54.1(+2.7) 52.4(+2.7) 46.2(+4.7) 42.5(+5.9)\n",
            "B+WC+ED 55.5(+4.1) 53.8(+4.1) 47.4(+5.9) 44.7(+8.1)\n",
            "Table 2.3:Domain adaptation results with word representations.\n",
            "The key observations from the table are:\n",
            "7. This set of\n",
            "  ID: 826c8a3c-2124-4304-bb9d-c2994a410cc9\n",
            "--------------------\n",
            "Node 70:\n",
            "  Text: adaptation results with word representations.\n",
            "The key observations from the table are:\n",
            "7. This set of prefix lengths is shown to produce the best results experimentally .\n",
            "8. All the improvements over the baseline in T able 2.3 are significant at confidence level \u0015\n",
            "95%.\n",
            "41\n",
            "  ID: 65da4b0e-3b30-460e-b95b-96a83eb7beaf\n",
            "--------------------\n",
            "Node 71:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "(i): The baseline system achieves a performance of 51.4% within its own domain\n",
            "while the performance on target domainsbc, cts, wl drops to 49.7%, 41.5% and\n",
            "36.6% respectively. Our baseline performance is worse than that of (Plank and\n",
            "Moschitti, 2013) only on the target domain cts and better in the other cases.\n",
            "This might be explained by the difference between our baseline feature set and\n",
            "the feature set underlying their kernel-based system. However, the performance\n",
            "order across domains of the two baselines are the same. Besides, the baseline\n",
            "performance is improved over all target domains when the system is enriched with\n",
            "word cluster features of the 10 prefix length only (row 2).\n",
            "(ii): Over all the target domains, the performance of the system augmented\n",
            "with word cluster features of various granularities (row 3) is superior to that when\n",
            "only cluster features for the prefix length 10 are added (row 2). This is significant\n",
            "(at confidence level\u001595%) for domains bc and wl and verifies our assumption\n",
            "that various granularities for word cluster features are more effective than a single\n",
            "granularity for domain adaptation of RE.\n",
            "(iii): Row 4 shows that word embedding itself is also very useful for domain\n",
            "adaptation in RE since it improves the baseline system for all the target domains.\n",
            "(iv): In row 5, we see that the addition of both word cluster and word embed-\n",
            "ding features improves the system further and results in the best performance over\n",
            "all target domains (this is significant with confidence level\u001595% in domainsbc\n",
            "and wl). The result suggests that word embeddings seem to capture different infor-\n",
            "mation from word clusters and their combination would be effective to generalize\n",
            "relation extractors across domains. However, in domain cts, the improvement\n",
            "42\n",
            "  ID: 17bc0696-304d-4a84-a300-0cd999290074\n",
            "--------------------\n",
            "Node 72:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "that word embeddings provide for word clusters is modest. This is because the\n",
            "RCV1 corpus used to induce the word embeddings (Turian et al.,2010) does not\n",
            "cover spoken language words incts very well.\n",
            "(v): Finally, the in-domain performance is also improved consistently demon-\n",
            "strating the robustness of word representations (Plank and Moschitti,2013).\n",
            "2.1.4.4 Domain Adaptation Experiments with Regularization\n",
            "All the experiments we have conducted so far do not apply regularization for\n",
            "training (like some previous research on RE (Sun et al.,2011)). In this section,\n",
            "in order to evaluate the effect of regularization on the generalization capacity of\n",
            "relation extractors across domains, we replicate all the experiments in Section\n",
            "2.1.4.3 but apply regularization when relation extractors are trained9. Table 2.4\n",
            "presents the results10.\n",
            "System In-domain bc cts wl\n",
            "Baseline(B) 56.2 55.5 48.7 42.2\n",
            "B+WC10 57.5(+1.3) 57.3(+1.8) 52.3(+3.6) 45.0(+2.8)\n",
            "B+WC 58.9(+2.7) 58.4(+2.9) 52.8(+4.1) 47.3(+5.1)\n",
            "B+ED 58.9(+2.7) 59.5(+4.0) 52.6(+3.9) 48.6(+6.4)\n",
            "B+WC+ED 59.4(+3.2) 59.8(+4.3) 52.9(+4.2) 49.7(+7.5)\n",
            "Table 2.4:Domain adaptation results with regularization.\n",
            "For this experiment, every statement in (ii), (iii), (iv) and (v) of Section2.1.4.3\n",
            "also holds. More importantly, the performance in every cell of Table2.4 is sig-\n",
            "9. W e use a L2 regularizer with the regularization parameter of 0.5 for its best\n",
            "  ID: 8426f70e-fd10-4ed2-bf2f-ebf5418348d3\n",
            "--------------------\n",
            "Node 73:\n",
            "  Text: W e use a L2 regularizer with the regularization parameter of 0.5 for its best experimental\n",
            "results.\n",
            "10. All the improvements over the baseline in T able2.4 are significant at confidence level \u0015\n",
            "95%.\n",
            "43\n",
            "  ID: e2321e79-8dc9-4420-8689-fcb7b553f3bd\n",
            "--------------------\n",
            "Node 74:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "nificantly better than the corresponding cell in Table2.3 (5% or better gain in F\n",
            "measure, a significant improvement at confidence level\u001595%). This demonstrates\n",
            "the effectiveness of regularization for RE in general and for domain adaptation of\n",
            "RE specifically.\n",
            "2.2 The Kernel-based Approach\n",
            "In parallel to our work in the previous section on DA for RE (Nguyen and\n",
            "Grishman, 2014a), Nguyen et al.,2014d present a supervised DA algorithm for\n",
            "RE that assumes some labeled data in the target domains. This differs from\n",
            "the work in (Nguyen and Grishman,2014a) and (Plank and Moschitti,2013) in\n",
            "that the latter belongs to the unsupervised domain adaptation techniques (i.e,\n",
            "requiring no labeled data in the target domains). In our view, unsupervised DA\n",
            "is more challenging, but more realistic and practical for RE as we usually do not\n",
            "know which target domains we need to work on in advance, thus cannot expect to\n",
            "possess labeled data of the target domains. Our work in this section therefore also\n",
            "focuses on the single-systemunsupervised DA. The single-system setting implies\n",
            "theconstructionofasinglesystemthatcanworkrobustlywithdifferentbutrelated\n",
            "domains (multiple target domains) as in the previous section.\n",
            "Plank and Moschitti,2013 propose to embed word clusters and latent seman-\n",
            "tic analysis (LSA) of words into tree kernels for DA of RE, while (Nguyen and\n",
            "Grishman, 2014a) studies the application of word clusters and word embeddings\n",
            "for DA of RE on the feature-based method. Although word clusters (Brown et al.,\n",
            "1992) have been employed by both studies to improve the performance of relation\n",
            "44\n",
            "  ID: 62e074af-9833-4b00-b147-7ec25155134c\n",
            "--------------------\n",
            "Node 75:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "extractors across domains, the application of word embeddings (Bengio et al.,2003;\n",
            "Mnih and Hinton,2008; Turian et al.,2010) for DA of RE is only examined in the\n",
            "feature-based method and never explored in the tree kernel-based method so far,\n",
            "giving rise to the first question we want to address in this section:\n",
            "(i) Can word embeddings help the tree kernel-based methods on DA for RE and\n",
            "more importantly, in which way can we do it effectively?\n",
            "This question is important as word embeddings are real valued vectors, while\n",
            "the tree kernel-based methods rely on the symbolic matches or mismatches of\n",
            "concrete labels in the parse trees to compute the kernels. It is unclear at the first\n",
            "glance how to encode word embeddings into the tree kernels effectively so that\n",
            "word embeddings could help to improve the generalization performance of RE.\n",
            "One way is to use word embeddings to compute similarities between words and\n",
            "embed these similarity scores into the kernel functions, e.g., by resembling the\n",
            "method of (Plank and Moschitti,2013) that exploited LSA (in the semantic syn-\n",
            "tactic tree kernel (SSTK), cf. §2.2.1.1). We explore various methods to apply word\n",
            "embeddings to generate the semantic representations for DA of RE and demon-\n",
            "strate that semantic representations are very effective to significantly improve the\n",
            "portability of the relation extractors based on the tree kernels, bringing us to the\n",
            "second question:\n",
            "(ii) Between the feature-based method in (Nguyen and Grishman, 2014a) and\n",
            "the SSTK method in (Plank and Moschitti, 2013), which method is better for DA\n",
            "of RE, given the recent discovery of word embeddings for both methods?\n",
            "It is worth noting that besides the approach difference, these two works employ\n",
            "45\n",
            "  ID: 8f60fc08-912c-4134-8950-59cb6c609ab6\n",
            "--------------------\n",
            "Node 76:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "rather different resources and settings in their evaluation, making it impossible\n",
            "to directly compare their performance. In particular, while Plank and Moschitti,\n",
            "2013 only use the path-enclosed trees induced from the constituent parse trees\n",
            "as the representation for relation mentions, Nguyen and Grishman,2014a include\n",
            "a rich set of features extracted from multiple resources such as constituent trees,\n",
            "dependency trees, gazetteers, semantic resources in the representation. Besides,\n",
            "Plank and Moschitti,2013 consider the direction of relations in their evaluation\n",
            "(i.e, distinguishing between relation classes and their inverses) but Nguyen and\n",
            "Grishman, 2014a disregard this relation direction. Finally, we note that although\n",
            "both studies evaluate their systems on the ACE 2005 dataset, they actually have\n",
            "different dataset partitions. In order to overcome this limitation, we conduct an\n",
            "evaluation in which the two methods are directed to use the same resources and\n",
            "settings, and are thus compared in acompatible manner to achieve an insight on\n",
            "their effectiveness for DA of RE. In fact, the problem of incompatible comparison\n",
            "is unfortunately very common in the RE literature (Plank and Moschitti,2013;\n",
            "Wang, 2008) and we believe there is a need to tackle this increasing confusion in\n",
            "this line of research. Therefore, this is actually the first attempt to compare the\n",
            "two methods (tree kernel-based and feature-based) on the same settings. To ease\n",
            "the comparison for future work and circumvent theZigglebottom pitfall (Pedersen,\n",
            "2008), the entire setup and package is available11.\n",
            "11. https://bitbucket.org/nycphre/limo-re\n",
            "46\n",
            "  ID: adce9deb-8fba-4e7b-8b97-2692177e7f1e\n",
            "--------------------\n",
            "Node 77:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "2.2.1 Relation Extraction Approaches\n",
            "In the following, we review and compare the two relation extraction systems\n",
            "with greater details to facilitate the later discussion.\n",
            "2.2.1.1 T ree kernel-based Method\n",
            "In the tree kernel-based method (Moschitti,2006, 2008; Plank and Moschitti,\n",
            "2013), a relation mention (the two entity mentions and the sentence containing\n",
            "them) is represented by the path-enclosed tree (PET), the smallest constituency-\n",
            "based subtree including the two target entity mentions (Zhang et al.,2006). The\n",
            "syntactic tree kernel (STK) is then defined to compute the similarity between two\n",
            "PET trees (where target entities are marked) by counting the common sub-trees,\n",
            "without enumerating the whole fragment space (Moschitti,2006, 2008). STK is\n",
            "then applied in the support vector machines (SVMs) for RE. The major limita-\n",
            "tion of STK is its inability to match two trees that share the same substructure,\n",
            "but involve different though semantically related terminal nodes (words). This is\n",
            "caused by the hard matches between words, and consequently between sequences\n",
            "containing them. For instance, in the following example taken from (Plank and\n",
            "Moschitti,2013), the two fragments “governor from T exas” and “head of Maryland”\n",
            "would not match in STK although they have very similar syntactic structures and\n",
            "basically convey the same relationship.\n",
            "Plank and Moschitti, 2013 propose to resolve this issue for STK using the\n",
            "semantic syntactic tree kernel (SSTK) (Bloehdorn and Moschitti,2007) and apply\n",
            "it to the domain adaptation problem of RE. The two following techniques are\n",
            "47\n",
            "  ID: 102f45b1-a207-4f69-a4cd-f52cea0528a4\n",
            "--------------------\n",
            "Node 78:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "utilized to activate the SSTK: (i) replace the part-of-speech nodes in the PET\n",
            "trees by the new ones labeled by the word clusters of the corresponding terminals\n",
            "(words); (ii) replace the binary similarity scores between words (i.e, either 1 or 0)\n",
            "by the similarities induced from the latent semantic analysis (LSA) of large corpus.\n",
            "The former generalizes the part-of-speech similarity to the semantic similarity on\n",
            "word clusters; the latter, on the other hand, allows soft matches between words\n",
            "that have the same latent semantic but differ in symbolic representation. Both\n",
            "techniques emphasize the invariants of word semantics in different domains, thus\n",
            "being helpful to alleviate the vocabulary difference across domains.\n",
            "2.2.1.2 F eature-based Method\n",
            "In the feature-based method (Nguyen and Grishman,2014a; Sun et al.,2011;\n",
            "Zhou et al.,2005), relation mentions are first transformed into rich feature vectors\n",
            "that capture various characteristics of the relation mentions (i.e, lexicon, syntax,\n",
            "semantics etc). The resulting vectors are then fed into the statistical classifiers\n",
            "such as Maximum Entropy (MaxEnt) to perform classification for RE.\n",
            "The main reason for the performance loss of the feature-based systems on new\n",
            "domains is the behavioral changes of the features when domains shift. Some fea-\n",
            "tures might be very informative in the source domain but become less relevant in\n",
            "thetargetdomains. Forinstance, somewords, thatareveryindicativeinthesource\n",
            "domain might not appear in the target domains (lexical sparsity). Consequently,\n",
            "the models putting high weights on such words (features) in the source domain\n",
            "will fail to perform well on the target domains. Nguyen and Grishman, 2014a\n",
            "48\n",
            "  ID: c4571ff1-b065-4af5-bb40-9a050c75cb46\n",
            "--------------------\n",
            "Node 79:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "address this problem for the feature-based method in DA of RE by introducing\n",
            "word embeddings as additional features. The rationale is based on the fact that\n",
            "word embeddings are low dimensional and real valued vectors, capturing latent\n",
            "syntactic and semantic properties of words (Bengio et al.,2003; Mnih and Hinton,\n",
            "2008; Turian et al.,2010). The embeddings of symbolically different words are of-\n",
            "ten close to each other if they have similar semantic and syntactic functions. This\n",
            "again helps to mitigate the lexical sparsity or the vocabulary difference between\n",
            "the domains and has proven helpful for, amongst others, the feature-based method\n",
            "in DA of RE.\n",
            "2.2.1.3 T ree Kernel-based vs F eature-based\n",
            "The feature-based method explicitly encapsulates the linguistic intuition and\n",
            "domain expertise for RE into the features, while the tree kernel-based method\n",
            "avoids the complicated feature engineering and implicitly encode the features into\n",
            "the computation of the tree kernels. Which method is better for DA of RE?\n",
            "In order to ensure the two methods (Nguyen and Grishman,2014a; Plank and\n",
            "Moschitti, 2013) are compared compatibly on the same resources, we make sure\n",
            "the two systems have access to the same amount of information. Thus, we follow\n",
            "(Plank and Moschitti,2013) and use the PET trees (beside word clusters and word\n",
            "embeddings) as the only resource the two methods can exploit.\n",
            "For the feature-based method, we utilize all the features extractable from the\n",
            "PETtreesthatarestandardlyusedinthestate-of-the-artfeature-basedsystemsfor\n",
            "DA of RE (Nguyen and Grishman,2014a). Specifically, the feature set employed in\n",
            "49\n",
            "  ID: e5206d99-0a15-4b07-a2bb-ff5dce102be7\n",
            "--------------------\n",
            "Node 80:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "this work (denoted by FET) includes: the lexical features, i.e., the context words,\n",
            "the head words, the bigrams, the number of words, the lexical path, the order of\n",
            "mention (Sun et al.,2011; Zhou et al.,2005); and the syntactic features, i.e., the\n",
            "path connecting the two mentions in PET and the unigrams, bigrams, trigrams\n",
            "along this path (Jiang and Zhai,2007a; Zhou et al.,2005).\n",
            "Hypothesis: Assuming identical settings and resources, we hypothesize that\n",
            "the tree kernel-based method is better than the feature-based method for DA of\n",
            "RE. This is motivated because of at least two reasons: (i) the tree kernel-based\n",
            "method implicitly encodes a more comprehensive feature set (involving all the sub-\n",
            "trees in the PETs), thus potentially captures more domain-independent features\n",
            "to be useful for DA of RE; (ii) the tree kernel-based method avoids the inclusion\n",
            "of fine-tuned and domain-specific features originated from the excessive feature\n",
            "engineering (i.e., hand-designing feature sets based on the linguistic intuition for\n",
            "specific domains) of the feature-based method.\n",
            "2.2.2 W ord Embeddings & T ree Kernels\n",
            "In this section, we first give the intuition that guides us in designing the pro-\n",
            "posed methods. In particular, one limitation of the syntactic semantic tree kernel\n",
            "presented in (Plank and Moschitti,2013) (§2.2.1.1) is that semantics is highly tied\n",
            "to syntax (the PET trees) in the kernel computation, limiting the generalization\n",
            "capacity of semantics to the extent of syntactic matches. If two relation mentions\n",
            "have different syntactic structures, the two relation mentions will not match, al-\n",
            "though they share the same semantic representation and express the same relation\n",
            "50\n",
            "  ID: 45fc70ef-121e-4a74-bc5d-fc199acf07c3\n",
            "--------------------\n",
            "Node 81:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "class. For instance, the two fragments “T om is the CEO of the company ” and\n",
            "“the company, headed by T om” express the same relationship between “T om” and\n",
            "“company” based on the semantics of their context words, but cannot be matched\n",
            "in SSTK as their syntactic structures are different. In such a case, it is desirable\n",
            "to have a representation of relation mentions that is grounded on the semantics of\n",
            "the context words and reflects the latent semantics of the whole relation mentions.\n",
            "This representation is expected to be general enough to be effective on different\n",
            "domains. Once the semantic representation of relation mentions is established, we\n",
            "can use it in conjunction with the traditional tree kernels to extend their coverage.\n",
            "The benefit is mutual as both semantics and syntax help to generalize relation\n",
            "mentions to improve the recall, but also constrain each other to support precision.\n",
            "This is the basic idea of our approach, which we compare to the previous methods.\n",
            "2.2.2.1 Methods\n",
            "We propose to utilize word embeddings of the context words as the principal\n",
            "components to obtain semantic representations for relation mentions in the tree\n",
            "kernel-based methods. Besides more traditional approaches to exploit word em-\n",
            "beddings, we investigate representations that go beyond the word level and use\n",
            "compositionality embeddings for domain adaptation for the first time.\n",
            "In general, suppose we are able to acquire an additional real-valued vector\n",
            "VECTi from word embeddings to semantically represent a relation mentionRELi\n",
            "(along with the PET treeTREEi), leading to the new representation ofRELi =\n",
            "51\n",
            "  ID: e8cdd993-626b-4d94-892d-d1620c4299d7\n",
            "--------------------\n",
            "Node 82:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "(TREEi;VECTi). The new kernel function in this case is then defined by:\n",
            "Knew(RELi;RELj) = (1 \u0000\u000b)SSTK(TREEi;TREEj) + \u000bKvec(VECTi;VECTj)\n",
            "(2.1)\n",
            "where Kvec(VECTi;VECTj) is some standard vector kernel like the polynomial\n",
            "kernels. \u000b is a trade-off parameter and indicates whether the system attributes\n",
            "more weight to the traditional SSTK or the new semantic kernelKvec.\n",
            "In this work, we consider the following methods to obtain the semantic represen-\n",
            "tation VECTi from the word embeddings of the context words ofRELi (assuming\n",
            "me is the dimensionality of the word embeddings):\n",
            "HEAD: VECTi = the concatenation of the word embeddings of the two en-\n",
            "tity mention heads ofRELi. This representation is inherited from (Nguyen and\n",
            "Grishman, 2014a) that only examines embeddings at the word level separately for\n",
            "the feature-based method without considering the compositionality embeddings of\n",
            "relation mentions. The dimensionality of HEAD is2me.\n",
            "According to the principle of compositionality (Baroni and Zamparelli,2010;\n",
            "Paperno et al.,2014; Werning et al.,2006), the meaning of a complex expression is\n",
            "determined by the meanings of its components and the rules to combine them. We\n",
            "study the following two compositionality embeddings for relation mentions that\n",
            "can be generated from the embeddings of the context words:\n",
            "PHRASE:VECTi =themeanoftheembeddingsofthewordscontainedinthe\n",
            "PET treeTi of RELi. Although this composition is simple, it is in fact competitive\n",
            "to the more complicated methods based on recursive neural networks (Blacoe and\n",
            "Lapata, 2012; Socher et al.,2012b; Sterckx et al.,2014) on representing phrase\n",
            "52\n",
            "  ID: 8a88dfe5-1d0f-4d94-b370-819280d9bb98\n",
            "--------------------\n",
            "Node 83:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "semantics.\n",
            "TREE: This is motivated by the training of recursive neural networks (Socher\n",
            "et al.,2012a) for semantic compositionality and attempts to aggregate the context\n",
            "words embeddings syntactically. In particular, we compute an embedding for every\n",
            "node in the PET tree in a bottom-up manner. The embeddings of the leaves are\n",
            "the embeddings of the words associated with them while the embeddings of the\n",
            "internal nodes are the means of the embeddings of their children nodes. We use\n",
            "the embeddings of the root of the PET tree to represent the relation mention in\n",
            "this case. Both PHRASE and TREE haveme dimensions.\n",
            "It is also interesting to examine combinations of these three representations\n",
            "(cf., Table2.5).\n",
            "SIM: Finally, for completeness, we experiment with a more obvious way to in-\n",
            "troducewordembeddingsintotreekernels, resemblingmorecloselytheapproachof\n",
            "(Plank and Moschitti,2013). In particularly, the SIM method simply replaces the\n",
            "similarity scores between word pairs obtained from LSA by the cosine similarities\n",
            "between the word embeddings to be used in the SSTK kernel.\n",
            "2.2.3 Experiments\n",
            "2.2.3.1 Dataset, Resources and Parameters\n",
            "We use the word clusters trained by (Plank and Moschitti,2013) on the ukWaC\n",
            "corpus (Baroni et al.,2009) with 2 billion words, and the C&W word embeddings\n",
            "from (Turian et al.,2010)12 with 50 dimensions following (Nguyen and Grishman,\n",
            "12. http://metaoptimize.com/projects/wordreprs\n",
            "53\n",
            "  ID: 676438e6-08d0-4b66-854d-4ea3e127d294\n",
            "--------------------\n",
            "Node 84:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "2014a). In order to make the comparisons compatible, we introduce word em-\n",
            "beddings into the tree kernel by extending the package provided by (Plank and\n",
            "Moschitti, 2013), which uses the Charniak parser to obtain the constituent trees,\n",
            "the SVM-light-TK for the SSTK kernel in SVM, the directional relation classes,\n",
            "etc. We utilize the default vector kernel in the SVM-light-TK package (d=3). For\n",
            "the feature-based method, we apply the MaxEnt classifier in the MALLET13 pack-\n",
            "age with the L2 regularizer on the hierarchical architecture for relation extraction\n",
            "as in (Nguyen and Grishman,2014a).\n",
            "Following prior work, we evaluate the systems on the ACE 2005 dataset which\n",
            "involves 6 domains: broadcast news (bn), newswire (nw), broadcast conversation\n",
            "(bc), telephone conversation (cts), weblogs (wl) and usenet (un). The union ofbn\n",
            "and nw (news) is used as the source domain whilebc, cts and wl play the role of\n",
            "the target domains. We take half of bc as the only target development set, and\n",
            "use the remaining data and domains for testing. The dataset partition is exactly\n",
            "the same as in (Plank and Moschitti,2013).\n",
            "2.2.3.2 W ord Embeddings for T ree Kernel\n",
            "We investigate the effectiveness of different semantic representations (§2.2.2.1)\n",
            "in tree kernels by taking the PET tree as the baseline14, and evaluate the perfor-\n",
            "mance of the representations when combined with the baseline on thebc develop-\n",
            "ment set.\n",
            "Table2.5 shows the results. The main conclusions include:\n",
            "13. http://mallet.cs.umass.edu\n",
            "14. By using their system we obtained the same results.\n",
            "54\n",
            "  ID: 73e39281-d0e1-4c8f-985c-e1f5a30d5b48\n",
            "--------------------\n",
            "Node 85:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "Method P R F1\n",
            "PET (Plank and Moschitti,2013) 52.2 41.7 46.4\n",
            "PET+SIM 39.4 37.2 38.3\n",
            "PET+HEAD 60.4 44.9 51.5\n",
            "PET+PHRASE 58.4 40.7 48.0\n",
            "PET+TREE 59.8 42.2 49.5\n",
            "PET+HEAD+PHRASE 63.2 46.2 53.4\n",
            "PET+HEAD+TREE 61.0 45.7 52.3\n",
            "PET+PHRASE+TREE 59.2 42.4 49.4\n",
            "PET+HEAD+PHRASE+TREE 60.8 45.2 51.9\n",
            "Table 2.5:Performance on thebc dev set for PET.\n",
            "(i) The substitution of LSA similarity scores with the word embedding cosine\n",
            "similarities (SIM) does not help to improve the performance of the tree kernel\n",
            "method.\n",
            "(ii) When employed independently, both the word level embeddings (HEAD)\n",
            "and the compositionality embeddings (PHRASE, TREE) are effective for the tree\n",
            "kernel-based method on DA for RE, showing a slight advantage for HEAD.\n",
            "(iii) Thus, the compositionality embeddings PHRASE and TREE seem to cap-\n",
            "ture different information with respect to the word level embeddings HEAD. We\n",
            "expect the combination of HEAD with either PHRASE or TREE to further im-\n",
            "prove performance. This is the case when adding one of them at a time. PHRASE\n",
            "and TREE seem to capture similar information, combining all (last row in Table\n",
            "2.5) is not the overall best system. The best performance is achieved when the\n",
            "HEAD and PHRASE embeddings are utilized at the same time, reaching an F1 of\n",
            "53.4% (compared to 46.4% of the baseline) on the development set.\n",
            "The results in Table2.5 are obtained using the trade-off parameter\u000b = 0 :7.\n",
            "55\n",
            "  ID: 88b94fea-7d8c-41f4-b740-ed900f90b637\n",
            "--------------------\n",
            "Node 86:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "0 0:1 0:3 0:5 0:7 0:9 146\n",
            "48\n",
            "50\n",
            "52\n",
            "\u000b\n",
            "F-measure\n",
            "Figure 2.1: \u000b vs F-measure on PET+HEAD+PHRASE\n",
            "Figure 2.1 additionally shows the variation of the performance with changing\u000b\n",
            "(for the best system on dev, i.e., for the representation PET+HEAD+PHRASE).\n",
            "As we can see, the performance for \u000b > 0:5 is in general better, suggesting a\n",
            "preference for the semantic representation over the syntactic representation in DA\n",
            "for RE. The performance reaches its peak when the suitable amounts of semantics\n",
            "and syntax are combined (i.e,\u000b= 0 :7).\n",
            "Inthefollowingexperiments, weusetheembeddingcombination(HEAD+PHRASE)\n",
            "with \u000b= 0 :7 for the tree kernels, denoted WED.\n",
            "2.2.3.3 Domain Adaptation Experiments\n",
            "In this section, we examine the semantic representation for DA of RE in the\n",
            "tree kernel-based method. In particular, we take the systems using the PET trees,\n",
            "wordclusters and LSA in (Plank and Moschitti,2013) as the baselines and augment\n",
            "them with the embeddings WED = HEAD+PHRASE. We report the performance\n",
            "56\n",
            "  ID: 2d1ee70e-cef1-45a3-b768-0bc15c6d7477\n",
            "--------------------\n",
            "Node 87:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "of these augmented systems in Table2.6 for the two scenarios: (i) in-domain: both\n",
            "training and testing are performed on the source domain via 5-fold cross validation\n",
            "and (ii) out-of-domain: models are trained on the source domain but evaluated on\n",
            "the three target domains. To summarize, we find:\n",
            "nw+bn(in-dom.) bc cts wl# System: P: R: F1: P: R: F1: P: R: F1: P: R: F1:\n",
            "1 PET (Plank and Moschitti,2013) 50.6 42.1 46.051.2 40.6 45.351.0 37.8 43.435.4 32.8 34.02 PET+WED 55.848.752.057.345.750.8 54.038.144.7 40.136.538.2\n",
            "3 PET_WC 55.4 44.6 49.454.3 41.4 47.055.9 37.1 44.640.0 32.7 36.04 PET_WC+WED 56.348.251.957.044.349.8 56.138.145.4 40.736.138.2\n",
            "5 PET_LSA 52.3 44.1 47.951.4 41.7 46.049.7 36.5 42.138.1 36.5 37.36 PET_LSA+WED 55.248.551.658.845.851.5 54.138.144.7 40.938.539.6\n",
            "7 PET+PET_WC 55.0 46.5 50.454.4 43.4 48.354.1 38.1 44.738.4 34.5 36.38 PET+PET_WC+WED 56.350.353.157.546.651.5 55.639.846.441.537.939.6\n",
            "9 PET+PET_LSA 52.7 46.6\n",
            "  ID: 7807af6f-0278-42bc-bd52-c18f7a992508\n",
            "--------------------\n",
            "Node 88:\n",
            "  Text: PET+PET_LSA 52.7 46.6 49.553.9 45.2 49.249.9 37.6 42.937.9 38.3 38.110 PET+PET_LSA+WED 55.549.952.656.845.850.8 52.538.644.5 41.639.340.5\n",
            "11 PET+PET_WC+PET_LSA55.1 45.9 50.155.3 43.1 48.553.1 37.0 43.639.9 35.8 37.812 PET+PET_WC+PET_LSA+WED55.048.851.758.547.352.352.638.844.7 42.338.940.5\n",
            "Table 2.6:In-domain (first column) and out-of-domain performance (columns two\n",
            "to four) on ACE 2005. Systems of the rows not in gray come from (Plank and\n",
            "Moschitti, 2013) (the baselines). WED means HEAD+PHRASE.\n",
            "First, word embeddings seem to subsume word clusters in the tree kernel-based\n",
            "method (comparing rows 2 and 4, and except domain cts) while word embeddings\n",
            "and LSA actually encode different information (comparing rows 2 and 6 for the\n",
            "out-of-domain experiments) and their combination would be helpful for DA of RE.\n",
            "Second, regarding composite kernels, given word embeddings, the addition of\n",
            "the baseline kernel (PET) is in general useful for the augmented kernels PET_WC\n",
            "and PET_LSA (comparing rows 4 and 8, rows 6 and 10) although it is less pro-\n",
            "nounced for PET_LSA.\n",
            "Third and most importantly, for all the systems in (Plank and Moschitti,\n",
            "2013) (the baselines) and for all the target domains, whether word clusters and\n",
            "57\n",
            "  ID: 18bd4ac7-d528-4e84-abd0-a604167f4ea7\n",
            "--------------------\n",
            "Node 89:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "LSA are utilized or not, we consistently witness the performance improvement of\n",
            "the baselines when combined with word embedding (comparing systems X and\n",
            "X+WED where X is some baseline system). The best out-of-domain performance\n",
            "is achieved when word embeddings are employed in conjunction with the compos-\n",
            "ite kernels (PET+PET_WC+PET_LSA for the target domainsbc and wl, and\n",
            "PET+PET_WC for the target domaincts). To be more concrete, the best sys-\n",
            "tem with word embeddings (row 12 in Table2.6) significantly outperforms the best\n",
            "system in (Plank and Moschitti,2013) with p <0:05, an improvement of 3.7%,\n",
            "1.1% and 2.7% on the target domainsbc, cts and wl respectively, demonstrating\n",
            "the benefit of word embeddings for DA of RE in the tree kernel-based method.\n",
            "2.2.3.4 T ree Kernel-based vs F eature-based DA of RE\n",
            "This section aims to compare the tree kernel-based method in (Plank and Mos-\n",
            "chitti, 2013) and the feature-based method in (Nguyen and Grishman,2014a) for\n",
            "DAofREonthesamesettings(i.e, samedatasetpartition, thesamepre-processing\n",
            "procedure, the same model of directional relation classes, the same PET trees for\n",
            "tree kernels and feature extraction, the same word clusters and the same word\n",
            "embeddings). We first evaluate the feature-based system with different combina-\n",
            "tions of embeddings (i.e, HEAD, PHRASE and TREE) on the bc development\n",
            "set. Based on the evaluation results, we then discuss the effect of the semantic\n",
            "representations on the feature-based system and the tree kernel-based system, and\n",
            "then compare the performance of the two methods when they are augmented with\n",
            "their best corresponding embedding combinations.\n",
            "58\n",
            "  ID: 47bab0a1-2403-420e-ae9d-34764bc33ca5\n",
            "--------------------\n",
            "Node 90:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "Table2.7 presents the evaluation results on thebc development for the feature-\n",
            "based system where B is the baseline feature set consisting of FET and word\n",
            "clusters (WC) (Nguyen and Grishman,2014a).\n",
            "System P R F1\n",
            "B 51.2 49.4 50.3\n",
            "B+HEAD 55.8 52.4 54.0\n",
            "B+PHRASE 50.7 46.2 48.4\n",
            "B+TREE 53.6 51.1 52.3\n",
            "B+HEAD+PHRASE 53.2 50.1 51.6\n",
            "B+HEAD+TREE 54.9 51.4 53.1\n",
            "B+PHRASE+TREE 50.7 48.4 49.5\n",
            "B+HEAD+PHRASE+TREE 52.7 49.4 51.0\n",
            "Table 2.7:Performance of the feature-based method (dev).\n",
            "The Role of Semantic Representations\n",
            "Considering Table2.7 for the feature-based method and Table2.5 for the tree\n",
            "kernel-based method, we see that when combined with the HEAD embeddings, the\n",
            "compositionality embedding TREE is more effective for the feature-based method,\n",
            "in contrast to the tree kernel-based method, where the PHRASE embeddings are\n",
            "better. This can be partly explained by the fact that the tree kernel-based method\n",
            "emphasizes the syntactic structure of the relation mentions, while the feature-\n",
            "based method exploits the sequential structure more. Consequently, the syntactic\n",
            "semantics of TREE are more helpful for the feature-based method, whereas the\n",
            "sequential semantics of PHRASE are more useful for the tree kernel-based method.\n",
            "Performance Comparison\n",
            "The three best embedding combinations for the feature-based system in Table\n",
            "2.7 are (listed by performance order): (HEAD), (HEAD+TREE) and (TREE),\n",
            "59\n",
            "  ID: eaa9619d-96f1-4a3a-994e-3168024154d5\n",
            "--------------------\n",
            "Node 91:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "where (HEAD) is also the best word level method employed in (Nguyen and Gr-\n",
            "ishman, 2014a). In order to enable a fairer and clearer evaluation, when doing\n",
            "comparison, we use both the three best embedding combinations in the feature-\n",
            "based method and the best embedding combination (HEAD+PHRASE) in the\n",
            "tree kernel-based method. In the tree kernel-based method, we do not employ\n",
            "the LSA information as it comes in the form of similarity scores between pairs of\n",
            "words, and it is not clear how to encode this information into the feature-based\n",
            "method effectively. Finally, we utilize the composite kernel for its demonstrated\n",
            "effectiveness in Section2.2.3.3.\n",
            "nw+bn(in-dom.) bc cts wl\n",
            "System: P: R: F1: P: R: F1: P: R: F1: P: R: F1:\n",
            "T ree kernel-based:\n",
            "PET+PET_WC+HEAD+PHRASE56.3 50.353.157.5 46.651.555.6 39.846.441.5 37.939.6\n",
            "F eature-based:\n",
            "FET+WC+HEAD 44.5 51.0 47.546.5 49.3 47.844.5 40.0 42.135.4 39.5 37.3\n",
            "FET+WC+TREE 44.4 50.2 47.146.4 48.7 47.643.7 40.3 41.932.7 36.7 34.6\n",
            "FET+WC+HEAD+PHRASE44.9 51.6 48.046.0 49.1 47.545.2 41.5 43.334.7 39.2 36.8\n",
            "FET+WC+HEAD+TREE45.1 51.0 47.846.9 48.4 47.643.8 39.5 41.534.7 38.8 36.6\n",
            "Table 2.8: Tree kernel-based in (Plank and\n",
            "  ID: da748b42-b3c7-40a5-9505-0c68746eef56\n",
            "--------------------\n",
            "Node 92:\n",
            "  Text: 36.6\n",
            "Table 2.8: Tree kernel-based in (Plank and Moschitti,2013) vs feature-based in\n",
            "(Nguyen and Grishman,2014a). All the comparisons between the tree kernel-based\n",
            "method and the feature-based method in this table are significant withp< 0:05.\n",
            "The most important observation from the experimental results (shown in Table\n",
            "2.8) is that over all the target domains, the tree kernel-based system is significantly\n",
            "better than the feature-based systems withp< 0:05 (assuming the same resources\n",
            "and settings mentioned above). In fact, there are large margins between the tree\n",
            "kernel-based and the feature-based methods in this case (i.e, about 3.7% forbc,\n",
            "3.1% forcts and 2.3% forwl), clearly confirming the hypothesis about the advan-\n",
            "tage of the tree kernel-based method over the feature-based method on DA for RE\n",
            "60\n",
            "  ID: 5adf3813-482e-4b3d-bb91-8e350f2e8fc9\n",
            "--------------------\n",
            "Node 93:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "in Section2.2.1.3.\n",
            "2.2.4 Analysis\n",
            "This section analyzes the output of the systems to gain more insights into their\n",
            "operation.\n",
            "W ord Embeddings for the T ree-kernel based Method\n",
            "We focus on the comparison of the best model in (Plank and Moschitti,2013)\n",
            "(row 11 in Table2.6) (called P) with the same model but augmented with the\n",
            "embedding WED (row 12 in Tabel2.6) (called P+WED). One of the most inter-\n",
            "esting insights is that the embedding WED helps to semantically generalize the\n",
            "phrases connecting the two target entity mentions beyond the syntactic constraints.\n",
            "For instance, model P fails to discover the relation between “Chuck Hagel ” and\n",
            "“Vietnam” in the sentence (of the target domain bc): “Sergeant Chuck Hagel was\n",
            "seriously wounded twice in Vietnam. ” (i.e, it returns the NONE relation as the\n",
            "prediction) as the substructure associated with “seriously wounded twice” does not\n",
            "appear with any relation in the source domain. Model P+WED, on the other\n",
            "hand, correctly predicts the PHYS (Located) relation between the two entities as\n",
            "the PHRASE embedding of “Chuck Hagel was seriously wounded twice in Viet-\n",
            "nam.” (phrase X1) is very close to the embedding of the source domain phrase:\n",
            "“Stewart faces up to 30 years in prison ” (phrase X2) (annotated with the PHYS\n",
            "relation between “Stewart” and “prison”).\n",
            "In fact, X2 is only the 9th closest phrase in the source domain of X1. The\n",
            "closest phrase of X1 in the source domain is X3: the phrase between “Iraqi sol-\n",
            "61\n",
            "  ID: 1813279b-f297-4022-a29d-cc4b405c0d57\n",
            "--------------------\n",
            "Node 94:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "diers” and “herself ” in the sentence “The W ashington Post is reporting she shot\n",
            "several Iraqi soldiers before she was captured and she was shot herself ,\n",
            "too.”. However, as the syntactical structure of X1 is more similar to X2’s, and is\n",
            "remarkably different from X3 as well as the other closest phrases (ranked from 2nd\n",
            "to 8th), the new kernel functionKnew would still prefer X2 due to its trade-off\n",
            "between syntax and semantics.\n",
            "T ree Kernel-based vs F eature-based\n",
            "From the analysis of the systems in Table2.8, we find that, among others, the\n",
            "tree kernel-based method improves the precision significantly via the semantic and\n",
            "syntactic refinement it maintains. Let us consider the following phrase of the target\n",
            "domain bc: “troops have dislodged stubborn Iraqi soldiers” (called Y1). The feature-\n",
            "basedsystemsinTable 2.8incorrectlypredicttheORG-AFFrelation(Employment\n",
            "or Membership) between “Iraqi soldiers” and “troops”. This is mainly due to the\n",
            "high weights of the features linking the words “troop” and “soldiers” with the\n",
            "relation type ORG-AFF in the feature-based models, which is, in turn, originated\n",
            "from the high correlation of these words and the relation type in the training\n",
            "data of the source domain (domain bias). The tree kernel-based model in Table\n",
            "2.8 successfully recognizes the NONE relation in this case. A closer examination\n",
            "shows that the phrase with the closest embedding to Y1 in the source domain is\n",
            "Y2: “Iraqi soldiers abandoned their posts ”15, which is annotated with the NONE\n",
            "relation between “Iraqi soldiers ” and “their posts ”. As the syntactic structure of\n",
            "Y2 is also very similar to Y1, it is not surprising that Y1 is closest to Y2 in the new\n",
            "15. The full sentence is: “ After today’s air strikes, Iraqi soldiers abandoned their posts and\n",
            "surrendered to Kurdish fighters.” .\n",
            "62\n",
            "  ID: 7133cadf-120b-4364-b318-b6098a0325ae\n",
            "--------------------\n",
            "Node 95:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "kernel function, consequently helping the tree kernel-based method work correctly\n",
            "in this case.\n",
            "2.3 Related work\n",
            "Word embeddings are only applied to RE recently. Socher et al.,2012b use\n",
            "word embeddings as input for matrix-vector recursive neural networks in relation\n",
            "classification while Zeng et al.,2014, and Nguyen and Grishman,2015a employ\n",
            "word embeddings in the framework of convolutional neural networks for relation\n",
            "classification and extraction, respectively. Sterckx et al.,2014 utilize word embed-\n",
            "dings to reduce noise of training data in distant supervision. Kuksa et al.,2010\n",
            "present a string kernel for bio-relation extraction with word embeddings, and Yu\n",
            "et al., 2014, 2015 study the factor-based compositional embedding models. How-\n",
            "ever, none of this work examines word embeddings for domain adaptation as we\n",
            "do.\n",
            "Regarding DA, in the unsupervised DA setting, Huang and Yates,2010 at-\n",
            "tempt to learn multi-dimensional feature representations while Blitzer et al.,2006\n",
            "introduce structural correspondence learning. Daume,2007 propose an easy adap-\n",
            "tation framework (EA) while Xiao and Guo,2013 present a log-bilinear language\n",
            "adaptation technique in the supervised DA setting. Unfortunately, all of this work\n",
            "assumes some prior (in the form of either labeled or unlabeled data) on the target\n",
            "domains for the sequential labeling tasks, in contrast to our single-system unsu-\n",
            "pervised DA setting for relation extraction. An alternative method that is also\n",
            "popular to DA is instance weighting (Jiang and Zhai,2007b). However, as shown\n",
            "63\n",
            "  ID: a60891b6-6b1e-4ac7-aaf8-ebae667c5a3d\n",
            "--------------------\n",
            "Node 96:\n",
            "  Text: CHAPTER 2. WORD EMBEDDINGS FOR DOMAIN ADAPTATION OF\n",
            "RELATION EXTRACTION\n",
            "by (Plank and Moschitti,2013), instance weighting is not very useful for DA of\n",
            "RE.\n",
            "2.4 Conclusion\n",
            "In order to improve the generalization (DA) for relation extractors, we propose\n",
            "several methods to incorporate word embeddings into the feature-based and the\n",
            "tree kernel-based approaches: (i) We have evaluated the effectiveness of word em-\n",
            "bedding and clustering features as well as regularization on tackling the portability\n",
            "of a feature-based relation extractor to new domains, and (ii) We augment the se-\n",
            "mantic syntactic tree kernels with the semantic representation of relation mentions,\n",
            "generated from the word embeddings of the context words. The methods demon-\n",
            "strates strong promise for the DA of RE, i.e, it significantly improves the best\n",
            "system of (Plank and Moschitti,2013) (up to 7% relative improvement). More-\n",
            "over, we perform a compatible comparison between the tree kernel-based method\n",
            "and the feature-based method on the same settings and resources, which suggests\n",
            "that the tree kernel-based method (Plank and Moschitti,2013) is better than the\n",
            "feature-based method (Nguyen and Grishman, 2014a) for DA of RE. An error\n",
            "analysis is conducted to get a deeper comprehension of the systems.\n",
            "64\n",
            "  ID: 2bb8adc4-729c-4f50-99bd-826358f23360\n",
            "--------------------\n",
            "Node 97:\n",
            "  Text: Chapter 3\n",
            "Deep Learning for Entity Mention\n",
            "Detection\n",
            "The previous chapter has introduced the application of word embeddings to\n",
            "improve the robustness of relation extractors. In the rest of this dissertation, we\n",
            "will totally focus on developing deep learning models for IE tasks. We start by\n",
            "the entity mention detection task in this chapter and dedicate chapters 3 and 4 for\n",
            "relation extraction and event detection respectively.\n",
            "Traditionally, bothentitymentiondetection(orsimplymentiondetection(MD))\n",
            "and named entity recognition (NER) are formalized as sequential labeling prob-\n",
            "lems, thereby being solved by some linear graphical models such as Hidden Markov\n",
            "Models (HMMs), Maximum Entropy Markov Models (MEMMs) or Conditional\n",
            "Random Fields (CRFs) (Lafferty et al.,2001). Although these graphical models\n",
            "have achieved the top performance for MD, there are still at least three problems\n",
            "we want to focus on this work:\n",
            "65\n",
            "  ID: 366672f2-4388-4f5f-ae77-839e789f7709\n",
            "--------------------\n",
            "Node 98:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "(i) The first problem is the performance loss of the mention detectors when they\n",
            "are trained on some domain (the source domain) and applied to other domains (the\n",
            "target domains). The problem might originate from various mismatches between\n",
            "thesourceandthetargetdomains(domainshifts)suchasthevocabularydifference,\n",
            "the distribution mismatches etc (Blitzer et al.,2006; Daume, 2007; Plank and\n",
            "Moschitti, 2013).\n",
            "(ii) Second, in mention detection, we might need to capture a long context,\n",
            "possibly covering the whole sentence, to correctly predict the type for a word. For\n",
            "instance, consider the following sentence with the pronominal “they”:\n",
            "Now, the reason that F rance, Russia and Germany are against war is because\n",
            "they have suffered much from the past war.\n",
            "In this sentence, the correct type GPE1 for “they” can only be inferred from\n",
            "its GPE references: “F rance”, “Russia” and “Germany” which are far from the\n",
            "pronominal “they” of interest. The challenge is to come up with the models that\n",
            "can encode and utilize these long-range dependency contexts effectively.\n",
            "(iii) The third challenge is to be able to quickly adapt the current techniques\n",
            "for MD so that they can perform well on new languages.\n",
            "In this chapter, we propose to address these problems for MD via recurrent\n",
            "neural networks (RNNs) which offer an effective recurrent mechanism to embed\n",
            "the sentence context into a distributed representation and employ it to decode\n",
            "the sentences. Besides, as RNNs replace the symbolic forms of words in the sen-\n",
            "tences with their word embeddings, the distributed representation that captures\n",
            "the general syntactic and semantic properties of words (Turian et al.,2010), they\n",
            "1. Geographical Political Entity\n",
            "66\n",
            "  ID: 699e924e-6cfe-4413-9d66-32cc9213bdd9\n",
            "--------------------\n",
            "Node 99:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "can alleviate the lexical sparsity, induce more general feature representation, thus\n",
            "generalizing well across domains (Nguyen and Grishman,2015b). This also helps\n",
            "RNNs to quickly and effectively adapt to new languages which just require word\n",
            "embeddings as the only new knowledge we need to obtain. Finally, we can achieve\n",
            "the task-specific word embeddings for MD to improve the overall performance by\n",
            "updating the initial pre-trained word embeddings during the course of training in\n",
            "RNNs.\n",
            "The recent emerging interest in deep learning has produced many successful\n",
            "applications of RNNs for NLP problems such as machine translation (Bahdanau\n",
            "et al., 2015; Cho et al.,2014a), semantic role labeling (Zhou and Xu,2015) etc.\n",
            "However, to the best of our knowledge, there has been no prior work employing\n",
            "RNNs for MD on the cross-domain and language settings so far. To summarize,\n",
            "the main contributions of this chapter are as follows:\n",
            "1. We perform a systematic investigation on various RNN architectures and\n",
            "word embedding techniques that are motivated from linguistic observations for\n",
            "MD.\n",
            "2. We achieve the state-of-the-art performance for MD in the cross-domain\n",
            "setting with the bidirectional modeling applied to RNNs.\n",
            "3. We demonstrate the portability of the RNN models for MD to new languages\n",
            "by their significant improvement with large margins over the best reported system\n",
            "for named entity recognition in Dutch.\n",
            "The work in this chapter is published in (Nguyen et al.,2016d).\n",
            "67\n",
            "  ID: aec0b294-d0eb-48e4-af01-ac1e096a237c\n",
            "--------------------\n",
            "Node 100:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "3.1 Models\n",
            "We formalize the mention detection problem as a sequential labeling task.\n",
            "Given a sentenceW = [ w1;w2;:::;w n], where wi is the i-th word and n is the\n",
            "length of the sentence, we want to predict the label sequenceY = [ y1;y2;:::;y n]\n",
            "for X, where yi is the label for wi. The labels yi follow the BIO2 encoding to\n",
            "capture the entity mentions inW. Note that this work focuses on the extraction\n",
            "of the entity mention heads, following (Florian et al.,2006) and (Li and Ji,2014a).\n",
            "In order to prepare the sentence for RNNs, we first transform each wordwi\n",
            "into a real-valued vectorveci using the concatenation of two vectorsembi and feti:\n",
            "veci = [ embi;feti]2, where:\n",
            "• embi is the word embedding vector ofwi, obtained by training a language\n",
            "model on a large corpus (discussed later).\n",
            "• feti is a binary vector encompassing different features forwi. In this work,\n",
            "we are utilizing four types of features: capitalization, gazetteers, triggers\n",
            "(whether wi is present in a list of trigger words3 or not) and cache (the label\n",
            "that is assigned towi sometime before in the document).\n",
            "Wethenenrichthisvectorrepresentationbyincludingthewordvectorsinacon-\n",
            "text window ofvc for each word in the sentence to capture the short-term dependen-\n",
            "ciesfor prediction(Mesnil et al.,2013). This effectivelyconvertswi intothecontext\n",
            "window version of the concatenated vectors:xi = [ veci\u0000vc;:::; veci;:::; veci+vc].\n",
            "2. F or simplicity , we are using the word wi and its real-valued vector representation inter-\n",
            "changeably .\n",
            "3. T rigger words are the words that are often followed by entity names in sentences such as\n",
            "“president”, “Mr.” etc.\n",
            "68\n",
            "  ID: e5729fe0-3f72-42a8-a757-05f74d94fc3c\n",
            "--------------------\n",
            "Node 101:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "Given the new input representation, we describe the RNNs to be investigated\n",
            "in this work below.\n",
            "3.1.1 The Basic Models\n",
            "In standard recurrent neural networks, at each time step (word position in\n",
            "sentence) i, we have three main vectors: the input vectorxi 2RmI , the hidden\n",
            "vector hi 2 RmH and the output vector oi 2 RmO (mI, mH and mO are the\n",
            "dimensions of the input vectors, the dimension of the hidden vectors and the\n",
            "number of possible labels for each word respectively). The output vectoroi is the\n",
            "probabilistic distribution over the possible labels for the wordxi and obtained from\n",
            "hi via the softmax functionφ:\n",
            "oi = φ(Ohi); φ(tj) = etj\n",
            "∑\n",
            "ketk\n",
            "(3.1)\n",
            "Regardingthehiddenvectorsorunits hi, therearetwomajormethodstoobtain\n",
            "them from the current input and the last hidden and output vectors, leading to\n",
            "two different RNN variants:\n",
            "• In the Elman model, calledELMAN, the hidden vector from the previous\n",
            "step hi\u00001, along with the input in the current stepxi, constitute the inputs\n",
            "to compute the current hidden statehi:\n",
            "hi = \b( Uxi + Vhi\u00001) (3.2)\n",
            "• In the Jordan model, calledJORDAN, the output vector from the previous\n",
            "step oi\u00001 is fed into the current hidden layer rather than the hidden vector\n",
            "69\n",
            "  ID: f87b02e1-7000-49be-8a03-4f5956509fb3\n",
            "--------------------\n",
            "Node 102:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "from the previous stepshi\u00001. The rationale for this topology is to introduce\n",
            "the label from the preceding step as a feature for current prediction:\n",
            "hi = \b( Uxi + Voi\u00001) (3.3)\n",
            "In the formula above,\b is the sigmoid activation function:\b(t) = 1\n",
            "1+e\u0000t and\n",
            "O, U, andV are the same weight matrices for all time steps, to be learned during\n",
            "training. The unfolded dependency graphs for the two models are given in Figure\n",
            "3.1.\n",
            "h1h0 h2 h3 hn\u00001 hn h1 h2 h3 hn\u00001 hn\n",
            "x1 x2 x3 xn\u00001 xn x1 x2 x3 xn\u00001 xn\n",
            "o1 o2 o3 on\u00001 on o0 o1 o2 o3 on\u00001 on\n",
            "ELMAN JORDAN\n",
            "Figure 3.1: The ELMAN and JORDAN models\n",
            "3.1.2 Gated Recurrent Units\n",
            "The ELMAN and JORDAN models are basically the stacks of the standard\n",
            "feed-forward neural networks that share the same weight matrices. Unfortunately,\n",
            "this stacking mechanism is prone to the “vanishing gradient ” problem (Bengio et\n",
            "al., 1994), making it challenging to train the networks properly in practice. This\n",
            "problem can be alleviated by long-short term memory units (LSTM) (Hochreiter\n",
            "and Schmidhuber,1997) that propose the idea of memory cells to allow the infor-\n",
            "mation storage and access over a long period of time.\n",
            "70\n",
            "  ID: 83e77e44-3007-428c-9116-f84dc0932ded\n",
            "--------------------\n",
            "Node 103:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "In this work, we use a variant of LSTM, called theGated Recurrent Units\n",
            "(GRUs) by (Cho et al.,2014a). GRU is shown to be simpler than LSTM in terms\n",
            "of computation and implementation but still achieves comparable performance\n",
            "(Józefowicz et al.,2015).\n",
            "The introduction of GRUs into the models ELMAN and JORDAN amounts\n",
            "to two new models, namedELMAN_GRU and JORDAN_GRU respectively,\n",
            "with two new methods to compute the hidden vectorshi. The formula for EL-\n",
            "MAN_GRU is adopted directly from (Cho,2014b) and given below:\n",
            "hi = zi ⊙^hi + (1 \u0000zi) ⊙hi\u00001\n",
            "^hi = \b( Whxi + Uh(ri ⊙hi\u00001))\n",
            "zi = \b( Wzxi + Uzhi\u00001)\n",
            "ri = \b( Wrxi + Urhi\u00001)\n",
            "(3.4)\n",
            "where Wh;Wz;Wr 2RmH\u0002mI , Uh;Uz;Ur 2RmH\u0002mH and ⊙is the element-wise\n",
            "multiplication operation.\n",
            "We cannot directly apply the formula above to the JORDAN_GRU model\n",
            "since the dimensions of the output vectorsoi and the hidden vectorhi are different\n",
            "in general. For JORDAN_GRU, we first need to transform the output vectoroi\n",
            "into the hidden vector space, leading to the following formula:\n",
            "71\n",
            "  ID: 39ea7cce-e20e-42a5-b3a6-0505165e2ebd\n",
            "--------------------\n",
            "Node 104:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "hi = zi ⊙^oi + (1 \u0000zi) ⊙ti\u00001\n",
            "ti\u00001 = Toi\u00001\n",
            "^oi = \b( Woxi + Uo(ri ⊙ti\u00001))\n",
            "zi = \b( Wzxi + Uzti\u00001)\n",
            "ri = \b( Wrxi + Urti\u00001)\n",
            "(3.5)\n",
            "where T 2RmH\u0002mO .\n",
            "3.1.3 The Bidirectional Networks\n",
            "One of the limitations of the four basic models presented above is their inca-\n",
            "pacity to incorporate the future context information that might be crucial to the\n",
            "prediction in the current step. For instance, consider the first word “Liverpool” in\n",
            "the following sentence:\n",
            "Liverpool suffered an upset first home league defeat of the season, beaten 1-0\n",
            "by a Guy Whittingham goal for Sheffield W ednesday.\n",
            "In this case, the correct label ORGANIZATION can only be detected if we first\n",
            "go over the whole sentence and then utilize the context words after “Liverpool” to\n",
            "decide its label.\n",
            "The limitation of the four models originates in their mechanism to perform a\n",
            "single pass over the sentences from left to right and make the prediction for a word\n",
            "when they first encounter it. Guided by this intuition, we propose to employ the\n",
            "bidirectional networks to solve the MD problem.\n",
            "72\n",
            "  ID: 318e118b-673f-4608-aaa7-b12cc4d90d5c\n",
            "--------------------\n",
            "Node 105:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "The bidirectional networks involve three passes over the sentence, in which\n",
            "the first two passes are designated to encode the sentence while the third pass is\n",
            "responsible for decoding. The procedure for the sentenceX = [ x1;x2;:::;x n] is\n",
            "below:\n",
            "(i) Run the first RNN\u0000\u0000\u0000!RNN from left to right over[x1;x2;:::;x n] to obtain the\n",
            "first hidden vector or output vector sequence (depending on whether\u0000\u0000\u0000!RNN is an\n",
            "Elman or Jordan network respectively):\u0000\u0000\u0000!RNN([x1;x2;:::;x n]) = [ \u0000 !h1;\u0000 !h2;:::; \u0000 !hn]\n",
            "(forward encoding).\n",
            "(ii) Run the second RNN \u0000\u0000\u0000RNN from right to left over[x1;x2;:::;x n] to obtain\n",
            "the second hidden vector or output vector sequence: \u0000\u0000\u0000RNN([xn;xn\u00001;:::;x 1]) =\n",
            "[ \u0000hn; \u0000\u0000hn\u00001;:::;  \u0000h1] (backward encoding).\n",
            "(iii) Obtain the concatenated sequenceh= [ h1;h2;:::;h n] where hi = [ \u0000 !hi; \u0000hi].\n",
            "(iv) Decode the sentence with the third RNNRd (the decoding model) usingh\n",
            "asthe input vector, i.e, replacingxi byhi in the formula(3.2), (3.3), (3.4) and(3.5).\n",
            "Conceptually, the encoding RNNs \u0000\u0000\u0000!RNN and  \u0000\u0000\u0000RNN can be different but in\n",
            "this work, for simplicity and consistency, we assume that we only have a single\n",
            "encoding model, i.e,\u0000\u0000\u0000!RNN =  \u0000\u0000\u0000RNN = Re. Note thatRe and Rd can be any model\n",
            "in {ELMAN, JORDAN, ELMAN_GRU, JORDAN_GRU}.\n",
            "The observation is, at the time stepi, the forward hidden vector\u0000 !hi represents\n",
            "the encoding for the past word context\n",
            "  ID: 510baa28-71ef-457f-92ba-37dce46fadbe\n",
            "--------------------\n",
            "Node 106:\n",
            "  Text: time stepi, the forward hidden vector\u0000 !hi represents\n",
            "the encoding for the past word context (from position 1 toi) while the backward\n",
            "hidden vector \u0000hi is the summary for the future word context (from positionn to\n",
            "73\n",
            "  ID: e0629300-a199-4905-9a76-6105eefa4e49\n",
            "--------------------\n",
            "Node 107:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "i). Consequently, the concatenated vectorhi = [ \u0000 !hi; \u0000hi] constitutes a distributed\n",
            "representation that is specific to the word at positioni but still encapsulates the\n",
            "context information over the whole sentence at the same time. This effectively\n",
            "provides the networks a much richer representation to decode the sentence. The\n",
            "bidirectional network forRe = ELMAN andRd = JORDAN is given on the left\n",
            "of Figure3.2.\n",
            "We notice that (Mesnil et al.,2013) also investigate the bidirectional models\n",
            "for the task of slot filling in spoken language understanding. However, compared\n",
            "to the work presented here, (Mesnil et al.,2013) does not use any special transition\n",
            "memory cells (like the GRUs we are employing in this work) to avoid numerical\n",
            "stability issues (Pascanu et al.,2012). Besides, they form the inputs h for the\n",
            "decoding phase from a larger context of the forward and backward encoding out-\n",
            "puts, while performing word-wise, independent classification; in contrast, we use\n",
            "only the current output vectors in the forward and backward encodings forh, but\n",
            "perform recursive computations to decode the sentence via the RNN modelRd\n",
            "(demonstrated on the right of Figure3.2).\n",
            "3.1.4 T raining and Inference\n",
            "We train the networks locally. In particular, each training example consists of\n",
            "a wordxi and its corresponding labelyi in a sentenceX = [ x1;x2;:::;x n] (denoted\n",
            "by I = ( xi;yi;X)). In the encoding phase, we first compute the necessary inputs\n",
            "according to the specific model of interest. This can be the original input vectors\n",
            "[x1;x2;:::;x n] in the four basic models or the concatenated vectors [h1;h2;:::;h n]\n",
            "74\n",
            "  ID: 214d8d59-4771-427c-b862-88ae7da1f8af\n",
            "--------------------\n",
            "Node 108:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "h1 h2 h3 hn\u00001 hn\n",
            "o0 o1 o2 o3 on\u00001 on\n",
            "x1 x2 x3 xn\u00001 xn\n",
            "l0 l1 l2 l3 ln\u00001 ln\n",
            "rn+1rnrn\u00001r3r2r1\n",
            "h1 h2 h3 hn\u00001 hn\n",
            "o1 o2 o3 on\u00001 on\n",
            "x1 x2 x3 xn\u00001 xn\n",
            "l0 l1 l2 l3 ln\u00001 ln\n",
            "rn+1rnrn\u00001r3r2r1\n",
            "\u000b1 \u000b2 \u000b3 \u000bn\u00001 \u000bn \u000b1 \u000b2 \u000b3 \u000bn\u00001 \u000bn\n",
            "Figure 3.2: The bidirectional models. The model on the right is from(Mesnil et\n",
            "al., 2013) with the forward and backward context size of 1.l0;rn+1 are the zero\n",
            "vectors.\n",
            "in the bidirectional models. Eventually, in the decoding phase, an sequence of\n",
            "vd input vectors preceding the current positioni is fed into the decoding network\n",
            "Rd to obtain the output vector sequence. The last vector in this output sequence\n",
            "corresponds to the probabilistic label distribution for the current positioni, to be\n",
            "used to compute the objective function. For example, in the bidirectional models,\n",
            "the input sequence for the decoding phase ishi\u0000vdhi\u0000vd+1 :::h i while the output\n",
            "sequence is: Re([hi\u0000vd;hi\u0000vd+1;:::;h i]) = [ oi\u0000vd;oi\u0000vd+1;:::;o i].\n",
            "In this work, we employ the stochastic gradient descent algorithm4 to update\n",
            "the parameters via minimizing the negative log-likelihood objective function:\n",
            "nll(I) = \u0000log(oi[yi]): (3.6)\n",
            "Finally, besides the weight matrices in the networks, the word embeddings are\n",
            "also optimized during training to obtain the task-specific word embeddings for MD.\n",
            "The gradients are computed via back-propagation and inference is performed by\n",
            "4. W e try the AdaDelta algorithm and the dropout regularization but do not see much\n",
            "difference.\n",
            "75\n",
            "  ID: 4d3f46ec-dcf0-458d-826f-715632cd2cb5\n",
            "--------------------\n",
            "Node 109:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "running the networks over the whole sentences and takingargmax over the output\n",
            "sequence:\n",
            "yi = argmax( oi): (3.7)\n",
            "3.2 W ord Representation\n",
            "Following (Collobert et al.,2011), we pre-train word embeddings from a large\n",
            "corpus and employ them to initialize the word representations in the models. One\n",
            "of the state-of-the-art models to train word embeddings have been proposed re-\n",
            "cently in (Mikolov et al.,2013b) that introduce two log-linear models, i.e the con-\n",
            "tinuous bag-of-words model (CBOW) and the continuous skip-gram model (Skip-\n",
            "gram). The CBOW model attempts to predict the current word based on the\n",
            "average of the context word vectors while the Skip-gram model aims to predict the\n",
            "surrounding words in a sentence given the current word.\n",
            "Inthiswork, besidestheCBOWandskip-grammodels, weexamineaconcatenation-\n",
            "based variant of CBOW (C-CBOW) to train word embeddings and compare the\n",
            "three models to gain insights into which kind of model is effective to obtain word\n",
            "representations for the MD task. The objective of C-CBOW is to predict the target\n",
            "word usingthe concatenation of the vectors of the words surrounding it , motivated\n",
            "from our strategy to decide the label for a word based on the concatenated context\n",
            "vectors. Intuitively, the C-CBOW model would perform better than CBOW as\n",
            "the concatenation mechanism helps to assign different weights to different context\n",
            "76\n",
            "  ID: 423440e4-ad81-46b7-9580-f31861ae240e\n",
            "--------------------\n",
            "Node 110:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "words, thereby being more flexible than CBOW that applies a single weight for all\n",
            "the context words. CBOW, Skip-gram and C-CBOW are illustrated in Figure3.3.\n",
            "wt\u00002\n",
            "wt\u00001\n",
            "wt+1\n",
            "wt+2\n",
            "wt\n",
            "SUM\n",
            "INPUTPROJECTIONOUTPUT\n",
            "wt\u00002\n",
            "wt\u00001\n",
            "wt+1\n",
            "wt+2\n",
            "wt\n",
            "INPUTPROJECTIONOUTPUT\n",
            "wt\u00002\n",
            "wt\u00001\n",
            "wt+1\n",
            "wt+2\n",
            "wt\n",
            "INPUTPROJECTIONOUTPUT\n",
            "CONCATENATE\n",
            "CBOW Skip-gram C-CBOW\n",
            "Figure 3.3: Methods to Train Word Embeddings\n",
            "3.3 Experiments\n",
            "3.3.1 Dataset\n",
            "In order to investigate the robustness across domains, following the prior work\n",
            "(Nguyen and Grishman,2015a; Plank and Moschitti,2013), we utilize the ACE\n",
            "2005 dataset which contains 6 domains: broadcast news (bn), newswire (nw), broad-\n",
            "cast conversation (bc), telephone conversation (cts), weblogs (wl), usenet (un) and\n",
            "7 entity types: person, organization, GPE, location, facility, weapon, vehicle. The\n",
            "union of bn and nw is considered as a single domain, callednews. We take half\n",
            "of bc as the only development data and use the remaining data and domains for\n",
            "evaluation. Some statistics about the domains are given in Table3.1.\n",
            "77\n",
            "  ID: 655f191f-b5c3-4597-92b5-38ff076bab82\n",
            "--------------------\n",
            "Node 111:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "Domain #Docs #Sents #Mentions\n",
            "news 332 6487 22460\n",
            "bc 60 3720 9336\n",
            "cts 39 5900 9924\n",
            "wl 119 2447 6538\n",
            "un 49 2746 6507\n",
            "Total 599 21300 54765\n",
            "Table 3.1:ACE 2005 Dataset\n",
            "Regarding the robustness across languages, we further evaluate the RNN mod-\n",
            "els on the CoNLL 2002 dataset for Dutch Named Entity Recognition5 (Carreras\n",
            "et al., 2002; Sang and Meulder, 2002). The CoNLL dataset comes along with\n",
            "the training data, validation data and test data, annotated for 4 types of entities:\n",
            "person, organization, location and miscellaneous.\n",
            "3.3.2 Resources and Parameters\n",
            "In all the experiments for RNNs below, we employ the context windowvc = 5 ,\n",
            "the decoding windowvd = 9 . We find that the optimal number of hidden units (or\n",
            "the dimension of the hidden vectors) and the learning rate vary according to the\n",
            "dataset. For the ACE 2005 dataset, we utilize 200 hidden units with learning rate\n",
            "= 0.01 while these numbers are 100 and 0.06 respectively for the Dutch CoNLL\n",
            "dataset. Note that the number of hidden units is kept the same in both the\n",
            "encoding phase and the decoding phase.\n",
            "For word representation, we train the word embeddings for English from the\n",
            "Gigaword corpus augmented with the newsgroups data from BOLT (Broad Opera-\n",
            "5. http://www.cnts.ua.ac.be/conll2002/ner\n",
            "78\n",
            "  ID: a72aed77-9478-45a0-8eb0-bedac3cfb849\n",
            "--------------------\n",
            "Node 112:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "tional Language Technologies) (6 billion tokens) while the entire Dutch Wikipedia\n",
            "pages (310 million tokens) are extracted to train the Dutch word embeddings. We\n",
            "utilize theword2vec toolkit6 (modified to add the C-CBOW model) to learn the\n",
            "word representations. Following (Baroni et al.,2014), we use the context window\n",
            "of 5, subsampling set to 1e-05 and negative sampling with the number of instances\n",
            "set to 10. The dimension of the vectors is set to 300 to make it comparable with\n",
            "the word2vec toolkit. Finally, we use the standard IOB2 tagging schema for both\n",
            "ACE 2005 and Dutch CoNLL datasets.\n",
            "3.3.3 Model Architecture Evaluation\n",
            "In this section, we evaluate different RNN models by training the models on\n",
            "the news domain and report the performance on the development set. As pre-\n",
            "sented in the previous sections, we have 4 basic modelsM = {ELMAN, JORDAN,\n",
            "ELMAN_GRU, JORDAN_GRU} and 16 bidirectional models (4 choices for the\n",
            "encodinganddecodingmodels Re, Rd inM). Theperformanceforthebasicmodels\n",
            "and the bidirectional models are shown in Table3.2 and Table3.3 respectively7.\n",
            "Model(Rd) F1\n",
            "ELMAN 80.70\n",
            "JORDAN 80.46\n",
            "ELMAN_GRU 80.85\n",
            "JORDAN_GRU 81.06\n",
            "Table 3.2:The basic models’ performance\n",
            "There are several important observations from the three tables:\n",
            "6. https://code.google.com/p/word2vec\n",
            "7. The experiments in this section use C-CBOW to pre-train word embeddings.\n",
            "79\n",
            "  ID: 8741600b-2c52-4c4f-af13-6e32b2919efa\n",
            "--------------------\n",
            "Node 113:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "Rd Re ELMAN ELMAN_GRU\n",
            "ELMAN 80.99 81.42\n",
            "JORDAN 81.14 81.68\n",
            "ELMAN_GRU 80.53 81.16\n",
            "JORDAN_GRU 80.98 82.37\n",
            "Rd Re JORDAN JORDAN_GRU\n",
            "ELMAN 79.12 79.64\n",
            "JORDAN 79.21 80.85\n",
            "ELMAN_GRU 79.80 80.41\n",
            "JORDAN_GRU 79.76 81.02\n",
            "Table 3.3:The bidirectional models’ performance\n",
            "-Elman vs Jordan: In the encoding phase, the Elman models consistently out-\n",
            "perform the Jordan models when the same decoding model is applied in the bidirec-\n",
            "tional architecture. In the decoding phase, however, it turns out that the Jordan\n",
            "models are better most of the time over different model architectures (basic or\n",
            "bidirectional).\n",
            "-With vs Without GRUs: It is clear from the tables that GRUs are very helpful\n",
            "in the encoding part of the bidirectional architecture for MD. However, for the\n",
            "decoding part, we can only see the clear benefit of GRUs in the basic models and\n",
            "the bidirectional architecture whenRe is a Jordan model.\n",
            "-Regarding different model architectures, in general, the bidirectional models\n",
            "are more effective than the basic models, confirming the effectiveness of bidirec-\n",
            "tional modeling to achieve a richer representation for MD.\n",
            "The best basic model (F1 = 81.06%) and the best bidirectional model (F1 =\n",
            "82.37%) are called BASIC and BIDIRECT respectively. In the following, we only\n",
            "focus on these best models in the experiments.\n",
            "80\n",
            "  ID: 1683c7d5-9391-4156-8532-bab668da98b5\n",
            "--------------------\n",
            "Node 114:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "3.3.4 Comparison to other Bidirectional RNN W ork\n",
            "Mesnil et al.,2013 also present a RNN system with bidirectional modeling for\n",
            "the slot filling task. As described in Section3.1.3, the major difference between\n",
            "the bidirectional models in this work and (Mesnil et al.,2013)’s is the recurrence\n",
            "in our decoding phase. Table3.4 compares the performance of the bidirectional\n",
            "model from (Mesnil et al., 2013), called MESNIL, and the BIDIRECT model.\n",
            "In order to verify the effectiveness of recurrence in decoding, the performance\n",
            "of MESNIL incorporated with the JORDAN_GRU model in the decoding phase\n",
            "(MESNIL+JORDAN_GRU) is also reported.\n",
            "Model P R F1\n",
            "MESNIL (Mesnil et al., 2013) 81.01 79.67 80.33\n",
            "MESNIL + JORDAN_GRU 82.17 79.56 80.85\n",
            "BIDIRECT 82.91 81.83 82.37\n",
            "Table 3.4:Comparison to (Mesnil et al.,2013).\n",
            "In general, we see that the bidirectional model in this work is much better than\n",
            "the model in (Mesnil et al.,2013) for MD. This is significant withp <0:05 and\n",
            "a large margin (an absolute improvement of 2.04%). More interestingly, MESNIL\n",
            "is further improved when it is augmented with the JORDAN_GRU decoding,\n",
            "verifying the importance of recurrence in decoding for MD.\n",
            "3.3.5 W ord Embedding Evaluation\n",
            "The section investigates the effectiveness of different techniques to learn word\n",
            "embeddings to initialize the RNNs for MD. Table3.5 presents the performance\n",
            "81\n",
            "  ID: 2bd61b4e-c383-4319-b002-30c1e0c2ae79\n",
            "--------------------\n",
            "Node 115:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "of the BASIC and BIDIRECT models on the development set (trained onnews)\n",
            "when the CBOW, SKIP-GRAM and C-CBOW techniques are utilized to obtain\n",
            "word embeddings from the same English corpus. We also report the performance\n",
            "of the models when they are initialized with theword2vec word embeddings from\n",
            "(Mikolov et al.,2013b) (trained with the Skip-gram model on 100 billion words of\n",
            "Google News) (WORD2VEC). All of these word embeddings are updated during\n",
            "the training of the RNNs to induce the task-specific word embeddings . Finally,\n",
            "for comparison purpose, the performance for the following two scenarios is also\n",
            "included: (i) the word vectors are initialized randomly (not using any pre-trained\n",
            "word embeddings) (RANDOM), and (ii) the word vectors are loaded from the C-\n",
            "CBOW pre-trained word embeddings but fixed during the RNN training (FIXED).\n",
            "W ord Model\n",
            "Embeddings BASIC BIDIRECT\n",
            "RANDOM 79.30 79.76\n",
            "FIXED 80.36 81.52\n",
            "WORD2VEC 80.92 81.41\n",
            "CBOW 78.61 79.74\n",
            "SKIP-GRAM 81.45 81.96\n",
            "C-CBOW 81.06 82.37\n",
            "Table 3.5:Comparison of methods for word embeddings.\n",
            "The first observation is that we need to borrow some pre-trained word embed-\n",
            "dings and update them during the training process to improve the MD performance\n",
            "(comparing C-CBOW, RANDOM and FIXED). Second, C-CBOW is much better\n",
            "than CBOW, confirming our intuition in Section3.2. Third, we do not see much\n",
            "difference in terms of MD performance when we enlarge the corpus to learn word\n",
            "embeddings (comparing SKIP-GRAM and WORD2VEC that is trained with the\n",
            "82\n",
            "  ID: 30dba87f-606b-4284-b179-7dd085e452f7\n",
            "--------------------\n",
            "Node 116:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "skip-gram model on a much larger corpus). Finally, we achieve the best perfor-\n",
            "mance when we apply the C-CBOW technique in the BIDIRECT model. From now\n",
            "on, for consistency, we use the C-CBOW word embeddings in all the remaining\n",
            "experiments in this chapter.\n",
            "3.3.6 Cross-Domain Experiments\n",
            "This section evaluates the MD systems on the cross-domain settings to gain\n",
            "an insight into their operation when the domain changes. The state-of-the-art\n",
            "systems for MD have been the joint extraction system for entity mentions and\n",
            "relations from (Li and Ji,2014a), the information networks to unify the outputs\n",
            "of three information extraction tasks: entity mentions, relations and events using\n",
            "structured perceptron from (Li et al.,2014b) and the Maximum Entropy Markov\n",
            "Model (MEMM) system from (Florian et al.,2006). These systems extensively\n",
            "hand-design a large set of features (parsers, gazetteers, word clusters, coreference\n",
            "etc) to capture the useful structures for MD. In this work, we use the MEMM\n",
            "system in (Florian et al., 2006) as the baseline and compare it with the RNN\n",
            "systems. The reason for this choice is twofold: (i) as shown in Section 5.4 of (Li\n",
            "and Ji,2014a), the performance of the joint systems are comparable to the MEMM\n",
            "system in (Florian et al.,2006), and (ii) similar to our work, the MEMM system in\n",
            "(Florian et al.,2006) only focuses on the MD task while the joint systems in (Li and\n",
            "Ji, 2014a; Li et al.,2014b) involves the predictions for other tasks, making it less\n",
            "comparable to our work, especially on the cross-domain setting for MD. Evaluating\n",
            "the joint models in (Li and Ji,2014a; Li et al.,2014b) on the cross-domain setting\n",
            "83\n",
            "  ID: 59bee8d7-0917-42ed-98ed-d8686b031a54\n",
            "--------------------\n",
            "Node 117:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "for MD is another important dimension, however, out of the scope of the current\n",
            "work.\n",
            "We note that the performance of the MEMM system reported in this work is\n",
            "obtained from the actual system in (Florian et al.,2006) and the feature set of the\n",
            "MEMM8 system also includes the four features we are using in the RNN models\n",
            "(Section 3.1).\n",
            "Following the previous work on the cross-domain settings for the ACE 2005\n",
            "dataset (Nguyen et al.,2015c; Plank and Moschitti,2013), we treatnews as the\n",
            "source domain and the other domains:bc, cts, wl and un as the target domains.\n",
            "We then examine the systems on two scenarios: (i) the systems are trained and\n",
            "tested on the source domain via 5-fold cross validation (in-domain performance),\n",
            "and (ii) the systems are trained on the source domain but evaluated on the target\n",
            "domains. Besides, in order to understand the effect of the features on the systems,\n",
            "we report the systems’ performance both including and excluding the features\n",
            "described in Section3.1. Table3.6 presents the results.\n",
            "System Without Features With Features\n",
            "In-Domainbc cts wl un In-Domainbc cts wl un\n",
            "MEMM 76.90 71.73 78.02 66.89 67.77 82.55 78.33 87.17 76.70 76.75\n",
            "BASIC 79.01 77.06 85.42 73.00 72.93 81.99 78.75 86.51 76.60 76.94\n",
            "BIDIRECT80.00† 76.27†85.64†73.79†73.88† 82.52 79.65†88.43†76.7077.03\n",
            "Table 3.6: System’s performance on the cross-domain setting. Cells marked with\n",
            "†designate the BIDIRECT models that significantly outperform (p <0:05) the\n",
            "MEMM model on the specified domains.\n",
            "To summarize, we find that the RNN systems significantly outperform the\n",
            "MEMM system across\n",
            "  ID: a5c9cf69-e9c3-4811-9521-658d43895d01\n",
            "--------------------\n",
            "Node 118:\n",
            "  Text: summarize, we find that the RNN systems significantly outperform the\n",
            "MEMM system across all the target domains when the features are not applied.\n",
            "8. W e also tried the CRF model with the same feature set as the MEMM system but it is\n",
            "worse in our case.\n",
            "84\n",
            "  ID: 982c7012-b614-49c1-a8e6-1a0bb3c87d51\n",
            "--------------------\n",
            "Node 119:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "MEMM BIDIRECT BIDIRECT-MEMM\n",
            "bc cts wl un bc cts wl un bc cts wl un\n",
            "bc 75.20 86.60 70.25 72.38 75.49 87.51 70.75 73.04 0.29 0.91† 0.50† 0.66†\n",
            "cts 66.91 89.76 68.74 69.72 68.23 91.24 68.82 70.27 1.32† 1.48† 0.08 0.55†\n",
            "wl 74.94 86.53 77.07 75.90 74.73 86.79 76.35 75.37 -0.21 0.26 -0.72 -0.53\n",
            "un 72.72 86.75 72.04 73.47 73.53 88.29 73.16 74.00 0.81† 1.45† 1.12† 0.53†\n",
            "Table 3.7:Comparison between MEMM and BIDIRECT. Cells marked with †des-\n",
            "ignate the statistical significance (p <0:05). The columns and rows correspond\n",
            "to the source and target domains respectively. BIDIRECT-MEMM implies perfor-\n",
            "mance substraction.\n",
            "The BIDIRECT system still yields the best performance among systems being\n",
            "investigated (except in domainbc). This is also the case when the features from\n",
            "Section 3.1 are included and demonstrates the robustness of the BIDIRECT model\n",
            "in the domain shifts. We further support this result in Table3.7 where we report\n",
            "theperformanceoftheMEMMandBIDIRECTsystems(withfeatures)ondifferent\n",
            "domain assignments for the source and the target domains. Finally, we also see\n",
            "that the features are very useful for both the MEMM and the RNNs.\n",
            "3.3.7 Named Entity Recognition for Dutch\n",
            "The previous sections have dealt with mention detection for English. In this\n",
            "section, we want to explore the capacity of the systems to quickly and effectively\n",
            "adapt to a new\n",
            "  ID: bfab4eb1-8eab-4b18-a350-cf65667d54bf\n",
            "--------------------\n",
            "Node 120:\n",
            "  Text: we want to explore the capacity of the systems to quickly and effectively\n",
            "adapt to a new language. In particular, we evaluate the systems on the named\n",
            "entity recognition task (the simplified version of the MD task) for Dutch using\n",
            "the CoNLL 2002 dataset. The state-of-the-art performance for this dataset in\n",
            "the CoNLL evaluation is due to (Carreras et al.,2002) who utilize the AdaBoost\n",
            "classifier. In (Nothman et al.,2013), the authors leverage data from Wikipedia and\n",
            "85\n",
            "  ID: 74709a39-4882-4da7-b6ce-4277b022a66c\n",
            "--------------------\n",
            "Node 121:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "are able improve the state-of-the-art performance for Dutch. Very recently, while\n",
            "we are preparing this work, (Gillick et al.,2015) introduce a multilingual language\n",
            "processing system based on bytes and also report the performance on this dataset.\n",
            "Table3.8 compares the systems.\n",
            "System P R F1\n",
            "State-of-the-art in CoNLL 77.83 76.29 77.05\n",
            "Nothman et al.,2013 - - 78.60\n",
            "Gillick et al.,2015 - - 78.08\n",
            "Gil lick et al., 2015* - - 82.84\n",
            "MEMM 80.25 77.52 78.86\n",
            "BASIC 82.98 81.53 82.25\n",
            "BIDIRECT 84.08 82.82 83.45\n",
            "Table 3.8:Performance on Dutch CoNLL 2002.\n",
            "We note that the system in (Gillick et al.,2015) is also based on RNNs and\n",
            "the row labeled with * (Gillick et al.,2015) corresponds to the system trained\n",
            "on multiple datasets instead of the single CoNLL dataset for Dutch, so not being\n",
            "comparable to ours.\n",
            "The most important conclusion from the table is that the RNN models in\n",
            "this work significantly outperform MEMM as well as the other comparable system\n",
            "by large margins (up to 22% reduction in relative error). This proves that the\n",
            "proposed RNN systems are less subject to the language changes than MEMM and\n",
            "the other systems. Finally, BIDIRECT is also significantly better than BASIC,\n",
            "testifying to its robustness across languages.\n",
            "86\n",
            "  ID: 4ec632cf-1a1d-49d5-9609-c535df128f5a\n",
            "--------------------\n",
            "Node 122:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "3.4 Related W ork\n",
            "Both named entity recognition (Ando and Zhang, 2005; Bikel et al., 1997;\n",
            "Borthwick et al.,1997; Cherry and Guo,2015; Florian et al.,2003; Lin and Wu,\n",
            "2009; Miller et al.,2004; Passos et al.,2014; Ratinov and Roth,2009; Ritter et\n",
            "al., 2011; Sang and Meulder,2003; Suzuki and Isozaki,2008; Turian et al.,2010)\n",
            "and mention detection (Florian et al.,2004) have been extensively studied with\n",
            "various evaluation in the last decades: MUC6, MUC7, CoNLL’02, CoNLL’03 and\n",
            "ACE. The previous work on MD has examined the cascade models (Florian et al.,\n",
            "2006), transferred knowledge from rich-resource languages to low-resource ones via\n",
            "machine translation (Zitouni and Florian,2008) or improved the systems on noisy\n",
            "input (Florian et al., 2010). Besides, some recent work also tries to solve MD\n",
            "jointly with other tasks such as relation or event extraction to benefit from their\n",
            "inter-dependencies (Kate and Mooney,2010; Li and Ji, 2014a; Li et al., 2014b;\n",
            "Roth and Yih,2007). However, none of these work investigates RNNs for MD on\n",
            "the cross-domain and language settings as we do in this work.\n",
            "Regarding neural networks for NER, Collobert et al.,2011 propose a CNN-\n",
            "based framework while Mesnil et al.,2013 and Yao et al.,2013, 2014 investigate\n",
            "the RNNs for the slot filling problem in spoken language understanding. Although\n",
            "our work also examines the RNNs, we consider the mention detection problem with\n",
            "an emphasis on the robustness of the models in the domain shifts and language\n",
            "changes which has never been explored in the literature before.\n",
            "87\n",
            "  ID: ca4e2904-774b-4e8f-8ea3-9fc3bedc2aa2\n",
            "--------------------\n",
            "Node 123:\n",
            "  Text: CHAPTER 3. DEEP LEARNING FOR ENTITY MENTION DETECTION\n",
            "3.5 Conclusion\n",
            "We systematically investigate various RNNs to solve the MD problem which\n",
            "suggests that bidirectional modeling is a very helpful mechanism for this task.\n",
            "In particular, the bidirectional model outperforms a very strong baseline of the\n",
            "feature-based exponential models in the cross-domain setting, thus demonstrating\n",
            "its robustness across domains. We also show that the bidirectional model is more\n",
            "portable to new languages as it is significantly better than the best reported sys-\n",
            "tems for NER in Dutch (up to 22% reduction in relative error). In the future,\n",
            "we plan to apply the bidirectional modeling technique to other tasks as well as\n",
            "study the combination of different network architectures and resources to further\n",
            "improve the performance of the systems.\n",
            "88\n",
            "  ID: e7cdb4ea-2394-492f-81e2-c108df63bce0\n",
            "--------------------\n",
            "Node 124:\n",
            "  Text: Chapter 4\n",
            "Deep Learning for Relation\n",
            "Extraction\n",
            "Thischapterpresentsseveraldeeplearningmodelsforrelationextraction. There\n",
            "are two major parts in this chapter. The first part introduces a convolutional neu-\n",
            "ral network that do not require feature engineering for relation extraction while\n",
            "the second part aims at the other extreme, exploring the combination of convo-\n",
            "lutional neural networks, recurrent neural networks and feature engineering to\n",
            "achieve the state-of-the-art RE performance. The words in this chapter are pub-\n",
            "lished in (Nguyen and Grishman,2015a) and (Nguyen and Grishman,2016c).\n",
            "89\n",
            "  ID: d7ba03e9-5efe-4d20-9691-ff966dc56f09\n",
            "--------------------\n",
            "Node 125:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.1 Convolutional Neural Networks for Relation\n",
            "Extraction\n",
            "The relation extraction (RE) task can be divided into two steps: detecting if a\n",
            "relation mention corresponding to some entity mention pair of interest represents\n",
            "some relation and classifying the detected relation mentions into some predefined\n",
            "classes. If we only need to categorize the given relation mentions that are known\n",
            "to express some expected relation (perfect detection), we are left with therelation\n",
            "classification (RC) task. One variation of relation classification is that one might\n",
            "have non-relation examples in the dataset but the number of those is compara-\n",
            "ble to the number of the other examples. The non-relation examples, therefore,\n",
            "can be treated as a usual relation class. Relation extraction, on the other hand,\n",
            "often comes with a tremendously unbalanced dataset where the number of the\n",
            "non-relation examples far exceeds the others, making relation extraction more chal-\n",
            "lenging but more practical than relation classification. Our present work focuses\n",
            "on the relation extraction task with an unbalanced corpus.\n",
            "As we can see in Chapter2, traditional RE systems require extensive feature\n",
            "engineering and rely on existing natural language processing (NLP) modules to\n",
            "analyze relation mentions and extract features, including part of speech taggers,\n",
            "chunkers, name taggers, and parsers. Besides the costly effort for feature engineer-\n",
            "ing, the traditional relation extractors might be subject to the error propagation\n",
            "introduced by the imperfect quality of the supervised existing NLP toolkits. For\n",
            "instance, all the tasks mentioned above are known to suffer from a performance\n",
            "90\n",
            "  ID: 9da9b3d5-27aa-4563-9a85-9fc49c59f882\n",
            "--------------------\n",
            "Node 126:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "loss when they are applied to out-of-domain data (Blitzer et al.,2006; Daume,\n",
            "2007; McClosky et al., 2010), causing the collapse of the RE systems based on\n",
            "them. In this section, we target an independent RE system that both avoids com-\n",
            "plicated feature engineering and minimizes the reliance on the supervised NLP\n",
            "modules for features, potentially alleviating the error propagation and advancing\n",
            "our performance in this area.\n",
            "To be concrete, our relation extraction system is provided only with raw sen-\n",
            "tences marked with the positions of the two entities of interest1. The only elements\n",
            "we can derive from this structure are the words, thek-grams and their positions in\n",
            "the sentences, suggesting a paradigm in which relation mentions are represented\n",
            "by features that depend on these elements. Eventually, word embeddings that are\n",
            "capable of capturing latent semantic and syntactic properties of words (Bengio\n",
            "et al.,2003; Collobert and Westion,2008; Mikolov et al.,2013b; Mnih and Hinton,\n",
            "2008; Turian et al.,2010) and convolutional neural networks (CNN) that are able\n",
            "to recognize specific classes ofk-gram and induce more abstract representations\n",
            "(Kalchbrenner et al.,2014) are a natural combination one should apply to obtain\n",
            "more effective representations for RE in this setting.\n",
            "Convolutional neural networks (dating back to the 1980s) are a type of feed-\n",
            "forward artificial neural networks whose layers are formed by a convolution opera-\n",
            "tion followed by a pooling operation (Kalchbrenner et al.,2014; LeCun et al.,1988).\n",
            "Recently, with the emerging interests of the community in deep learning, CNNs\n",
            "have been revived and effectively applied in various NLP tasks, including semantic\n",
            "1. F or evaluation purpose, we assume the positions of the two entities of interest in the\n",
            "sentences like most previous studies in this area. These are the only external features we need\n",
            "to achieve an end-to-end relation extractor.\n",
            "91\n",
            "  ID: f586c865-e37a-42e0-ab05-678a2a15b9e4\n",
            "--------------------\n",
            "Node 127:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "parsing (Yih et al., 2014), search query retrieval (Shen et al.,2014a), sentence\n",
            "modeling and classification (Kalchbrenner et al.,2014; Kim,2014), name tagging\n",
            "and semantic role labeling (Collobert et al.,2011). For relation classification and\n",
            "extraction, there are two prior works on CNNs for relation classification (Liu et al.,\n",
            "2013)2 and (Zeng et al.,2014); however, to the best of our knowledge, there has\n",
            "been no work on employing CNNs for relation extraction so far. This work is the\n",
            "first attempt to fill in that gap and serves as a baseline for future research in this\n",
            "area.\n",
            "Our convolutional neural network is built upon that of (Kalchbrenner et al.,\n",
            "2014) and (Kim,2014) which are originally proposed for sentence classification and\n",
            "modeling. We adapt the network for relation extraction by introducing the posi-\n",
            "tion embeddings to encode the relative distances of the words in the sentence to\n",
            "the two entities of interest. Compared to the models in (Liu et al.,2013) and (Zeng\n",
            "et al.,2014) for relation classification that apply a single window size, our model\n",
            "for relation extraction incorporates various window sizes for convolutional filters,\n",
            "allowing the network to capture wider ranges ofk-grams to be helpful for relation\n",
            "extraction. In addition, rather than initializing the word embeddings randomly\n",
            "as do (Liu et al.,2013) and fixing the randomly generated position embeddings\n",
            "during training as do (Zeng et al.,2014), we use pre-trained word embeddings\n",
            "for initialization and optimize both word embeddings and position embeddings as\n",
            "model parameters. More importantly, rather than using exterior features (either\n",
            "from human annotation or other pre-processing modules) to enrich the represen-\n",
            "2. The title of the paper (Liu et al., 2013) on relation extraction is misleading since the\n",
            "authors actually do relation classification, according to the experimental description.\n",
            "92\n",
            "  ID: 2b7f5375-8cc3-4ffb-8d0c-cec42e9769b0\n",
            "--------------------\n",
            "Node 128:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "tation as do (Liu et al.,2013) and (Zeng et al.,2014), our model (adapted for\n",
            "RC where entity heads are given) avoids usage of manual linguistic resources and\n",
            "supervised NLP toolkits constructed externally, utilizing word embeddings that\n",
            "can be trained automatically in an unsupervised framework as the only external\n",
            "resource for the whole system.\n",
            "We explore different model architectures systematically and demonstrate that\n",
            "the best model performance is achieved when multiple window sizes are imple-\n",
            "mented and the wordembeddings, once initialized bysome “universal”embeddings,\n",
            "are allowed to vary during the optimization process to reach an effective state for\n",
            "relation extraction. We evaluate our models on both relation classification and\n",
            "relation extraction tasks. For relation classification, experiments show that our\n",
            "model (without any external features and resources) outperforms the state-of-the-\n",
            "art models whether the external features are included in these models or not. For\n",
            "relation extraction, our model is significantly better than the baseline models that\n",
            "use the words and the embeddings themselves as the features.\n",
            "4.1.1 Model\n",
            "Our convolutional neural network for relation extraction consists of four main\n",
            "layers: (i) the look-up tables to encode words in sentences by real-valued vectors,\n",
            "(ii) the convolutional layer to recognizek-grams, (iii) the pooling layer to determine\n",
            "the most relevant features and (iv) a logistic regression layer (a fully connected\n",
            "neural network with a softmax at the end) to perform classification (Collobert et\n",
            "al., 2011; Kalchbrenner et al.,2014; Kim, 2014). Figure 4.1 gives an overview of\n",
            "93\n",
            "  ID: 1348aaee-9b9e-402d-b03e-5a16d029c499\n",
            "--------------------\n",
            "Node 129:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "In the morning, the <e1>President</e1> traveled to <e2>Detroit</e2> \n",
            "in\n",
            "the\n",
            "morning,\n",
            "the\n",
            "president\n",
            "traveled\n",
            "to\n",
            "detroit\n",
            "entity 1\n",
            "entity 2\n",
            "input sentence with marked entities\n",
            "word embedding matrix\n",
            "position embeddings matrix\n",
            "table look-up\n",
            "      Convolutional layer \n",
            "with multiple window sizes \n",
            "            for filters\n",
            "Max pooling Fully connected layer\n",
            "    with dropout and\n",
            "      softmax output\n",
            "Look-up tables\n",
            "Figure 4.1: Convolutional Neural Network for Relation Extraction.\n",
            "the network.\n",
            "4.1.1.1 W ord Representation\n",
            "The input to the CNN for relation extraction consists of sentences marked\n",
            "with the two entity mentions of interest. As CNNs can only work with fixed length\n",
            "inputs, we compute the maximal separation between entity mentions linked by a\n",
            "relation and choose an input width greater than this distance. We insure that\n",
            "every input (relation mention) has this length by trimming longer sentences and\n",
            "padding shorter sentences with a special token.\n",
            "Let nbe the length of the relation mentions andW = [ w1;w2;:::;w n] be some\n",
            "94\n",
            "  ID: b471db29-e22a-4c84-bc06-2058adeb314d\n",
            "--------------------\n",
            "Node 130:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "relation mention where wi is the i-th word in the mention. Also, let wi1 and\n",
            "wi2 be the two heads of the two entity mentions of interest. Before entering the\n",
            "network, each wordwi is first transformed into a vectorembi by looking up the\n",
            "word embedding tableEMB that can be initialized either by a random process or\n",
            "by some pre-trained word embeddings. Besides, in order to embed the positions\n",
            "of the two entity heads as well as the other words in the relation mention into the\n",
            "representation, for each wordwi, its relative distances to the two entity headsi\u0000i1\n",
            "and i\u0000i2 are also mapped into real-value vectorsdisti1 and disti2 respectively using\n",
            "a position embedding tableDIST (initialized randomly) (Collobert et al.,2011; Liu\n",
            "et al., 2013; Zeng et al.,2014). Note that the relative distances only range from\n",
            "\u0000n+ 1 to n\u00001 so the position embedding matrixDIST has size(2n\u00001) \u0002md\n",
            "(md is a hyperparameter indicating the dimensionality of the position embedding\n",
            "vectors).\n",
            "Finally, the word embeddingsembi and the position embeddingsdist1 and dist2\n",
            "are concatenated into a single vectorxi = [ embi;disti1;disti2]⊤ to represent the\n",
            "word wi. As a result, the original sentenceW can now be viewed as a matrixX of\n",
            "size (me+ 2md) \u0002nwhere me is the dimensionality of the word embedding vectors.\n",
            "X = [ x1;x2;:::;x n] (4.1)\n",
            "4.1.1.2 Convolution\n",
            "In the next step, the matrixX representing the input relation mention is fed\n",
            "into the convolutional layer to extract higher level features. Given a widow size\n",
            "95\n",
            "  ID: fb1c109a-bd74-4400-88a9-502eb2c8be10\n",
            "--------------------\n",
            "Node 131:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "k, a filter is seen as a weight matrixf = [ f1;f2;:::; fk] (fi is a column vector of\n",
            "size me + 2 md). The core of this layer is obtained from the application of the\n",
            "convolutional operator on the two matricesX and f to produce a score sequence\n",
            "s = [ s1;s2;:::;s n\u0000k+1]:\n",
            "si = g(\n",
            "k\u00001∑\n",
            "j=0\n",
            "f⊤\n",
            "j+1x⊤\n",
            "j+i + b) (4.2)\n",
            "where b is a bias term andg is some non-linear function.\n",
            "This process can then be replicated for various filters with different window\n",
            "sizes to increase thek-gram coverage of the model.\n",
            "For relation extraction, we call thek-grams accompanied with relative positions\n",
            "of its words the augmentedk-grams. It is instructive to think about the filterf\n",
            "as representing some hidden class of the augmentedk-grams and the scores si\n",
            "as measuring the possibility the augmentedk-gram at position i belongs to the\n",
            "corresponding hidden class (although these scores are not probabilities at all). The\n",
            "trained weights of the filterf would then amount to a feature detector that learns\n",
            "to recognize the hidden class of the augmentedk-grams (Kalchbrenner et al.,2014).\n",
            "4.1.1.3 Pooling\n",
            "The rationale of the pooling layer is to further abstract the features generated\n",
            "from the convolutional layer by aggregating the scores for each filter to introduce\n",
            "the invariance to the absolute positions but preserve the relative positions of the\n",
            "k-grams between themselves and the entity heads at the same time. The popular\n",
            "aggregating function is max as it bears responsibility for identifying the most\n",
            "96\n",
            "  ID: e95e3bff-5886-4cf2-b7e0-d309741983ea\n",
            "--------------------\n",
            "Node 132:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "important or relevant features from the score sequence. Concretely, for each filterf,\n",
            "its score sequences is passed through themax function to produce a single number:\n",
            "pk\n",
            "f = max fsg= max fs1;s2;:::s n\u0000w+1gwhich can be interpreted as estimating the\n",
            "possibility some augmentedk-gram of the hidden class off appears in the context.\n",
            "4.1.1.4 Regularization and Classification\n",
            "In the final step, the pooling scores for every filter are concatenated into a\n",
            "single feature vectorz = [ p1;p2;:::;p m] to represent the relation mention. Here,\n",
            "mis the number of filters in the model andpi is the pooling score of thei-th filter.\n",
            "Before actually applying this feature vector, following (Kim,2014; Srivastava et\n",
            "al., 2014), we execute a dropout for regularization by randomly setting to zero\n",
            "a proportion \u001a of the elements of the feature vector3 z to produce the vectorzd.\n",
            "The dropout vectorzd is then fed into a fully connected layer of standard neural\n",
            "networks followed by a softmax layer in the end to perform classification. The fully\n",
            "connected layer induces a weight matrixFULL as model parameters.\n",
            "At test time, the unseen relation mentions are scored using the feature vectors\n",
            "that are not dropped out. We also rescale the weights whose Frobenius norms\n",
            "exceed a hyperparameter as (Kim,2014).\n",
            "Overall, the parameters for the presentedCNN are: the wordembedding matrix\n",
            "EMB, the position embedding matrixDIST, themfilter matrices, and the weight\n",
            "matrixFULL for the fully connected layer. The gradients are computed using back-\n",
            "propagation while training is done via stochastic gradient descent with shuffled\n",
            "mini-batches and the AdaDelta update rule (Kim,2014; Zeiler,2012).\n",
            "3. F ollowing the Bernoulli distribution.\n",
            "97\n",
            "  ID: 1cca3ac1-276a-455d-bf8f-6f2f228fe507\n",
            "--------------------\n",
            "Node 133:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.1.2 Experiments\n",
            "4.1.2.1 Hyperparameters and Resources\n",
            "For all the experiments below, we use:tanh for the non-linear function, 150\n",
            "filters for each window size in the model and position embedding vectors with\n",
            "dimensionality of md = 50 4. Regarding the other parameters, we use the same\n",
            "values as do (Kim,2014), i.e, the dropout rate\u001a= 0 :5, the mini-batch size of 50,\n",
            "the hyperparameter for the Frobenius norms of 3.\n",
            "Finally, we utilize the pre-trained word embeddingsword2vec from (Mikolov\n",
            "et al.,2013b) which have dimensionality ofme = 300 and are trained on 100 bil-\n",
            "lion words of Google News using the continuous bag-of-words architecture. These\n",
            "embeddings are publicly available here5. Vectors for the words not included in the\n",
            "pre-trained embeddings are initialized randomly. Besides the word embeddings\n",
            "word2vec, the model does not use any other NLP toolkits or resources.\n",
            "4.1.2.2 Datasets\n",
            "We evaluate our models on two datasets: the SemEval-2010 Task 8 dataset\n",
            "(Hendrickx et al.,2010) for relation classification and the ACE 2005 dataset for\n",
            "relation extraction.\n",
            "The SemEval dataset can be downloaded here6 and contains 10,717 annotated\n",
            "examples, including 8,000 examples for training and 2,717 examples for testing.\n",
            "Each example is a sentence annotated for a pair of entities of interest and the\n",
            "4. These values produce the best performance during our experimental process.\n",
            "5. https://code.google.com/p/word2vec\n",
            "6. http://docs.google.com/View?id=dfvxd49s36c28v9pmw\n",
            "98\n",
            "  ID: 2b053378-e1fb-4ef4-881b-e9e249cc6c64\n",
            "--------------------\n",
            "Node 134:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "corresponding relation class for this entity pair. There are 9 ordered relationships\n",
            "(with two directions) and an undirectedOther class, resulting in 19 classes. A pair\n",
            "is counted as correct if the order of the entities in the relationship is correct. For\n",
            "the ACE 2005 dataset, documents are annotated for 6 major relation classes and\n",
            "7 entity types. In order to generate the non-relation examples or the examples for\n",
            "the Other class, we collect every pair of entity mentions within a single sentence\n",
            "and not included in the annotated relation set. To reduce the noise, we truncate\n",
            "the generated dataset by removing all the examples whose distances between the\n",
            "two entity heads are greater than 15. This results in a considerably unbalanced\n",
            "dataset of 8,365 positive examples of the 6 annotated relation classes and 79,147\n",
            "negative examples of the classOther. The distributions of the relation classes on\n",
            "the two datasets are shown in Table4.1. As we can see, the ACE dataset is much\n",
            "more biased toward theOther class than the SemEval dataset and thus more ap-\n",
            "propriate for relation extraction experiments.\n",
            "4.1.2.3 Evaluation of Model Architectures\n",
            "We investigate the effectiveness of different window sizes of filters by running\n",
            "the proposed CNN model on window sizes of 2, 3, 4 and 5. To understand the\n",
            "behavior of the model on multiple window sizes, we further test it on the following\n",
            "window size combinations: (4,5), (3,4,5) and (2,3,4,5). In each of these window size\n",
            "configurations, we evaluate the system on three different scenarios: (i) the word\n",
            "embeddings and the position embeddings are randomly initialized and optimized\n",
            "99\n",
            "  ID: 1a05846f-f62d-4e1f-9a05-812750776bf2\n",
            "--------------------\n",
            "Node 135:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "ACE 2005 (87,512) SemEval 2010 (10,717)\n",
            "Relation % Relation %\n",
            "ORG-AFF 2.8 Cause-Effect 12.4\n",
            "PER-SOC 1.2 Component-Whole 11.7\n",
            "ART 1.0 Entity-Destination 10.6\n",
            "PART-WHOLE 1.4 Entity-Origin 9.1\n",
            "GEN-AFF 1.1 Product-Producer 8.8\n",
            "PHYS 2.1 Member-Collection 8.6\n",
            "Other 90.4 Message-Topic 8.4\n",
            "Content-Container 6.8\n",
            "Instrument-Agency 6.2\n",
            "Other 17.4\n",
            "Table 4.1:ACE 2005 and SemEval 2010 relation class distributions.\n",
            "during the training process (denoted bynonstatic.rand), (ii) the word embeddings\n",
            "are initialized by the pre-trained word embeddings; the position embeddings are\n",
            "initialized randomly and the two embeddings are kept unchanged during the train-\n",
            "ing (denoted by static.word2vec), (iii) the two embeddings are initialized as in\n",
            "case (ii) but they are optimized as model parameters when the model is trained\n",
            "(denoted by nonstatic.word2vec). These experiments are carried out for relation\n",
            "extraction on the ACE 2005 dataset via 5-fold cross validation. Table4.2 presents\n",
            "the system performance on Precision (P), Recall (R) and F1 score (F).\n",
            "The key observations from the table are7:\n",
            "(i) From rows 1, 2, 3, 4, we see that evaluating window sizes individually is\n",
            "quite intricate. It is unclear which window size is the best size for CNNs on relation\n",
            "extraction. For instance, on thenonstatic.rand mode, the window size 4 seems to\n",
            "outperform the others while on the other modes, the window sizes 3 and 5 turn out\n",
            "7. The statements at points (ii) and (iii) are significant at confidence levels \u001595%.\n",
            "100\n",
            "  ID: e5d1b7da-9b48-4f06-ae97-5496a2f7f0e7\n",
            "--------------------\n",
            "Node 136:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "nonstatic.rand static.word2vec nonstatic.word2vec\n",
            "# window sizes P R F P R F P R F\n",
            "1 2 69.56 41.64 52.04 74.66 41.03 52.90 72.74 49.49 58.87\n",
            "2 3 68.47 42.73 52.57 74.19 42.16 53.73 72.50 50.75 59.66\n",
            "3 4 68.17 43.39 52.94 73.60 41.90 53.35 72.56 49.81 58.97\n",
            "4 5 66.83 43.46 52.55 73.52 42.60 53.89 71.70 51.08 59.57\n",
            "5 4-5 66.18 46.12 54.25 72.69 45.23 55.71 71.88 52.36 60.50\n",
            "6 3-4-5 67.54 45.73 54.43 71.99 46.85 56.73 71.21 53.24 60.86\n",
            "7 2-3-4-5 66.42 47.20 55.12 72.60 46.77 56.85 71.25 53.91 61.32\n",
            "Table 4.2:System performance on various window size combinations and architec-\n",
            "tures.\n",
            "to be better. Besides, the performance gaps between the window sizes are small,\n",
            "making it hard to draw a conclusive judgement. In any case, the window size 2\n",
            "seems to be the worst, suggesting that the 2-grams might be less informative than\n",
            "the others on representing relation mentions for CNNs on this dataset.\n",
            "(ii) While the results on evaluating single window sizes are hard to analyze, the\n",
            "results for multiple window sizes are quite clear and conclusive. Moving from single\n",
            "window sizes of 2, 3, 4 or 5 (rows 1, 2, 3 and 4 respectively) to\n",
            "  ID: cc4c34f3-e473-4f14-b374-166a9936a600\n",
            "--------------------\n",
            "Node 137:\n",
            "  Text: or 5 (rows 1, 2, 3 and 4 respectively) to the configuration\n",
            "with two window sizes 4 and 5 (row 5) gives us consistent improvements on all the\n",
            "model architectures. The performance is then consistently enhanced when more\n",
            "window sizes are included, resulting in the best performance when all the window\n",
            "sizes 2, 3, 4 and 5 are employed. This demonstrates the advantages of the models\n",
            "with multiple window sizes over the single window size models in (Liu et al.,2013)\n",
            "and (Zeng et al.,2014).\n",
            "(iii) Regarding different model architectures, the picture is even clearer. No\n",
            "matter which window size configuration is applied, we constantly see thenon-\n",
            "static.word2vec architectureperformsmosteffectively, followedbythe static.word2vect\n",
            "101\n",
            "  ID: 77296035-f799-4b20-a032-9cfc67dfa8af\n",
            "--------------------\n",
            "Node 138:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "setting which is in turn followed by thenonstatic.rand model. This suggests the\n",
            "undeniable benefits of initializing the word embeddings by some “universal” pre-\n",
            "trained values and updating the embeddings to reflex RE specific embeddings when\n",
            "training the models (Collobert et al.,2011; Kim,2014). For the next experiments,\n",
            "we always use all the window sizes 2, 3, 4 and 5 with thenonstatic.word2vec archi-\n",
            "tecture.\n",
            "4.1.2.4 Relation Extraction Experiment\n",
            "We compare our system with the traditional feature-based relation extraction\n",
            "systems when these system are only allowed to use the same information and\n",
            "resources as our systems, i.e, the words in the relation mentions, the positions of\n",
            "the two entity heads and the word embeddings.\n",
            "Given the sentences and the positions of the two entity heads, the features\n",
            "that the state-of-the-art feature-based systems extract include: the heads of the\n",
            "two entity mentions; the words in the context before mention 1; after mention 2\n",
            "and between two mentions; the bigrams, the word sequences between two entities,\n",
            "the order of two mentions, the number of words between two mentions (Jiang and\n",
            "Zhai, 2007a; Sun et al.,2011; Zhou et al.,2005). The feature-based system using\n",
            "this feature set is calledW ords. Armed with the word embeddings, one can fur-\n",
            "ther introduce these embeddings into the head words or the words in the context\n",
            "as additional features (Nguyen and Grishman,2014a). We call the systemW ords\n",
            "augmented with the embeddings for the two headsW ords-HM-W edand W ordsaug-\n",
            "mented with the embeddings for words in the contextsW ords-WC-W ed. We apply\n",
            "102\n",
            "  ID: 2cbc3e8c-16e1-4ab2-8d5e-56aedf7cf4dd\n",
            "--------------------\n",
            "Node 139:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "the MaxEnt framework with L2 regularization in the Mallet toolkit8 to train these\n",
            "feature-based models (as (Jiang and Zhai,2007a; Nguyen and Grishman,2014a;\n",
            "Sun et al.,2011)). Table4.3 shows the performance of the three baseline systems\n",
            "and our proposed CNN via 5-fold cross validation on the ACE 2005 dataset.\n",
            "System P R F\n",
            "Words 54.95 43.73 48.69\n",
            "Words-WC-Wed 50.10 44.47 47.11\n",
            "Words-HM-Wed 57.01 55.74 56.36\n",
            "Our CNN 71.25 53.91 61.32\n",
            "Table 4.3:Performance of relation extraction systems.\n",
            "The first observation is that adding the word embeddings to the words in the\n",
            "context hurt the performance of the feature-based systems while augmenting the\n",
            "heads of the entitieswith word embeddings significantlyimproves the feature-based\n",
            "systems. This is consistent with the results reported by (Nguyen and Grishman,\n",
            "2014a) and demonstrates that the ability to wisely pick the words for embeddings\n",
            "and avoid embeddings on specific locations is crucial to the feature-based systems.\n",
            "More importantly, our proposed CNN significantly outperforms all the baseline\n",
            "models at the confidence levels\u001595%, an improvement of 4.96% over the best\n",
            "feature-based systemW ords-HM-W ed(Nguyen and Grishman,2014a). This result\n",
            "indicates that CNNs are a better way to employ word embeddings for relation\n",
            "extraction.\n",
            "Remember that although the traditional systems can achieve a performance\n",
            "greater than 72% on the ACE dataset (Qian et al.,2008; Sun et al.,2011), they\n",
            "8. http://mallet.cs.umass.edu\n",
            "103\n",
            "  ID: cd248046-7a23-43ef-a852-3cabe993b94b\n",
            "--------------------\n",
            "Node 140:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "come at the expense of elaborate feature engineering as well as much more expen-\n",
            "sive feature extraction. In particular, the feature extractors of these feature-based\n",
            "systems require: (i) the perfect entity and mention type information hand-labeled\n",
            "laboriously by human annotators; (ii) the extensive usage of the existing super-\n",
            "vised NLP toolkits and resources (constituent and dependency parsers, dictionar-\n",
            "ies, gazetteers etc) which might be unavailable for various domains in reality. The\n",
            "absence of the perfect (hand-annotated) entity and mention type information (i.e,\n",
            "point (i) above) greatly impairs these feature-based systems’ performance. For\n",
            "instance, both (Plank and Moschitti,2013) and (Nguyen and Grishman,2014a)\n",
            "report a performance less than 60% on the ACE 2005 dataset when the perfect\n",
            "entity type and mention type features are not employed although the other fea-\n",
            "tures with extensive feature engineering (i.e point (ii) above) are still included. As\n",
            "a result, in a more realistic setting where hand-annotated features are prohibitive,\n",
            "the proposed CNN requires much less feature engineering and resources but still\n",
            "performs better than the traditional feature-based systems.\n",
            "4.1.2.5 Relation Classification Experiment\n",
            "In order to further verify the effectiveness of the system, we test the system\n",
            "on the relation classification task with the SemEval 2010 dataset and compare the\n",
            "results with the state-of-the-art systems in this area. Table4.9 describes the perfor-\n",
            "mance of various traditional systems that are based on classifiers such as MaxEnt\n",
            "and SVM with series of supervised and manual features9 (Hendrickx et al.,2010)\n",
            "9. i.e the features extracted from supervised pre-processing NLP modules and manual re-\n",
            "sources.\n",
            "104\n",
            "  ID: af989265-e1c8-48d5-aac5-b1146f84c2e1\n",
            "--------------------\n",
            "Node 141:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "as well as the more recent systems based on convolutional neural networks (Zeng\n",
            "et al.,2014) (O-CNN), recursive neural networks (RNN), matrix-vector recursive\n",
            "neural networks (MVRNN) (Socher et al.,2012b) or log-quadratic factor-based\n",
            "compositional embedding model (FCM) (Yu et al.,2014)10.\n",
            "As we can see, among the systemsnot using any supervised and manual features\n",
            "(i.e, POS, WordNet, name tagging, dependency parse, patterns etc), our system\n",
            "significantly outperforms the state-of-the-art system FCM (80.6%) (Yu et al.,2014)\n",
            "with an improvement of 2.2%. More interestingly, even without supervised and\n",
            "manual features, our system can still work comparably to the other systems utiliz-\n",
            "ing these features as the vital components. For instance, the supervised features\n",
            "(dependency parse and name tagging) are crucial to FCM (Yu et al.,2014) to\n",
            "significantly improve its performance. We attribute our performance advantage\n",
            "over the closely-related system O-CNN (Zeng et al.,2014) to the multiple window\n",
            "sizes, the optimization of the position embeddings during training and possibly the\n",
            "superiority of the embeddingsword2vec we use.\n",
            "4.1.2.6 Impact of Unbalanced Dataset\n",
            "Shifting from relation classification to relation extraction with an unbalanced\n",
            "corpus, we witness a large performance gap as described above. In this section,\n",
            "we study the impact of the unbalanced corpus on the performance of relation ex-\n",
            "tractors for both convolutional neural networks and traditional feature-based ap-\n",
            "proaches (W ordsand W ords-HM-W ed). In particular, we vary the ratio of positive\n",
            "(true relations) and negative (the classOther) examples in the ACE 2005 dataset\n",
            "10. These are the macro-averaged F1-scores, computed by the officially provided scorer.\n",
            "105\n",
            "  ID: 25ab103e-aba6-4a34-8345-211efec1be7c\n",
            "--------------------\n",
            "Node 142:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "Classifier Feature Sets F\n",
            "SVM POS, WordNet, morpho-\n",
            "logical features, thesauri,\n",
            "Google k-grams\n",
            "77.6\n",
            "MaxEnt POS, WordNet, morpho-\n",
            "logical features, noun\n",
            "compound system, the-\n",
            "sauri, Googlek-grams\n",
            "77.6\n",
            "SVM POS, WordNet, prefixes\n",
            "and other morphological\n",
            "features, dependency\n",
            "parse, Levin classes,\n",
            "PropBank, FrameNet,\n",
            "NomLex-Plus, Google\n",
            "k-grams, paraphrases,\n",
            "TextRunner\n",
            "82.2\n",
            "RNN - 74.8\n",
            "RNN POS, name tagging,\n",
            "WordNet\n",
            "77.6\n",
            "MVRNN - 79.1\n",
            "MVRNN POS, name tagging,\n",
            "WordNet\n",
            "82.4\n",
            "O-CNN - 78.9\n",
            "O-CNN WordNet 82.7\n",
            "FCM - 80.6\n",
            "FCM dependency parse, name\n",
            "tagging\n",
            "83.0\n",
            "Our\n",
            "CNN\n",
            "- 82.8\n",
            "Table 4.4:Performance of relation classification systems.\n",
            "106\n",
            "  ID: d60471f0-7952-419c-b2a0-1cf611b25e66\n",
            "--------------------\n",
            "Node 143:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "0 0:5 1 1:5 2 2:5 3\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "1 + log 10( #positive\n",
            "#negative)\n",
            "F-measure W ords\n",
            "W ords-HM-W ed\n",
            "Our CNN\n",
            "Figure 4.2: F measures vs positive/negative ratios\n",
            "and see how the system performance responds to this variation. Figure4.2 shows\n",
            "the curves. This is a 5-fold cross validation experiment and all the comparisons\n",
            "are significant at confidence levels\u001595%.\n",
            "From the figure, we see that all the models improve constantly with the increase\n",
            "of the ratio of the positive and negative examples. The performance peaks with\n",
            "an improvement of about 20% for all models when the number of examples of the\n",
            "class Other is small relative to the others. In other words, the systems attain their\n",
            "best performance when relation extraction is reduced to the relation classification\n",
            "problem, suggesting that relation extraction is much more challenging than rela-\n",
            "tion classification. Finally, for all the ratio values, we consistently see that the\n",
            "convolutional neural network is superior to the others, once again confirming its\n",
            "107\n",
            "  ID: 37f6b7fc-6eab-4dab-b753-2d181fe96eae\n",
            "--------------------\n",
            "Node 144:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "advantages.\n",
            "4.2 Combining Neural Networks and Log-linear\n",
            "Models to Improve Relation Extraction\n",
            "Aswehavediscussed in Chapter 2, the feature-based method forRE extensively\n",
            "leveraged linguistic analysis and knowledge resources to construct the feature repre-\n",
            "sentations, involving the combination ofdiscrete properties such as lexicon, syntax,\n",
            "and gazetteers. This approach is able to exploit the symbolic (discrete) structures\n",
            "within relation mentions; however they suffer from the difficulty to generalize over\n",
            "the unseen words (Gormley et al.,2015), motivating some very recent work on\n",
            "employing thecontinuous representations of words (word embeddings) to do RE\n",
            "(Nguyen and Grishman,2014a; Nguyen et al.,2015c). The most popular method\n",
            "involves neural networks (NNs) that effectively learn hidden and continuous struc-\n",
            "tures of relation mentions from such word embeddings, thus achieving the top\n",
            "performance for RE (Nguyen and Grishman,2015a; Santos et al.,2015a; Xu et al.,\n",
            "2015; Zeng et al.,2014).\n",
            "The NN research for relation extraction and classification so far has centered\n",
            "around two main network architectures: convolutional neural networks (CNN)11\n",
            "(Nguyen and Grishman, 2015a; Santos et al., 2015a; Zeng et al., 2015) and re-\n",
            "cursive/recurrent neural networks (Socher et al.,2012b; Xu et al., 2015). The\n",
            "distinction between convolutional neural networks and recurrent neural networks\n",
            "11. as we can see in the previous section.\n",
            "108\n",
            "  ID: 929eb570-7ad4-4f57-921f-21428d3e0aa0\n",
            "--------------------\n",
            "Node 145:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "(RNN) for RE is that the former aim to generalize the short and consecutive con-\n",
            "text (i.e, thek-grams) of the relation mentions (Lei et al.,2015; Nguyen and Grish-\n",
            "man, 2015a) while the latter adaptively accumulate the context information in the\n",
            "whole sentence via the memory units, thereby encoding the long and possibly non-\n",
            "consecutive patterns for RE (Hochreiter and Schmidhuber,1997). Consequently,\n",
            "the traditional feature-based method (i.e, thelog-linear or MaxEnt model with\n",
            "hand-crafted and discrete features), the CNNs and the RNNs tend to focus on dif-\n",
            "ferent angles for RE. Guided by this intuition, in this work, we propose to combine\n",
            "the three models to further improve the performance of RE. Note that this is in\n",
            "contrast to the work in Section4.1 that avoids the use of feature engineering with\n",
            "discrete features completely.\n",
            "While the architecture design of CNNs for RE is quite established due to the\n",
            "extensive studies in the last couple of years, the application of RNNs to RE is only\n",
            "very recent and the optimal designs of RNNs for RE are still a subject of ongoing\n",
            "research. In this work, we first perform a systematic exploration of various network\n",
            "architectures to seek the best RNN model for RE. In the next step, we extensively\n",
            "study different methods to assemble the log-linear model, CNNs and RNNs for RE,\n",
            "leading to the combined models that yield the state-of-the-art performance on the\n",
            "ACE 2005 and SemEval datasets. To the best of our knowledge, this is the first\n",
            "work to systematically examine the RNN architectures as well as combine them\n",
            "with CNNs and the traditional feature-based approach for RE.\n",
            "109\n",
            "  ID: 6fa3852c-70e9-4749-b4df-8673fd599140\n",
            "--------------------\n",
            "Node 146:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.2.1 Models\n",
            "Relation mentions consist of sentences marked with two entity mentions of\n",
            "interest. In this section, we examine two different representations for the sentences\n",
            "in RE: (i) the standard representation, called SEQ that takes all the words in\n",
            "the sentences into account and (ii) the dependency representation, called DEP\n",
            "that only considers the words along the dependency paths between the two entity\n",
            "mention heads of the sentences. In the following, unless indicated specifically, all\n",
            "the statements about the sentences hold for both representations SEQ and DEP.\n",
            "Following Section4.1, we assume that the input sentences of the relation men-\n",
            "tions have the same fixed lengthn. We also denoteW = [ w1;w2;:::;w n] as the\n",
            "input sentence of some relation mention, wherewi is thei-th word in the sentence,\n",
            "and wi1 and wi2 are the two heads of the two entity mentions of interest. In or-\n",
            "der to prepare the relation mention for neural networks in this section, we also\n",
            "transform each wordwi into a real-valued vectorxi. However, this section uses the\n",
            "concatenation of the following seven vectors, motivated by the previous research\n",
            "on feature analysis for RE (Gormley et al.,2015; Sun et al.,2011; Zeng et al.,2014;\n",
            "Zhou et al.,2005):\n",
            "- The real-valued word embedding vectorembi of wi, obtained by looking up\n",
            "the word embedding tableEMB.\n",
            "- The real-valued distance embedding vectorsdisti1, disti2 to encode the relative\n",
            "distances i\u0000i1 and i\u0000i2 of wi to the two entity heads of interestwi1 and wi2:\n",
            "disti1 = DIST[i\u0000i1], disti2 = DIST[i\u0000i2] where DIST is the position embedding\n",
            "table (initialized randomly).\n",
            "110\n",
            "  ID: f6e93212-91b8-4c5a-9d9f-7a4f59455333\n",
            "--------------------\n",
            "Node 147:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "- The real-valued embedding vectors for entity typesenti and chunkschunki to\n",
            "embed the entity type and chunking information forwi. These vectors are gener-\n",
            "ated by looking up the entity type and chunk embedding tables (also initialized ran-\n",
            "domly) (i.e,ENT and CHUNK respectively) for the entity type and chunking label\n",
            "ofwi: enti = ENT[entity type label ofwi],chunki = CHUNK[chunking label ofwi].\n",
            "- The binary vectordepi with one dimension to indicate whether the wordwi\n",
            "is on the dependency path betweenwi1 and wi2 or not.\n",
            "- The binary vectorreli whose dimensions correspond to the possible relations\n",
            "between words in the dependency trees. The value at a dimension ofreli is only\n",
            "set to 1 if there exists one edge of the corresponding relation connected towi in\n",
            "the dependency tree.\n",
            "The transformation from the wordwi to the vectorxi = [ embi;disti1;disti2;enti;\n",
            "chunki;depi;reli] essentially converts the relation mention with the input sentence\n",
            "W into a real-valued matrixX = [ x1;x2;:::;x n], to be used by the neural networks\n",
            "presented below.\n",
            "4.2.1.1 The Separate Models\n",
            "WereviewtwotypicalNNarchitecturesforREunderlyingthecombinedmodels\n",
            "in this work.\n",
            "The Convolutional Neural Networks\n",
            "In CNNs (Kalchbrenner et al.,2014; Nguyen and Grishman,2015a)12, given\n",
            "a window size of k, we have a set of feature maps (filters). Each feature map\n",
            "12. The CNN model in this section is very similar to that of Section 4.1. The only difference\n",
            "is in the representations of the words in the sentences. W e review it here to introduce necessary\n",
            "notations for this section.\n",
            "111\n",
            "  ID: 485f95ae-b1de-4a59-8f83-319bf5269fd2\n",
            "--------------------\n",
            "Node 148:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "f is a weight matrixf = [ f1;f2;:::; fk] where fi is a vector to be learnt during\n",
            "training as the model parameters. The core of CNNs is the application of the\n",
            "convolutional operator on the input matrixX and the filter matrixf to produce a\n",
            "score sequence (also called the hidden vector)s = [ s1;s2;:::;s n\u0000k+1], interpreted\n",
            "as a more abstract representation of the input matrixX:\n",
            "si = g(\n",
            "k\u00001∑\n",
            "j=0\n",
            "fj+1xj+i + b) (4.3)\n",
            "where b is a bias term andg is thetanh function.\n",
            "In the next step, we further abstract the scores in s by aggregating it via\n",
            "the max function to obtain the max-pooling score. We then repeat this process\n",
            "for all the feature maps with different window sizes k to generate a vector of\n",
            "the max-pooling scores. In the final step, we pass this vector into some standard\n",
            "multilayer neural network, followed by a softmax layer to produce the probabilistic\n",
            "distribution PC(yjX) over the possible relation classesy in the prediction task.\n",
            "The Recurrent Neural Networks\n",
            "In RNNs, we consider the input matrixX = [ x1;x2;:::;x n] as a sequence of\n",
            "column vectors indexed from 1 ton. At each stepi, we compute the hidden vector\n",
            "\u000bi from the current input vectorxi and the previous hidden vector\u000bi\u00001 using the\n",
            "non-linear transformation functionϕ: \u000bi = \b( xi;\u000bi\u00001).\n",
            "This recurrent computation can be done via three different directional mecha-\n",
            "nisms: (i) the forward mechanism that recurs from 1 tonand generate the forward\n",
            "hiddenvectorsequence: \u0000\u0000\u0000!RNN([x1;x2;:::;x n]) = [ \u0000 !h1;\u0000 !h2;:::; \u0000 !hn], (ii)thebackward\n",
            "mechanism that runs RNNs fromnto 1 and results in the backward hidden vector\n",
            "112\n",
            "  ID: c27f7bf0-89c5-4e4a-8058-a622e635585b\n",
            "--------------------\n",
            "Node 149:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "sequence  \u0000\u0000\u0000RNN([xn;xn\u00001;:::;x 1]) = [  \u0000hn; \u0000\u0000hn\u00001;:::;  \u0000h1]13, and (iii) the bidirectional\n",
            "mechanism that performs RNNs in both directions to produce the forward and\n",
            "backward hidden vector sequences, and then concatenate them at each position to\n",
            "generate the new hidden vector sequence [h1;h2;:::;h n]: hi = [ \u0000 !hi; \u0000hi].\n",
            "Given the hidden vector sequence [h1;h2;:::;h n] obtained from one of the three\n",
            "mechanisms above, we study the following two strategies to generate the represen-\n",
            "tation vector vR for the initial relation mention. Note that this representation\n",
            "vector can be again fed into some standard multilayer neural network with a soft-\n",
            "max layer in the end, resulting in the distributionPR(yjX) for the RNN models:\n",
            "- TheHEAD strategy: In this strategy,vR is the concatenation of the hidden\n",
            "vectors at the positions of the two entity mention heads of interest:vR = [ hi1;hi2].\n",
            "This is motivated by the importance of the two mention heads in RE (Nguyen and\n",
            "Grishman, 2014a; Sun et al.,2011).\n",
            "- TheMAX strategy: This strategy is similar to our max-pooling mechanism in\n",
            "CNNs. In particular,vR is obtained by taking the maximum along each dimension\n",
            "of the hidden vectorsh1;h2;:::;h n. The idea is to further abstract the hidden\n",
            "vectors by retaining only the most important feature in each dimension.\n",
            "Regarding the non-linear function, the simplest form of\b in the literature con-\n",
            "siders it as a one-layer feed-forward neural network, calledFF: hi = FF(xi;hi\u00001) =\n",
            "\b(Uxi + Vhi\u00001) where ϕ is the sigmoid function, U and V are weight matrices.\n",
            "Unfortunately, the application ofFF is prone to the “vanishing gradient” problem\n",
            "(Bengio et al.,1994), making it challenging to train RNNs properly. In this\n",
            "  ID: d66ca4b6-36ca-400a-b872-d372b23e14a4\n",
            "--------------------\n",
            "Node 150:\n",
            "  Text: et al.,1994), making it challenging to train RNNs properly. In this work,\n",
            "13. The initial hidden vectors are set to the zero vector.\n",
            "113\n",
            "  ID: f3e8a3f9-d1a9-4497-9692-37e1c24f6c75\n",
            "--------------------\n",
            "Node 151:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "we also use Gated Recurrent Units (Cho et al., 2014a) (GRU) to alleviate this\n",
            "problem (as in Section3.1.2).\n",
            "4.2.1.2 The Combined Models\n",
            "We first present three different methods to assemble CNNs and RNNs: ensem-\n",
            "bling, stacking and voting, to be investigated in this work. The combination of the\n",
            "neural networks with the log-linear model would be discussed in the next section.\n",
            "1. Ensembling\n",
            "In this method, we first run some CNN and RNN in Section4.2.1.1 over the\n",
            "input matrixX to gather the corresponding distributionsPC(yjX) and PR(yjX).\n",
            "We then combine the CNN and RNN by multiplying their distributions (element-\n",
            "wise): Pensemble(yjX) = 1\n",
            "ZPC(yjX)PR(yjX) (Z is a normalization constant).\n",
            "2. Stacking\n",
            "The overall architecture of the stacking method is to use one of the two network\n",
            "architectures (i.e, CNNs and RNNs) to generalize the hidden vectors of the other\n",
            "architecture. The expectation is that we can learn more effective features for\n",
            "RE via such a deeper architecture by alternating between the local and global\n",
            "representations provided by CNNs and RNNs.\n",
            "We examine two variants for this method. The first variant, calledRNN-CNN,\n",
            "applies the CNN model in Section4.2.1.1 on the hidden vector sequence generated\n",
            "by some RNN in Section4.2.1.1 to perform RE. The second variant, calledCNN-\n",
            "RNN, on the other hand, utilize the CNN model to acquire the hidden vector\n",
            "sequence, that is, in turn, fed as the input into some RNN for RE. For the second\n",
            "114\n",
            "  ID: b2a3862b-1387-46d5-aa2c-8814945ba883\n",
            "--------------------\n",
            "Node 152:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "variant, as the length of the hidden vectors = [ s1;s2;:::;s n\u0000k+1] in the CNN\n",
            "model depends on the specified window sizek for the corresponding feature map\n",
            "f, we need to pad the input matrixX with ⌊k\n",
            "2 ⌋zero column vectors on both sides\n",
            "to ensure the same fixed lengthn for all the hidden vectors:s = [ s1;s2;:::;s n].\n",
            "Besides, we need to re-arrange the scores in the hidden vectors from different\n",
            "feature maps of the CNN so they are grouped according to the positions in the\n",
            "sentence, thus being compatible with the input requirement of RNNs.\n",
            "3. V oting\n",
            "Instead of integrating CNNs and RNNs at the model level as the two previous\n",
            "methods, the voting method makes decisions for a relation mentionX by voting\n",
            "the individual decisions of the different models. While there are several voting\n",
            "schemes in the literature, for this work, we employ the simplest scheme of majority\n",
            "voting. If there is more than one relation class receiving the highest number of\n",
            "votes, the relation class returned by a model and having the highest probability\n",
            "would be chosen.\n",
            "4.2.2 The Hybrid Models\n",
            "In order to further improve the RE performance of models above, we investigate\n",
            "the integration of these neural network models with the traditional log-linear model\n",
            "that relies on various linguistic features from the past research on RE (Gormley\n",
            "et al., 2015; Sun et al.,2011; Zhou et al.,2005). Specifically, in such integration\n",
            "models (calledthe hybrid models ), the relation class distribution is obtained from\n",
            "the element-wise multiplication between the distributions of the neural network\n",
            "115\n",
            "  ID: a4113fb4-587a-4c9d-a91a-aef8ddb252dd\n",
            "--------------------\n",
            "Node 153:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "models and the log-linear model. Let us take the ensembling model in Section\n",
            "4.2.1.2 as an example. The corresponding hybrid model in this case would be:\n",
            "Phybrid(yjX) = 1\n",
            "ZPC(yjX)PR(yjX)Plogin(yjX), assumingPlogin(yjX) is the distribu-\n",
            "tion of the log-linear model andZis the normalization constant. The parameters of\n",
            "the log-linear model are learnt jointly with the parameters of the neural networks.\n",
            "Hypothesis: Let S be the set of relation mentions correctly predicted by some\n",
            "neural network model in some dataset (the coverage set). The introduction of the\n",
            "log-linear model into this neural network model essentially changes the coverage\n",
            "set of the network, resulting in the new coverage setS′ that might or might not\n",
            "subsume the original setS. In this work, we hypothesize that although S and\n",
            "S′ overlap, there are still some relation mentions that only belong to either set.\n",
            "Consequently, weproposetoimplementamajorityvotingsystem(calledthe hybrid-\n",
            "voting system ) on the outputs of the network and its corresponding hybrid model\n",
            "to enhance both models.\n",
            "Note that the voting models in Section4.2.1.2 involve the voting on two models\n",
            "(i.e, CNN and RNN). In order to integrate the log-linear model into such voting\n",
            "models, we first augment the separate CNN and RNN models with the log-linear\n",
            "model before we perform the voting procedure on the resulting models. Finally,\n",
            "the correspondinghybrid-voting systems would involve the voting on four models\n",
            "(CNN, hybrid CNN, RNN and hybrid RNN).\n",
            "116\n",
            "  ID: 8483153a-83fc-4609-a511-7cf3b7fdc6a9\n",
            "--------------------\n",
            "Node 154:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.2.2.1 T raining\n",
            "We train the models by minimizing the negative log-likelihood function us-\n",
            "ing the stochastic gradient descent algorithm with shuffled mini-batches and the\n",
            "AdaDeltaupdaterule(Zeiler, 2012). Thegradientsarecomputedviaback-propagation\n",
            "whileregularizationisexecutedbyadropoutonthehiddenvectorsbeforethemulti-\n",
            "layer neural networks (Srivastava et al.,2014). During training, besides the weight\n",
            "matrices, we also optimize the embedding tables EMB;DIST;ENT;CHUNK to\n",
            "achieve the optimal state. Finally, we rescale the weights whose Frobenius norms\n",
            "exceed a hyperparameter (Nguyen and Grishman,2015a).\n",
            "4.2.3 Experiments\n",
            "4.2.3.1 Resources and Parameters\n",
            "For all the experiments below, we utilize the pre-trained word embeddings\n",
            "word2vec with 300 dimensions from (Mikolov et al.,2013b) to initialize the word\n",
            "embedding tableEMB. The parameters for CNNs and training the networks are\n",
            "inherited from the previous studies, i.e, the window size set for feature maps =\n",
            "f2;3;4;5g, 150 feature maps for each window size, 50 dimensions for all the embed-\n",
            "ding tables (except the word embedding tableEMB), the dropout rate= 0 :5, the\n",
            "mini-batch size= 50 , the hyperparameter for the Frobenius norms = 3 (Nguyen\n",
            "and Grishman,2015a). Regarding RNNs, we employ 300 units in the hidden layers.\n",
            "117\n",
            "  ID: bb5e3a13-4b1b-4282-a5a2-cab63ad337bd\n",
            "--------------------\n",
            "Node 155:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.2.3.2 Dataset\n",
            "We evaluate our models on two datasets: the ACE 2005 dataset for relation ex-\n",
            "traction and the SemEval-2010 Task 8 dataset (Hendrickx et al.,2010) for relation\n",
            "classification.\n",
            "The ACE 2005 corpus comes with 6 different domains: broadcast conversation\n",
            "(bc), broadcast news(bn), telephoneconversation(cts), newswire(nw), usenet(un)\n",
            "and weblogs (wl). Similar to the previous chapters, following the common practice\n",
            "of domain adaptation research on this dataset (Gormley et al.,2015; Nguyen and\n",
            "Grishman, 2014a; Nguyen et al.,2015c; Plank and Moschitti,2013), we usenews\n",
            "(the union ofbn and nw) as the training data, half ofbc as the development set and\n",
            "the remainder (cts, wl and the other half ofbc) as the test data. Note that we\n",
            "are using the data prepared by (Gormley et al.,2015), thus utilizing the same data\n",
            "split onbc as well as the same data processing and NLP toolkits. The total number\n",
            "of relations in the training set is 43,49714. We employ the BIO annotation scheme\n",
            "to capture the chunking information for words in the sentences and only mark the\n",
            "entity types of the two entity mention heads (obtained from human annotation)\n",
            "for this dataset.\n",
            "The SemEvaldataset concerns the relation classification task that aims to deter-\n",
            "mine the relation type (or no relation) between two entities in sentences. In order\n",
            "to make it compatible with the previous research (Gormley et al.,2015; Socher et\n",
            "al., 2012b), for this dataset, besides the word embeddings and the distance embed-\n",
            "dings, we apply the name tagging, part of speech tagging and WordNet features\n",
            "14. It was an error in (Gormley et al., 2015) that reported 43,518 total relations in the\n",
            "training set. The authors acknowledged this error.\n",
            "118\n",
            "  ID: 117d2e10-e5dc-4b53-9abc-8b509d596525\n",
            "--------------------\n",
            "Node 156:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "(inherited from (Socher et al.,2012b) and encoded by the real-valued vectors for\n",
            "each word). The other settings are also adopted from the past studies (Socher\n",
            "et al.,2012b; Xu et al.,2015).\n",
            "4.2.3.3 RNN Architectures\n",
            "This section evaluates the performance of various RNN architectures for RE\n",
            "on the ACE 2005 development set. In particular, we compare different design\n",
            "combinations of the following four factors: (i) sentence representations (i.e, SEQ\n",
            "or DEP), (ii) transformation functions\b (i.e, FF or GRU), (iii) the strategies to\n",
            "employ the hidden vector sequence for RE (i.e, HEAD or MAX), and (iv) the\n",
            "directions to run RNNs (i.e, forward (!), backward ( ) or bidirectional (⇌)).\n",
            "Table4.5 presents the results.\n",
            "Systems DEP SEQ\n",
            "⇌ 60.78 63.22\n",
            "HEAD ! 55.55 60.05\n",
            "FF  57.69 58.54\n",
            "⇌ 50.00 51.22\n",
            "MAX ! 52.08 53.96\n",
            " 45.07 33.50\n",
            "⇌ 63.32 63.23\n",
            "HEAD ! 63.69 62.77\n",
            "GRU  61.57 62.55\n",
            "⇌ 60.96 64.24\n",
            "MAX ! 61.97 64.59\n",
            " 61.56 64.30\n",
            "Table 4.5:Performance (F1 scores) of RNNs on the dev set.\n",
            "The main conclusions include:\n",
            "119\n",
            "  ID: 617bf56f-f74d-4f77-a090-8ca945f8684a\n",
            "--------------------\n",
            "Node 157:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "(i) Assuming the same choices for the other three corresponding factors, GRU\n",
            "is more effective than FF, SEQ is better than DEP most of the time, and HEAD\n",
            "outperforms MAX (except in the case where SEQ and GRU are applied) for RE\n",
            "with RNNs. Note that the outperformance of SEQ over DEP can be partly ex-\n",
            "plained by the domination of the relation mentions with short distances between\n",
            "the two entity mentions in the ACE 2005 dataset.\n",
            "(ii) Regarding the direction mechanisms, the bidirectional mechanism achieves\n",
            "the best performance for the HEAD strategy while the forward direction is the\n",
            "best mechanism for the MAX strategy. This can be partly explained by the lack\n",
            "of past or future context information in the HEAD strategy when we follow the\n",
            "backward or forward direction respectively.\n",
            "The best performance corresponds to the application of the SEQ representation,\n",
            "theGRUfunction and theMAX strategy that wouldbe used in all theRNN models\n",
            "below. We call such RNN models with the forward, backward and bidirectional\n",
            "mechanismFOR W ARD,BACKW ARDandBIDIRECT respectively. Wealso\n",
            "apply the SEQ representation for the CNN model (called CNN) in the following\n",
            "experiments for consistency.\n",
            "4.2.3.4 Evaluating the Combined Models\n",
            "WeevaluatethecombinationmethodsforCNNsandRNNspresentedinSection\n",
            "4.2.1.2. In particular, for each method, we examine three models that are combined\n",
            "from one of the three RNN models FORWARD, BACKWARD, BIDIRECT and\n",
            "the CNN model. For instance, in the stacking method, the three combined mod-\n",
            "120\n",
            "  ID: 0e5de074-78ab-4e4b-b59e-dc35d6ec3f21\n",
            "--------------------\n",
            "Node 158:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "els corresponding to theRNN-CNN variant are FORWARD-CNN, BACKWARD-\n",
            "CNN, BIDIRECT-CNN while the three combined models corresponding to the\n",
            "CNN-RNN variant are CNN-FORWARD, CNN-BACKWARD, CNN-BIDIRECT.\n",
            "The notations for the other methods are self-explained. The model performance\n",
            "on the development set is given in Table4.6 that also includes the performance\n",
            "of the separate models (i.e, CNN, FORWARD, BACKWARD, BIDIRECT) for\n",
            "convenient comparison.\n",
            "Model P R F1\n",
            "BIDIRECT 69.16 59.97 64.24\n",
            "FORWARD 69.33 60.45 64.59\n",
            "BACKWARD 65.60 63.05 64.30\n",
            "CNN 68.35 59.16 63.42\n",
            "Ensembling\n",
            "CNN-BIDIRECT 71.22 54.13 61.51\n",
            "CNN-FORWARD 66.19 59.64 62.75\n",
            "CNN-BACKWARD 65.09 60.13 62.51\n",
            "Stacking\n",
            "CNN-BIDIRECT 66.55 59.97 63.09\n",
            "CNN-FORWARD 69.46 63.05 66.10\n",
            "CNN-BACKWARD 72.58 58.35 64.69\n",
            "BIDIRECT-CNN 65.63 61.59 63.55\n",
            "FORWARD-CNN 73.13 58.67 65.11\n",
            "BACKWARD-CNN 67.60 58.51 62.73\n",
            "Voting\n",
            "CNN-BIDIRECT 71.08 60.94 65.62\n",
            "CNN-FORWARD 70.38 59.32 64.38\n",
            "CNN-BACKWARD 69.78 61.75 65.52\n",
            "Table 4.6:Performance of the combination methods.\n",
            "The first observation is that the ensembling method is not an effective way to\n",
            "combine CNNs and RNNs as its performance is worse than the separate models.\n",
            "Second, regarding the stacking method, the best way to combine CNNs and RNNs\n",
            "121\n",
            "  ID: e3e02fe2-a99d-41e2-881b-9e5cc63f1c7f\n",
            "--------------------\n",
            "Node 159:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "in this framework is to assemble the CNN model and the FORWARD model. In\n",
            "fact, the combination of the CNN and FORWARD models helps to improve the\n",
            "performance of the separate models in both variants of this method (referring to\n",
            "the models CNN-FORWARD and FORWARD-CNN). Finally, the voting method\n",
            "is also helpful as it outperforms the separate models with the CNN-BIDIRECT\n",
            "and CNN-BACKWARD combinations.\n",
            "For the following experiments, we would only focus on the three best combined\n",
            "models in this section, i.e, the CNN-FORWARD model in the stacking method\n",
            "(called STACK-FORWARD) and the CNN-BIDIRECT and CNN-BACKWARD\n",
            "modelsinthevotingmethods(calledVOTE-BIDIRECTandVOTE-BACKWARD\n",
            "respectively).\n",
            "4.2.3.5 Evaluating the Hybrid Models\n",
            "This section investigates the hybrid andhybrid-voting models (Section 4.2.2)\n",
            "to see if they can further improve the performance of the neural network mod-\n",
            "els. In particular, we evaluate the separate models: CNN, BIDIRECT, FOR-\n",
            "WARD, BACKWARD, and the combined models: STACK-FORWARD, VOTE-\n",
            "BIDIRECT and VOTE-BACKWARD when they are augmented with the tradi-\n",
            "tional log-linear model (the hybrid models). Besides, in order to verify the hypoth-\n",
            "esis in Section 4.2.2, we also test the correspondinghybrid-voting models. The\n",
            "experimental results are shown in Table4.7.\n",
            "There are three main conclusions:\n",
            "(i) For all the models in columns “Neural Networks ”, “Hybrid Models ” and\n",
            "122\n",
            "  ID: 3b641dc6-851a-4f6b-a2f5-26ea47a15ea3\n",
            "--------------------\n",
            "Node 160:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "Model Neural Networks Hybrid Models Hybrid-Voting Models\n",
            "P R F1 P R F1 P R F1\n",
            "CNN 68.35 59.16 63.42 66.44 64.51 65.46 69.07 63.70 66.27\n",
            "BIDIRECT 69.16 59.97 64.24 68.04 59.00 63.19 71.13 60.29 65.26\n",
            "FORWARD 69.33 60.45 64.59 66.11 63.86 64.96 72.69 61.26 66.49\n",
            "BACKWARD 65.60 63.05 64.30 66.03 62.07 63.99 71.56 63.21 67.13\n",
            "Combined Models\n",
            "VOTE-BIDIRECT 71.08 60.94 65.62 69.24 62.40 65.64 71.30 62.40 66.55\n",
            "STACK-FORWARD69.46 63.05 66.10 65.93 68.07 66.99 69.32 66.29 67.77\n",
            "VOTE-BACKWARD69.78 61.75 65.52 67.30 63.05 65.10 70.79 64.02 67.23\n",
            "Table 4.7:Performance of the hybrid models on the ACE 2005 development set.\n",
            "“Hybrid-V oting Models”, we see that the combined models outperform their corre-\n",
            "sponding separate models (only except the hybrid model of VOTE-BACKWARD),\n",
            "thereby further confirming the benefits of the combined models.\n",
            "(ii) Comparing columns “Neural Networks” and “Hybrid Models”, we find that\n",
            "the traditional log-linear model significantly helps the CNN model. The effects on\n",
            "the other models are not clear.\n",
            "(iii) More interestingly, for all the neural networks being examined (either sepa-\n",
            "rate or combined), the correspondinghybrid-voting systems substantially improve\n",
            "both the neural network models as well as the corresponding hybrid models, tes-\n",
            "tifying to the\n",
            "  ID: d758a4cd-975d-4625-aab0-37728a6e46f0\n",
            "--------------------\n",
            "Node 161:\n",
            "  Text: the neural network models as well as the corresponding hybrid models, tes-\n",
            "tifying to the hypothesis about thehybrid-voting approach in Section4.2.2. Note\n",
            "that the simpler voting systems on three models: the log-linear model, the CNN\n",
            "model and some RNN model (i.e, either BIDIRECT, FORWARD or BACKWARD)\n",
            "produce worse performance than thehybrid-voting methods (the respective perfor-\n",
            "mance is 66.13%, 65.27%, and 65.96%).\n",
            "123\n",
            "  ID: 739984ba-9e50-4c1e-b32b-f56beb203770\n",
            "--------------------\n",
            "Node 162:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "4.2.3.6 Comparing to the State of the art\n",
            "The state-of-the-art system on the ACE 2005 for the unseen domains has been\n",
            "the feature-rich compositional embedding model (FCM) and the hybrid FCM\n",
            "model from (Gormley et al., 2015). In this section, we compare the proposed\n",
            "hybrid-voting systems with these state-of-the-art systems on the test domainsbc,\n",
            "cts, wl. Table 4.8 reports the results. For completeness, we also include the\n",
            "performance of the log-linear model and the separate models CNN, BIDIRECT,\n",
            "FORWARD, BACKWARD, serving as the other baselines for this work.\n",
            "System bc cts wl\n",
            "P R F1 P R F1 P R F1 Ave\n",
            "The State-of-the-art Systems\n",
            "FCM 66.56 57.86 61.90 65.62 44.35 52.93 57.80 44.62 50.36 55.06\n",
            "Hybrid FCM 74.39 55.35 63.48 74.53 45.01 56.12 65.63 47.59 55.17 58.26\n",
            "Separate Systems\n",
            "Log-Linear 68.44 50.07 57.83 73.62 41.57 53.14 60.40 47.31 53.06 54.68\n",
            "CNN 65.62 61.06 63.26 65.92 48.12 55.63 54.14 53.68 53.91 57.60\n",
            "BIDIRECT 65.23 61.06 63.07 66.15 49.26 56.47 55.91 51.56 53.65 57.73\n",
            "FORWARD 63.64 59.39 61.44 60.12 50.57 54.93 55.54 54.67 55.10 57.16\n",
            "BACKWARD 60.44 61.2 60.82 58.20 54.01 56.03 51.03\n",
            "  ID: 1848ec59-64d8-4ba5-9f36-a56a9ac2ae4c\n",
            "--------------------\n",
            "Node 163:\n",
            "  Text: 60.82 58.20 54.01 56.03 51.03 52.55 51.78 56.21\n",
            "Hybrid-Voting Systems\n",
            "VOTE-BIDIRECT70.40 63.84 66.96†66.74 49.92 57.12† 59.24 54.96 57.02† 60.37\n",
            "ST ACK-FOR W ARD65.75 66.48 66.11† 63.58 51.72 57.04† 56.35 57.22 56.78† 59.98\n",
            "VOTE-BACKW ARD69.57 63.28 66.28† 65.91 52.21 58.26†58.81 55.81 57.27†60.60\n",
            "Table 4.8:Comparison to the state of the art on the ACE 2005 dataset. The cells\n",
            "marked with †designates the models that are significantly better than the other\n",
            "neural network models (\u001a< 0:05) on the corresponding domains.\n",
            "From the table, we see that although the separate neural networks outper-\n",
            "form the FCM model across domains, they are still worse than the hybrid FCM\n",
            "model due to the introduction of the log-linear model into FCM. However, when\n",
            "the networks are combined and integrated with the log-linear model, they (the\n",
            "hybrid-voting systems) become significantly better than the FCM models across\n",
            "124\n",
            "  ID: 7b92cf38-e399-464b-9932-105960e56e51\n",
            "--------------------\n",
            "Node 164:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "all domains (up to 2% improvement on the average absolute F score),yielding the\n",
            "state-of-the-art performance for the unseen domains in this dataset .\n",
            "4.2.3.7 Relation Classification Experiments\n",
            "We further evaluate the proposed systems for the relation classification task on\n",
            "the SemEval dataset. Table4.9 presents the performance of the seprate models,\n",
            "the proposed systems as well as the other representative systems on this task. The\n",
            "most important observation is that thehybrid-voting systems VOTE-BIDIRECT\n",
            "and VOTE-BACKWARD achieve the state-of-the-art performance for this dataset,\n",
            "further highlighting their benefit for relation classification. The hybrid-voting\n",
            "STACK-FORWARD system performs less effectively in this case, possibly due\n",
            "to the small size of the SemEval dataset that is not sufficient to training such a\n",
            "deep model.\n",
            "4.2.4 Analysis\n",
            "In order to better understand why the combination of CNNs and RNNs out-\n",
            "performs the individual networks, we evaluate the performance breakdown per\n",
            "relation for the CNN and BIDIRECT models. The results on the development set\n",
            "of the ACE 2005 dataset are provided in Table4.10.\n",
            "One of the main insights is that although CNN and BIDIRECT have compa-\n",
            "rable overall performance, their recalls on individual relations are very divergent.\n",
            "In particular, BIDIRECT has much better recall for the PHYS relation while the\n",
            "recalls of CNN are significantly better for the ART, ORG-AFF and GEN-AFF\n",
            "125\n",
            "  ID: 3d57484c-3555-4a27-a632-9f599df0ea58\n",
            "--------------------\n",
            "Node 165:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "Classifier F\n",
            "SVM (Hendrickx et al.,2010) 82.2\n",
            "RNN (Socher et al.,2012b) 77.6\n",
            "MVRNN (Socher et al.,2012b) 82.4\n",
            "CNN (Zeng et al.,2014) 82.7\n",
            "CR-CNN (Santos et al.,2015a) 84.1†\n",
            "FCM (Gormley et al.,2015) 83.0\n",
            "Hybrid FCM (Gormley et al.,2015) 83.4\n",
            "DepNN (Liu et al.,2015) 83.6\n",
            "SDP-LSTM (Xu et al.,2015) 83.7\n",
            "Systems in this work\n",
            "CNN 83.5\n",
            "BIDIRECT 81.8\n",
            "FORWARD 81.9\n",
            "BACKWARD 82.4\n",
            "VOTE-BIDIRECT 84.1\n",
            "STACK-FORWARD 83.4\n",
            "VOTE-BACKWARD 84.1\n",
            "Table 4.9:Performance of relation classification systems. The “†” refers to special\n",
            "treatment of theOther class.\n",
            "Relation Class CNN BIDIRECT\n",
            "P R F1 P R F1\n",
            "PHYS 66.7 34.7 45.7 57.4 50.9 54.0\n",
            "PART-WHOLE68.6 67.8 68.2 74.4 70.1 72.2\n",
            "ART 64.2 51.2 57.0 68.6 41.7 51.9\n",
            "ORG-AFF 70.2 83.0 76.0 79.3 76.1 77.7\n",
            "PER-SOC 71.1 59.3 64.6 69.6 59.3 64.0\n",
            "GEN-AFF 65.9 55.1 60.0 59.0 46.9 52.3\n",
            "all 68.4 59.2 63.4 69.2 60.0 64.2\n",
            "Table 4.10:The performance breakdown per relation\n",
            "  ID: 023bb73c-e1e6-4339-85b9-5042e5fe90de\n",
            "--------------------\n",
            "Node 166:\n",
            "  Text: 60.0 64.2\n",
            "Table 4.10:The performance breakdown per relation for CNN and BIDIRECT on\n",
            "the development set.\n",
            "126\n",
            "  ID: 186a7b33-c71b-4e81-bcf0-529e2f04634a\n",
            "--------------------\n",
            "Node 167:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "relations. A closer investigation reveals two facts: (i) the PHYS relation mentions\n",
            "that are only correctly predicted by BIDIRECT involve long distances between two\n",
            "entity mentions, such as the PHYS relation between “Some” (a person entity) and\n",
            "“desert” (a location entity) in the following sentence: “Some of the 40,000 British\n",
            "troops are kicking up a lot of dust in the Iraqi desert making sure that nothing is\n",
            "left behind them that could hurt them. ”, and (ii) the ART, ORG-AFF, GEN-AFF\n",
            "relation mentions only correctly predicted by CNN contain patterns between the\n",
            "two entity mentions that are short but meaningful enough to decide the relation\n",
            "classes, such as “The Iraqi unit in possession of those guns ” (the ART relation\n",
            "between “unit” and “guns”), or “the al Qaeda chief operations officer ” (the ORG-\n",
            "AFF relation between “al Qaeda” and “officer”). The failure of CNN on the PHYS\n",
            "relation mentions with long distances originates from its mechanism to model short\n",
            "and consecutivek-grams (up to length 5 in our case), causing difficulty in captur-\n",
            "ing long and/or non-consecutive patterns. BIDIRECT, on the other hand, fails to\n",
            "predict the short (but expressive enough) patterns for ART, ORG-AFF, GEN-AFF\n",
            "because it involves the hidden vectors that only model the context words outside\n",
            "the short patterns, potentially introducing unnecessary and noisy information into\n",
            "the max-pooling scores for prediction. Eventually, the combination of RNNs and\n",
            "CNNs helps to compensate for the drawbacks of each model.\n",
            "4.3 Related W ork\n",
            "Forrelationextraction/classification, mostworkonneuralnetworkshasfocused\n",
            "on the relation classification task. In particular, (Socher et al.,2012b) study the\n",
            "127\n",
            "  ID: a9432c84-d547-4ab8-8d28-8c00574144b8\n",
            "--------------------\n",
            "Node 168:\n",
            "  Text: CHAPTER 4. DEEP LEARNING FOR RELATION EXTRACTION\n",
            "recursive NNs that recur over the tree structures while (Xu et al.,2015) investi-\n",
            "gate recurrent NNs. Regarding CNNs, (Zeng et al.,2014) examine CNNs via the\n",
            "sequential representation of sentences, (Santos et al.,2015a) explore a ranking loss\n",
            "function with data cleaning while (Zeng et al.,2015) propose dynamic pooling and\n",
            "multi-instance learning. For RE, (Yu et al.,2015) and (Gormley et al.,2015) work\n",
            "on the feature-rich compositional embedding models. Finally, the only work that\n",
            "combines NN architectures is due to (Liu et al.,2015) but it only focuses on the\n",
            "stacking of the recursive NNs and CNNs for relation classification.\n",
            "4.4 Conclusion\n",
            "We present a CNN for relation extraction that emphasizes an unbalanced cor-\n",
            "pus and minimizes usage of external supervised NLP toolkits for features. The\n",
            "network uses multiple window sizes for filters, position embeddings for encoding\n",
            "relative distances and pre-trained word embeddings for initialization in a non-\n",
            "static architecture. The experimental results demonstrate the effectiveness of the\n",
            "proposed CNN on both RC and RE.\n",
            "Inaddition, weinvestigatedifferentmethodstocombineCNNs, RNNsaswellas\n",
            "thehybridmodelstointegratethelog-linearmodelintotheNNs. Theexperimental\n",
            "results demonstrate that the stacking and majority voting between CNNs, RNNs\n",
            "and their corresponding hybrid models are the best combination methods. We\n",
            "achieve the state-of-the-art performance for both relation extraction and relation\n",
            "classification.\n",
            "128\n",
            "  ID: 192be782-a5bc-4b0a-a249-a15e17ea8e4c\n",
            "--------------------\n",
            "Node 169:\n",
            "  Text: Chapter 5\n",
            "Deep Learning for Event\n",
            "Detection\n",
            "This chapter focuses on the problem of event detection (ED) or trigger predic-\n",
            "tion, i.e, identifying instances of specified types of events in text. Associated with\n",
            "each event mention is a phrase, the event trigger (most often a single verb or nom-\n",
            "inalization), which evokes that event. Our task, more precisely stated, involves\n",
            "identifying event triggers and classifying them into specific types. For instance, ac-\n",
            "cording to the ACE 2005 annotation guideline1, in the sentence “A police officer\n",
            "was kil led in New Jersey today ”, an event detection system should be able to\n",
            "recognize the word “kil led” as a trigger for the event “Die”. This task is quite chal-\n",
            "lenging, as the same event might appear in the form of various trigger expressions\n",
            "and an expression might represent different events in different contexts. ED is a\n",
            "1. https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-events-guidelines-v5.4.3.\n",
            "pdf\n",
            "129\n",
            "  ID: ff068a06-1446-4b25-af56-38ce3032ef79\n",
            "--------------------\n",
            "Node 170:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "crucial component in the overall task of event extraction, which also involves event\n",
            "argument discovery.\n",
            "In order to develop deep learning models for event detection, we first show\n",
            "that a customization of the CNN architecture in Section4.1 can produce a highly\n",
            "effective model with less requirement for feature engineering. We then extend\n",
            "this CNN model to allow non-consecutive convolutions, thus further improving\n",
            "the performance for ED. The works in this chapter are published in (Nguyen and\n",
            "Grishman, 2015b) and (Nguyen and Grishman,2016e).\n",
            "5.1 Convolutional Neural Networks for Event\n",
            "Detection\n",
            "Recent systems for event extraction have employed either a pipeline architec-\n",
            "ture with separate classifiers for trigger and argument labeling (Gupta and Ji,2009;\n",
            "Huang and Riloff,2012; Ji and Grishman,2008; Li et al.,2013a; Liao and Grish-\n",
            "man, 2011; McClosky et al.,2011; Patwardhan and Rilof,2009) or a joint inference\n",
            "architecture that performs the two subtasks at the same time to benefit from their\n",
            "inter-dependencies (Li et al.,2013b; Riedel and McCallum,2011a, 2011b; Venu-\n",
            "gopal et al.,2014). Both approaches have coped with the ED task by elaborately\n",
            "hand-designing a large set of features (feature engineering) and utilizing the exist-\n",
            "ing supervised natural language processing (NLP) toolkits and resources (i.e name\n",
            "tagger, parsers, gazetteers etc) to extract these features for statistical classifiers.\n",
            "In this section, we approach ED via a different perspective that relies on convolu-\n",
            "130\n",
            "  ID: c53071eb-2ad6-4243-873d-3a14242b128c\n",
            "--------------------\n",
            "Node 171:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "tional neural networks (CNN) to automatically learn features from sentences, and\n",
            "to minimize the dependence on supervised toolkits and resources for features. The\n",
            "CNN models in this section are very similar to those of Section4.1, but we need\n",
            "to customize them to capture the special structures for ED. To the best of our\n",
            "knowledge, this is the first work on event detection via CNNs.\n",
            "First, we evaluate CNNs for ED in the general setting and show that CNNs,\n",
            "though not requiring complicated feature engineering, can still outperform the\n",
            "state-of-the-art feature-based methods extensively relying on the other supervised\n",
            "modules and manual resources for features. Second, we investigate CNNs in a\n",
            "domain adaptation (DA) setting for ED. We demonstrate that CNNs significantly\n",
            "outperform the traditional feature-based methods with respect to generalization\n",
            "performance across domains due to: (i) their capacity to mitigate the error prop-\n",
            "agation from the pre-processing modules for features, and (ii) the use of word\n",
            "embeddings to induce a more general representation for event trigger candidates.\n",
            "We believe that this is also the first research on domain adaptation using CNNs.\n",
            "5.1.1 Model\n",
            "Weformalizetheeventdetectionproblemasamulti-classclassificationproblem.\n",
            "Given a sentence, for every token in that sentence, we want to predict if the\n",
            "current token is an event trigger: i.e, does it express some event in the pre-defined\n",
            "event set or not (Li et al.,2013b)? The current token along with its context in\n",
            "the sentence constitute an event trigger candidate or an example in multi-class\n",
            "classification terms. In order to prepare for CNNs, we limit the context to a\n",
            "131\n",
            "  ID: ab232c65-0cf7-4fc2-b45a-5127f3712836\n",
            "--------------------\n",
            "Node 172:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "fixed window size by trimming longer sentences and padding shorter sentences\n",
            "with a special token when necessary. Let2n+ 1 be the fixed window size, and\n",
            "W = [ w0;w1;:::;w n;:::;w 2n\u00001;w2n] be some trigger candidate where the current\n",
            "token is positioned in the middle of the window (tokenwn). Before entering the\n",
            "CNNs, each tokenwi is transformed into a real-valued vector by looking up the\n",
            "following embedding tables to capture different characteristics of the token:\n",
            "- W ord Embedding T able (initialized by some pre-trained word embed-\n",
            "dings): to capture the hidden semantic and syntactic properties of the tokens\n",
            "(Collobert and Westion,2008; Turian et al.,2010).\n",
            "- Position Embedding T able : to embed the relative distancei\u0000n of the\n",
            "token wi to the current tokenwn. In practice, we initialize this table randomly.\n",
            "- Entity Type Embedding T able : If we further know the entity mentions\n",
            "and their entity types2 in the sentence, we can also capture this information for\n",
            "each token by looking up the entity type embedding table (initialized randomly)\n",
            "using the entity type associated with each token. We employ the BIO annotation\n",
            "scheme to assign entity type labels to each token in the trigger candidate using the\n",
            "heads of the entity mentions.\n",
            "For each token wi, the vectors obtained from the three look-ups above are\n",
            "concatenated into a single vectorxi to represent the token. As a result, the original\n",
            "event triggerW is transformed into a matrix:\n",
            "X = [ x0;x1;:::;x n;:::;x 2n\u00001;x2n] (5.1)\n",
            "2. F or convenience, when mentioning entities in this work, we always include ACE timex\n",
            "and values.\n",
            "132\n",
            "  ID: 4146e558-3cd3-4dd5-ace1-c37aa3d4c59c\n",
            "--------------------\n",
            "Node 173:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "of size d\u0002(2n+ 1) (d is the dimensionality of the concatenated vectors of the\n",
            "tokens).\n",
            "The matrix representationxis then passed through a convolution layer, a max\n",
            "pooling layer and a softmax at the end to perform classification (as in Section4.1).\n",
            "In the convolution layer, we have a set of feature maps (filters)ff1;f2;:::; fmgfor\n",
            "the convolution operation. Each feature mapfi corresponds to some window size\n",
            "kand can be essentially seen as a weight matrix of sized\u0002k. Figure5.1 illustrates\n",
            "the proposed CNN.\n",
            "Figure 5.1: Convolutional Neural Network for Event Detection.\n",
            "Again, similartoSection 4.1, thegradientsarecomputedusingback-propagation;\n",
            "regularization is implemented by a dropout (Srivastava et al.,2014); and training is\n",
            "done via stochastic gradient descent with shuffled mini-batches and the AdaDelta\n",
            "133\n",
            "  ID: 71c2366b-16ee-4528-9976-89e28ea6b5fb\n",
            "--------------------\n",
            "Node 174:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "update rule (Zeiler,2012). During the training, we also optimize the weights of\n",
            "the three embedding tables at the same time to reach an effective state.\n",
            "5.1.2 Experiments\n",
            "5.1.2.1 Dataset, Hyperparameters and Resources\n",
            "As the benefit of multiple window sizes in the convolution layer has been demon-\n",
            "strated in the previous work (Kalchbrenner et al.,2014; Kim, 2014; Nguyen and\n",
            "Grishman, 2015a), in the experiments below, we use window sizes in the set {2, 3,\n",
            "4, 5} to generate feature maps. We utilize 150 feature maps for each window size\n",
            "in this set. The window size for triggers is set to 31 while the dimensionality of\n",
            "the position embeddings and entity type embeddings is 503. We inherit the values\n",
            "for the other parameters from (Kim, 2014), i.e, the dropout rate \u001a = 0 :5, the\n",
            "mini-batch size = 50, the hyperparameter for the Frobenius norms = 3. Finally,\n",
            "we employ the pre-trained word embeddingsword2vec with 300 dimensions from\n",
            "(Mikolov et al.,2013b) for initialization.\n",
            "We evaluate the presented CNN over the ACE 2005 corpus for event detection.\n",
            "Forcomparisonpurposes, weutilizethesametestsetwith40newswirearticles(672\n",
            "sentences), the same development set with 30 other documents (836 sentences) and\n",
            "the same training set with the remaning 529 documents (14,849 sentences) as the\n",
            "previous studies on this dataset (Ji and Grishman,2008; Li et al.,2013b; Liao and\n",
            "Grishman, 2010b). The ACE 2005 corpus has 33 event subtypes that, along with\n",
            "one class “None” for the non-trigger tokens, constitutes a 34-class classification\n",
            "3. These values are chosen for their best performance on the development data.\n",
            "134\n",
            "  ID: 3fa2f0b8-2e80-4ba3-a25d-586704a29f43\n",
            "--------------------\n",
            "Node 175:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "problem.\n",
            "In order to evaluate the effectiveness of the position embeddings and the entity\n",
            "type embeddings, Table5.1 reports the performance of the proposed CNN on the\n",
            "development set when these embeddings are either included or excluded from the\n",
            "systems. With the large margins of performance, it is very clear from the table\n",
            "that the position embeddings are crucial while the entity embeddings are also very\n",
            "useful for CNNs on ED.\n",
            "Systems P R F\n",
            "-Entity Types -Position 16.8 12.0 14.0\n",
            "+Position 75.0 63.0 68.5\n",
            "+Entity Types -Position 17.0 15.0 15.9\n",
            "+Position 75.6 66.4 70.7\n",
            "Table 5.1:Performance on the development set.\n",
            "For the experiments below, we examine the CNNs in two scenarios: excluding\n",
            "the entity type embeddings (CNN1) and including the entity type embeddings\n",
            "(CNN2). We always use position embeddings in these two scenarios.\n",
            "5.1.2.2 Performance Comparison\n",
            "The state-of-the-art systems for event detection on the ACE 2005 dataset have\n",
            "followed the traditional feature-based approach with rich hand-designed feature\n",
            "sets, and statistical classifiers such as MaxEnt and perceptron for structured pre-\n",
            "diction in a joint architecture (Hong et al.,2011; Li et al.,2013b). In this section,\n",
            "we compare the proposed CNNs with these state-of-the-art systems on the blind\n",
            "135\n",
            "  ID: e4c55869-de82-43b5-8bfb-52f3e5ce83f7\n",
            "--------------------\n",
            "Node 176:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "test set. Table 5.2 presents the overall performance of the systems with gold-\n",
            "standard entity mention and type information4.\n",
            "Methods P R F\n",
            "Sentence-level in (Hong et al.,2011) 67.6 53.5 59.7\n",
            "MaxEnt with local features in (Li et al.,2013b) 74.5 59.1 65.9\n",
            "Jointbeamsearchwithlocalfeaturesin(Lietal., 2013b) 73.7 59.3 65.7\n",
            "Joint beam search with local and global features in (Li\n",
            "et al.,2013b)\n",
            "73.7 62.3 67.5\n",
            "Cross-entity in (Hong et al.,2011) y 72.9 64.3 68.3\n",
            "CNN1: CNN without any external features 71.9 63.8 67.6\n",
            "CNN2: CNN augmented with entity types 71.8 66.4 69.0\n",
            "Table 5.2: Performance with gold-standard entity mentions and types.ybeyond\n",
            "sentence level.\n",
            "As we can see from the table, considering the systems that only use sentence\n",
            "level information, CNN1 significantly outperforms the MaxEnt classifier as well as\n",
            "the joint beam search with local features from (Li et al.,2013b) (an improvement of\n",
            "1.6% in F1 score), and performs comparably with the joint beam search approach\n",
            "using both local and global features (Li et al.,2013b). This is remarkable since\n",
            "CNN1 does not require any external features5, in contrast to the other feature-\n",
            "based systems that extensively rely on such external features to perform well. More\n",
            "interestingly, when the entity type information is incorporated into CNN1, we\n",
            "obtain CNN2 that still only needs sentence level information but achieves the\n",
            "state-of-the-art performance for this task (an improvement of 1.5% over the best\n",
            "system with only sentence level information (Li et al.,2013b)).\n",
            "4. Entity mentions and types are used to introduce more features into the systems.\n",
            "5. External features are the features generated from the supervised NLP modules and\n",
            "manual resources such as parsers, name tagger,\n",
            "  ID: b7fc9a04-1429-4644-9c94-ce31a6ba1253\n",
            "--------------------\n",
            "Node 177:\n",
            "  Text: features generated from the supervised NLP modules and\n",
            "manual resources such as parsers, name tagger, entity mention extractors (either automatic or\n",
            "manual), gazetteers etc.\n",
            "136\n",
            "  ID: 014f392c-4d8b-4335-9e47-865b8a831f66\n",
            "--------------------\n",
            "Node 178:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "Except for CNN1, all the systems reported in Table 5.2 employ the gold-\n",
            "standard (perfect) entities mentions and types from manual annotation which\n",
            "might not be available in reality. Table5.3 compares the performance of CNN1\n",
            "and the feature-based systems in a more realistic setting, where entity mentions\n",
            "and types are acquired from an automatic high-performing name tagger and infor-\n",
            "mation extraction system (Li et al.,2013b). Note that CNN1 is eligible for this\n",
            "comparison as it does not utilize any external features, thus avoiding usage of the\n",
            "name tagger and the information extraction system to identify entity mentions\n",
            "and types.\n",
            "Methods F\n",
            "Sentence level in (Ji and Grishman,2008) 59.7\n",
            "MaxEnt with local features in (Li et al.,2013b) 64.7\n",
            "Joint beam search with local features in (Li et al.,2013b) 63.7\n",
            "Joint beam search with local and global features in (Li et al.,\n",
            "2013b)\n",
            "65.6\n",
            "CNN1: CNN without any external features 67.6\n",
            "Table 5.3:Performance with predicted entity mentions and types.\n",
            "5.1.2.3 Domain Adaptation Experiment\n",
            "We evaluate the robustness across domains of the CNN models in this section.\n",
            "In particular, we compare the proposed CNNs with the feature-based systems\n",
            "under the domain adaptation setting for event detection (as in Chapters 2 and\n",
            "3). In such setting, we take training data in somesource domain to learn models\n",
            "that can work well ontarget domains. The target domains are supposed to be so\n",
            "dissimilar from the source domain that the learning techniques would suffer from\n",
            "137\n",
            "  ID: f6427ba3-d600-4ecc-b9c3-f79e33b41ad7\n",
            "--------------------\n",
            "Node 179:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "a significant performance loss when trained on the source domain and applied to\n",
            "the target domains. We refer the reader to Chapters 1 and 2 to know more about\n",
            "the domain adaptation setting. To make it clear, we address the unsupervised DA\n",
            "problem in this section, i.e no training data in the target domains (Blitzer et al.,\n",
            "2006; Nguyen et al.,2015c; Plank and Moschitti,2013).\n",
            "We also do the experiments in this part over the ACE 2005 dataset but focus\n",
            "more on the difference between domains. Following the common practice of domain\n",
            "adaptation research on this dataset (Nguyen and Grishman,2014a; Nguyen et al.,\n",
            "2015c; Plank and Moschitti,2013), we usenews (the union ofbn and nw) as the\n",
            "source domain andbc, cts, wl as three different target domains. We take half of\n",
            "bc as the development set and use the remaining data for testing.\n",
            "Table5.4 presents the performance of five systems: the MaxEnt classifier with\n",
            "the local features from (Li et al.,2013b) (calledMaxEnt); the state-of-the-art joint\n",
            "beam search systems with: (i) only local features (calledJoint+Local); and (ii)\n",
            "both local and global features (calledJoint+Local+Global) in (Li et al.,2013b)\n",
            "(the baseline systems); CNN1 and CNN2 via 5-fold cross validation. For each\n",
            "system, we train a model on the training set of the source domainnews and report\n",
            "the performance of this model on the test set of the source domain (in-domain\n",
            "performance) as well as the performance of the model on the three target domains\n",
            "bc, cts and wl (out-of-domain performance)6.\n",
            "The main conclusions from the table include:\n",
            "(i) The baseline systems MaxEnt, Joint+Local, Joint+Local+Global achieve\n",
            "6. The performance of the feature-based systems MaxEnt, Joint+Local and\n",
            "Joint+Local+Global are obtained from the actual systems in (Li et al., 2013b).\n",
            "138\n",
            "  ID: 55dc86b0-9ac6-4321-9ef8-b9a3dc7b0060\n",
            "--------------------\n",
            "Node 180:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "System In-domain(bn+nw)bc cts wlP R F P R F P R F P R F\n",
            "MaxEnt 74.5 59.466.0 70.1 54.561.3 66.4 49.956.9 59.4 34.943.9\n",
            "Joint beam search in (Li et al.,2013b)Joint+Local 73.5 62.767.7 70.3 57.263.1 64.9 50.857.0 59.5 38.446.7\n",
            "Joint+Local+Global 72.9 63.267.7 68.8 57.562.6 64.5 52.357.7 56.4 38.545.7\n",
            "CNN1 70.9 64.067.3 71.0 61.966.1†64.0 55.059.1 53.2 38.444.6\n",
            "CNN2 69.2 67.068.0 70.2 65.267.6†68.3 58.262.8†54.8 42.047.5\n",
            "Table 5.4: In-domain (first column) and Out-of-domain performance for event\n",
            "detection (columns two to four). Cells marked with †designate CNN models that\n",
            "significantly outperform (p< 0:05) all the reported feature-based methods on the\n",
            "specified domain.\n",
            "high performance on the source domain, but degrade dramatically on the target\n",
            "domains due to the domain shifts.\n",
            "(ii) Comparing CNN1 and the baseline systems, we see that CNN1 performs\n",
            "comparably with the baseline systems on the source domain (in-domain perfor-\n",
            "mance) (as expected), substantially outperform the baseline systems on two of\n",
            "the three target domains (i.e, bc and cts), and is only less effective than the joint\n",
            "beam search approach on the wl domain; (iii) Finally and most importantly, we\n",
            "consistently achieve the best adaptation performance across all the target domains\n",
            "with CNN2 by only introducing entity type information into CNN1. In fact, CNN2\n",
            "significantly\n",
            "  ID: a47da6cb-30ee-452b-affe-5eabf2a65a5e\n",
            "--------------------\n",
            "Node 181:\n",
            "  Text: CNN2 by only introducing entity type information into CNN1. In fact, CNN2\n",
            "significantly outperforms the feature-based systems withp <0:05 and large mar-\n",
            "gins of about 5.0% on the domains bc and cts, clearly testifying to the benefits of\n",
            "CNNs on DA for ED.\n",
            "139\n",
            "  ID: adcbed9d-351a-41ea-9144-8cf29f1a98d5\n",
            "--------------------\n",
            "Node 182:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "5.2 Non-consecutive Convolutional Neural\n",
            "Networks for Event Detection\n",
            "The prior CNN models for ED are characterized by the temporal convolution\n",
            "operators that linearly map the vectors for thek-grams in the sentences into the\n",
            "feature space. Such k-gram vectors are obtained by concatenating the vectors of\n",
            "the kconsecutive words in the sentences (Chen et al.,2015; Nguyen and Grishman,\n",
            "2015b). In other words, the previous CNN models for ED only focus on modeling\n",
            "the consecutivek-grams. Unfortunately, such consecutive mechanism is unable to\n",
            "capture the long-range and non-consecutive dependencies that are necessary to the\n",
            "prediction of trigger words. For instance, consider the following sentence with the\n",
            "trigger word “leave” from the ACE 2005 corpus:\n",
            "The mystery is that she took the job in the first place or didn ’t leave earlier.\n",
            "The correct event type for the trigger word “leave” in this case is “End-Org”.\n",
            "However, the previous CNN models might not be able to detect “leave” as an\n",
            "event trigger or incorrectly predict its type as “Movement”. This is caused by their\n",
            "reliance on the consecutive localk-grams such as “leave earlier”. Consequently, we\n",
            "need to resort to the non-consecutive pattern “job leave ” to correctly determine\n",
            "the event type of “leave” in this case.\n",
            "Guided by this intuition, we propose to improve the previous CNN models\n",
            "for ED by operating the convolution on all possible non-consecutivek-grams in\n",
            "the sentences. We aggregate the resulting convolution scores via themax-pooling\n",
            "function to unveil the most important non-consecutivek-grams for ED. The aggre-\n",
            "140\n",
            "  ID: eff66fad-4e4a-4fec-ba82-3b764022d389\n",
            "--------------------\n",
            "Node 183:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "gation over all the possible non-consecutivek-grams is made efficient with dynamic\n",
            "programming.\n",
            "Notethatourworkisrelatedto(Leietal., 2015)whoemploythenon-consecutive\n",
            "convolution for the sentence and news classification problems. Our work is different\n",
            "from Lei et al.,2015 in that we model the relative distances of words to the trig-\n",
            "ger candidates in the sentences via position embeddings, while (Lei et al.,2015)\n",
            "use the absolute distances between words in thek-grams to compute the decay\n",
            "weights for aggregation. To the best of our knowledge, this is the first work on\n",
            "non-consecutive CNN for ED.\n",
            "We systematically evaluate the proposed model in the general setting as well\n",
            "as the domain adaptation setting. The experiment results demonstrate that our\n",
            "model significantly outperforms the current state-of-the-art models in such set-\n",
            "tings.\n",
            "5.2.1 Model\n",
            "We also formalize ED as a multi-class classification problem as the previous\n",
            "section. In order to make it compatible with the previous work, we follow the\n",
            "same preprocessing steps as the previous section (Section5.1), i.e, limiting the\n",
            "context of the event trigger candidates to some fixed window size, transforming\n",
            "every token in the context into a vector using its word embeddings, position em-\n",
            "beddings and entity type embeddings. The result of this process is the matrix\n",
            "X = [ x0;x1;:::;x n;:::;x 2n\u00001;x2n] to represent the input trigger candidateW as\n",
            "we can see in Equation5.1. This matrix can be seen as a sequence of real-valued\n",
            "141\n",
            "  ID: 384d4cfe-bf60-4553-9bf1-f4be59df075e\n",
            "--------------------\n",
            "Node 184:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "vectors X = ( x0;x1;:::;x 2n) that will be used as input in the following CNN\n",
            "models.\n",
            "5.2.1.1 The T raditional CNN\n",
            "Giventhe windowsize k, thetraditional CNN models (as in the previous section\n",
            "5.1) for ED consider the following set of2n+ 1 consecutive k-gram vectors:\n",
            "C = fui : 0 \u0014i\u00142ng (5.2)\n",
            "Vectorui is the concatenation of thek consecutive vectors preceding positioni in\n",
            "the sequenceX:\n",
            "ui = [ xi\u0000k+1;xi\u0000k+2;:::;x i] 2Rdk (5.3)\n",
            "where the out-of-index vectors are simply set to all zeros.\n",
            "The core of the CNN models is the convolution operation, specified by the filter\n",
            "vector f 2Rdk. In CNNs,f can be seen as a feature extractor for thek-grams that\n",
            "operates via the dot product with each element inC. This produces the following\n",
            "convolution score set:\n",
            "S(C) = ffTui : 0 \u0014i\u00142ng (5.4)\n",
            "In the next step, we aggregate the features inSwith themax function, resulting\n",
            "in the aggregation score:\n",
            "pk\n",
            "f = max S(C) = max fsi : 0 \u0014i\u00142ng (5.5)\n",
            "142\n",
            "  ID: 69ec987f-e93a-4598-896a-06012798fd74\n",
            "--------------------\n",
            "Node 185:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "Afterward, pk\n",
            "f is often transformed by a non-linear functiong7 to generate the\n",
            "transformed scoreg(pk\n",
            "f ), functioning as the extracted feature for the initial trigger\n",
            "candidate W.\n",
            "We can then repeat this process for different window sizesk and filtersf, gen-\n",
            "erating multiple featuresg(pk\n",
            "f ) to capture various aspects of the trigger candidate\n",
            "W. Finally, such features are concatenated into a single representation vector for\n",
            "W, to be fed into a feed-forward neural network with a softmax layer in the end\n",
            "to perform classification.\n",
            "5.2.1.2 The Non-consecutive CNN\n",
            "As mentioned in the introduction, the limitation of the previous CNN models\n",
            "for ED is the inability to encode the non-consecutivek-grams that might be crucial\n",
            "to the trigger prediction. This limitation originates from Equation5.2 in which\n",
            "only the consecutive k-gram vectors are considered. In order to overcome such\n",
            "limitation, we propose to model all possible non-consecutivek-grams in the trigger\n",
            "candidate, leading to the following set of non-consecutivek-gram vectors:\n",
            "N = fvi1i2:::ik : 0 \u0014i1 <i2 <:::<i k \u00142ng\n",
            "where: vi1i2:::ik = [ xi1;xi2;:::;x ik ] 2 Rdk and the number of elements in N is\n",
            "jNj=\n",
            "(2n+1\n",
            "k\n",
            ")\n",
            ".\n",
            "The non-consecutive CNN model then follows the procedure of the traditional\n",
            "CNN model in Section 5.2.1.1 to compute the representation vector for classifi-\n",
            "cation. The only difference is that the computation is done on the input set\n",
            "7. The tanh function in this work.\n",
            "143\n",
            "  ID: 1a495cfa-93f5-4182-98a5-1198695ac129\n",
            "--------------------\n",
            "Node 186:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "N instead of C. In particular, the convolution score set in this case would be\n",
            "S(N) = ffTv: v2Ng, while the aggregating score would be:\n",
            "pk\n",
            "f = max S(N) = max fs: s2S(N)g (5.6)\n",
            "5.2.1.3 Implementation\n",
            "Note that the maximum operation in Equation5.5 only requires O(n) opera-\n",
            "tions while the naive implementation of Equation5.6 would needO(jNj) = O(nk)\n",
            "operations. In this work, we employ the dynamic programming (DP) procedure\n",
            "below to reduce the computation time for Equation5.6.\n",
            "Assuming the filter vectorf is the concatenation of thekvectorsf1;:::; fk 2Rd:\n",
            "f = [ f1;:::; fk], Equation5.6 can be re-written by:\n",
            "pk\n",
            "f = maxffT\n",
            "1 xi1 + ::: + fT\n",
            "k xik\n",
            ": 0 \u0014i1 <i2 <:::<i k \u00142ng\n",
            "(5.7)\n",
            "Let Dj\n",
            "t be the dynamic programming table representing the maximum convo-\n",
            "lution score for the sub-filter[f1;:::; fj] over all possible non-consecutivej-gram\n",
            "vectors in the subsequence(x0;x1;:::;x t) of X:\n",
            "Dj\n",
            "t = maxffT\n",
            "1 xi1 + ::: + fT\n",
            "j xij\n",
            ": 0 \u0014i1 <i2 <:::<i j \u0014tg\n",
            "(5.8)\n",
            "where 1 \u0014j \u0014k, j\u00001 \u0014t\u00142n.\n",
            "Note thatpk\n",
            "f = Dk\n",
            "2n.\n",
            "144\n",
            "  ID: b0284d49-dcad-46ed-ad04-c6f855bfe261\n",
            "--------------------\n",
            "Node 187:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "We can solve this DP problem by the following recursive formulas8:\n",
            "Dj\n",
            "t = max fDj\n",
            "t\u00001;Dj\u00001\n",
            "t\u00001 + fT\n",
            "j xtg (5.9)\n",
            "The computation time for this procedure isO(kn) and remains linear in the\n",
            "sequence length.\n",
            "5.2.1.4 T raining\n",
            "We train the networks using stochastic gradient descent with shuffled mini-\n",
            "batches, the AdaDelta update rule, back-propagation and dropout. During the\n",
            "training, we also optimize the embedding tables (i.e, word, position and entity type\n",
            "embeddings) to achieve the optimal states. Finally, we rescale the weights whose\n",
            "Frobenius norms exceed a predefined threshold (Nguyen and Grishman,2015a).\n",
            "5.2.2 Experiments\n",
            "We applythe same parameters, resources and the ACE 2005 corpus as Section\n",
            "5.1.2.1 (Nguyen and Grishman,2015b) to ensure the compatible comparison.\n",
            "5.2.2.1 The General Setting\n",
            "We compares the non-consecutive CNN model (NC-CNN ) with the state-of-\n",
            "the-art systems on the ACE 2005 dataset in Table5.5. These systems include:\n",
            "1) The feature-based systems with rich hand-designed feature sets as in Sec-\n",
            "tion 5.1, including: the MaxEnt model with local features in (Li et al.,2013b)\n",
            "8. W e ignore the base cases as they are trivial.\n",
            "145\n",
            "  ID: 0eb9ddaa-67a1-49c8-ba19-1664743c77f6\n",
            "--------------------\n",
            "Node 188:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "(MaxEnt); the structured perceptron model for joint beam search with local fea-\n",
            "tures (Joint+Local), and with both local and global features in (Li et al.,2013b)\n",
            "(Joint+Local+Global); and the sentence-level and cross-entity models in (Hong et\n",
            "al., 2011).\n",
            "2) The neural network models, i.e, the CNN model in Section5.1 (Nguyen and\n",
            "Grishman, 2015b) (CNN ), the dynamic multi-pooling CNN model (DM-CNN ) in\n",
            "(Chen et al., 2015) and the bidirectional recurrent neural networks (B-RNN ) in\n",
            "(Nguyen et al.,2016a).\n",
            "3) The probabilistic soft logic based model to capture the event-event correla-\n",
            "tion in (Liu et al.,2016).\n",
            "Methods F\n",
            "Sentence-level in (Hong et al.,2011) 59.7\n",
            "MaxEnt (Li et al.,2013b) 65.9\n",
            "Joint+Local (Li et al.,2013b) 65.7\n",
            "Joint+Local+Global (Li et al.,2013b) 67.5\n",
            "Cross-entity in (Hong et al.,2011) y 68.3\n",
            "Probabilistic soft logic (Liu et al.,2016) y 69.4\n",
            "CNN (Nguyen and Grishman, 2015b) 69.0\n",
            "DM-CNN (Chen et al.,2015) 69.1\n",
            "B-RNN (Nguyen et al., 2016a) 69.3\n",
            "NC-CNN 71.3\n",
            "Table 5.5: Performance with gold-standard entity mentions and types.ybeyond\n",
            "sentence level.\n",
            "The most important observation from the table is that the non-consecutive\n",
            "CNN model significantly outperforms all the compared models with large mar-\n",
            "gins. In particular, NC-CNN is 2% better than B-RNN (Nguyen et al.,2016a),\n",
            "146\n",
            "  ID: a1afa322-c759-41e4-b79f-5620f20d246d\n",
            "--------------------\n",
            "Node 189:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "the state-of-the-art system that only relies on the context information within the\n",
            "sentences of the trigger candidates. In addition, althoughNC-CNN only employs\n",
            "the sentence-level information, it is still better than the other models that further\n",
            "exploit the document-level information for prediction (an improvement of 1.9%\n",
            "over the probabilistic soft logic based model in (Liu et al.,2016)). Finally, com-\n",
            "paring NC-CNN and the CNN model in (Nguyen and Grishman,2015b), we see\n",
            "that the non-consecutive mechanism significantly improves the performance of the\n",
            "traditional CNN model for ED (up to 2.3% in absolute F-measures withp< 0:05).\n",
            "5.2.2.2 The Domain Adaptation Experiments\n",
            "This section evaluates the robustness ofNC-CNN for ED in the domain adap-\n",
            "tation setting. The setting is exactly the same as those in Section5.1.2.3. The\n",
            "only exception is with respect to the domainun of the ACE 2005 dataset that is\n",
            "also used as one of the target domains (besidesbc, its and wl) in this section.\n",
            "We report the performance onun to further demonstrate the benefit ofNC-CNN.\n",
            "Table5.6 shows the performance of the systems in the domain adaptation setting\n",
            "(i.e, similar to Table5.4).\n",
            "System In-domain(bn+nw)bc cts wl unP R F P R F P R F P R F P R FMaxEnt 74.5 59.466.0 70.1 54.561.3 66.4 49.956.959.4 34.943.9 - - -\n",
            "Joint+Local 73.5 62.767.7 70.3 57.263.1 64.9 50.857.059.5 38.446.7 - - -Joint+Local+Global72.9 63.267.7 68.8 57.562.6 64.5 52.357.756.4 38.545.7 - - -\n",
            "B-RNN 71.4 63.567.1 70.7\n",
            "  ID: 2a9f87f0-2826-4108-8a86-106c5a357b1d\n",
            "--------------------\n",
            "Node 190:\n",
            "  Text: - - -\n",
            "B-RNN 71.4 63.567.1 70.7 62.166.1 70.0 54.461.052.7 38.344.266.2 46.054.1DM-CNN 75.9 62.768.7 75.3 59.366.4 74.8 52.361.559.2 37.445.872.2 44.555.0CNN 69.2 67.068.0 70.2 65.267.6 68.3 58.262.854.8 42.047.564.6 49.956.2\n",
            "NC-CNN 74.9 66.570.4y 73.6 64.768.8y 71.7 57.363.657.8 40.347.471.7 49.058.1y\n",
            "Table 5.6: Performance on the source domain and on the target domains. Cells\n",
            "marked with †designates that NC-CNN significantly outperforms (p <0:05) all\n",
            "the compared methods on the specified domain.\n",
            "147\n",
            "  ID: e8b8c390-7633-4a40-8ed5-ee25f0d79738\n",
            "--------------------\n",
            "Node 191:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "We notice that the performance of the systemsMaxEnt, Joint+Local, B-RNN,\n",
            "CNN and Joint+Local+Global is obtained from the actual systems in the original\n",
            "work (Li et al.,2013b; Nguyen and Grishman,2015b; Nguyen et al.,2016a). The\n",
            "performance ofDM-CNN, on the other hand, is from our re-implementation of the\n",
            "system in (Chen et al.,2015) using the same hyper-parameters and resources as\n",
            "CNN and NC-CNN for a fair comparison.\n",
            "From the table, we see thatNC-CNN is significantly better than the other\n",
            "models on the source domain. This is consistent with the conclusions in Section\n",
            "5.2.2.1 and further confirms the effectiveness ofNC-CNN. More importantly,NC-\n",
            "CNN outperforms CNN and the other models on the target domainsbc, cts and\n",
            "un, and performs comparably withCNN on wl. The performance improvement is\n",
            "significant onbc and un (p <0:05), thereby verifying the robustness ofNC-CNN\n",
            "for ED across domains.\n",
            "5.3 Related W ork\n",
            "There have been three major approaches to event detection in the literature.\n",
            "First, the pattern-based approach explores the application of patterns to identify\n",
            "the instances of events, in which the patterns are formed by predicates, event trig-\n",
            "gers and constraints on the syntactic context (Cao et al.,2015a, 2015b; Grishman\n",
            "et al.,2005).\n",
            "Second, the feature-based approach relies on linguistic intuition to design effec-\n",
            "tive feature sets for statistical models for ED, ranging from the local sentence-level\n",
            "representations (Ahn, 2006; Li et al.,2013a), to the higher level structures such\n",
            "148\n",
            "  ID: b59cc1c5-aa75-4c75-bc1c-47f61fb00d3d\n",
            "--------------------\n",
            "Node 192:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "as the cross-sentence or cross-event information (Gupta and Ji,2009; Hong et al.,\n",
            "2011; Ji and Grishman,2008; Li et al.,2015; Liao and Grishman,2010a, 2010b,\n",
            "2011; McClosky et al.,2011; Patwardhan and Rilof,2009). Some recent work on\n",
            "the feature-based approach has also investigated event trigger detection in the joint\n",
            "inference with event argument prediction (Li et al.,2013b; Poon and Vanderwende,\n",
            "2010; Riedel et al.,2009; Riedel and McCallum,2011a, 2011b; Venugopal et al.,\n",
            "2014) to benefit from their inter-dependencies.\n",
            "Finally, neural networks have been introduced into ED very recently with the\n",
            "early work on convolutional neural networks (Chen et al.,2015; Nguyen and Gr-\n",
            "ishman, 2015b). The other work includes: (Nguyen et al.,2016a) that employs\n",
            "bidirectional recurrent neural networks to perform event trigger and argument\n",
            "labeling jointly, (Jagannatha and Yu,2016) that extracts event instances from\n",
            "health records with recurrent neural networks, (Nguyen et al.,2016b) that pro-\n",
            "poses a two-stage training algorithm for event extension with neural networks and\n",
            "(Nguyen et al.,2016g) that applies non-consecutive CNNs for event nugget tasks.\n",
            "5.4 Conclusion\n",
            "We present a CNN for event detection that automatically learns effective fea-\n",
            "ture representations from pre-trained word embeddings, position embeddings as\n",
            "well as entity type embeddings, and reduces the error propagation. We conducted\n",
            "experiments to compare the proposed CNN with the state-of-the-art feature-based\n",
            "systems in both the general setting and the domain adaptation setting. The ex-\n",
            "perimental results demonstrate the effectiveness as well as the robustness across\n",
            "149\n",
            "  ID: 7a129e92-5d62-4f73-bf17-bc3d933c8bba\n",
            "--------------------\n",
            "Node 193:\n",
            "  Text: CHAPTER 5. DEEP LEARNING FOR EVENT DETECTION\n",
            "domains of the CNN. In addition, we extend such CNN architecture to employ\n",
            "non-consecutive convolutions, yielding the state-of-the-art performance for ED on\n",
            "both the general setting and the domain adaptation setting.\n",
            "150\n",
            "  ID: 33e4e1ee-2f06-46b4-a53a-3025ff14bfc7\n",
            "--------------------\n",
            "Node 194:\n",
            "  Text: Chapter 6\n",
            "Memory-augmented Networks for\n",
            "Joint Inference in Information\n",
            "Extraction\n",
            "We can view the tasks in the information extraction (IE) pipeline in Figure\n",
            "1.2 as sequences of prediction tasks. For instance, for trigger prediction or event\n",
            "detection, a document can be seen as a sequence of words in which a prediction\n",
            "is performed for every word in the sequence (i.e, predicting whether a word is a\n",
            "trigger word of some event types or not). For relation extraction, the sequences\n",
            "of prediction tasks corresponds to the sequences of entity mention pairs appearing\n",
            "in the same sentences of the documents. Consequently, the whole information\n",
            "extraction pipeline translates into a very long sequence of prediction tasks by\n",
            "concatenating the sequences of the individual tasks.\n",
            "151\n",
            "  ID: 34a643c6-3d92-4c77-a3e8-b0b6f87c4abb\n",
            "--------------------\n",
            "Node 195:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Given this view, the previous chapters and work on deep learning for informa-\n",
            "tion extraction have only concerned solving the predictions in the sequences for IE\n",
            "separately or independently. An illustration is given in Figure6.1.\n",
            "Figure 6.1: A sequence of prediction tasks in information extraction.\n",
            "As we can see from the figure, there aren prediction tasks in the sequence\n",
            "indexed from 1 ton. Each prediction task has its corresponding input and output.\n",
            "The current deep learning work for IE has essentially modeled every task in this\n",
            "sequence by neural networks that run separately and carry no information from\n",
            "one step (task) to the other steps. Among several problems, such independent\n",
            "modeling is unable to capture long range dependencies or interdependencies among\n",
            "the outputs of the prediction tasks in the sequence that might be important to the\n",
            "prediction. For example, consider the following sentence for the task of event\n",
            "detection:\n",
            "At least 10 people were kil led when US drones fired missiles at three vehicles,\n",
            "an senior security official told AFP.\n",
            "There are two event trigger words in this sentence: “kil led” for the event class\n",
            "152\n",
            "  ID: d286ae4d-4fdc-4f88-9b80-5ae8dd214658\n",
            "--------------------\n",
            "Node 196:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "(type) Die and “fired” for the event type “Attack”. It is often simple to recognize\n",
            "the event type “Die” for “kil led” based on the word itself, but it is more challenging\n",
            "to identify the event type for “fired” as this word is more ambiguous (i.e, having\n",
            "multiple possible meanings depending on context such as “Attack”, “End Position”\n",
            "etc). However, if we notice that a “Die” event is very likely followed by an “Attack”\n",
            "event appearing in the same sentence, we can infer that the event type for “fired”\n",
            "should be “Attack” more easily based on the event type of “kil led”. Note that such\n",
            "dependencies can occur between event types of words that are very far from each\n",
            "other in the sentences (i.e, long-range dependencies). As a result, if we solve the\n",
            "prediction tasks for words in the sentences independently, we will not be able to\n",
            "capture those interdependencies.\n",
            "6.1 General F ramework\n",
            "In this dissertation, we propose a general memory-augmented neural networks\n",
            "to allow the inclusion of the long-range dependencies into the modeling of the\n",
            "prediction sequences in IE. An overview of this framework is shown in Fiture6.2.\n",
            "The main proposal from this figure includes:\n",
            "1. Instead of solving the prediction tasks in the sequence separately, we will\n",
            "simultaneously perform such prediction tasks from left to right (joint modeling or\n",
            "joint inference).\n",
            "2. During the modeling process from 1 ton, we will maintain a memory at\n",
            "every step. The memory of the current stepiis computed from the memory of the\n",
            "previous stepi\u00001 and the output of the current step. In general, the memory at\n",
            "153\n",
            "  ID: c7282e11-7337-4fb3-a713-4fe2c5cc9038\n",
            "--------------------\n",
            "Node 197:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Figure 6.2: Memory-augmented neural networks.\n",
            "step i is expected to memorize or summarize the outputs that we have made so\n",
            "far (i.e, from step 1 toi).\n",
            "3. When we make a prediction for the step i+ 1 , we will use the memory\n",
            "from the previous step (i.e, stepi) in addition to the current input as the evidence.\n",
            "This mechanism helps to incorporate the previous decisions (including the previous\n",
            "decisions or labels that are very far from the current step) into the prediction of\n",
            "the current step, thus being able to exploit the long-range dependencies among\n",
            "outputs of the prediction tasks.\n",
            "In order to demonstrate the effectiveness of such memory-augmented neural\n",
            "networks, we seek their applications on two important problems of information\n",
            "extraction, i.e, event extraction (EE) and entity linking (EL) in the following\n",
            "sections. The work in this chapter is published in (Nguyen et al., 2016a) and\n",
            "(Nguyen et al.,2016f).\n",
            "154\n",
            "  ID: d54f36a4-9e05-44da-a1f0-020b300d9c3f\n",
            "--------------------\n",
            "Node 198:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "6.2 Event Extraction with Memory-augmented\n",
            "Neural Networks\n",
            "6.2.1 Event Extraction T ask\n",
            "We focus on the EE task of the Automatic Context Extraction (ACE) evalua-\n",
            "tion1. ACE defines an event as something that happens or leads to some change\n",
            "of state. We employ the following terminology:\n",
            "• Event mention: a phrase or sentence in which an event occurs, including\n",
            "one trigger and an arbitrary number of arguments.\n",
            "• Event trigger : the main word that most clearly expresses an event occur-\n",
            "rence.\n",
            "• Event argument : an entity mention (including temporal expression and\n",
            "value(e.g. Job-Title))thatserversasaparticipantorattributewithaspecific\n",
            "role in an event mention.\n",
            "ACE annotates 33 types2 (e.g., “Attack, “Die”, “Start-Position”) for event men-\n",
            "tions that also correspond to the types of the event triggers. Each event type has\n",
            "its own set of roles to be filled by the event arguments. For instance, the roles for\n",
            "the “Die” event include “Place”, “Victim” and “Time”. The total number of roles\n",
            "for all the event types is 36.\n",
            "1. http://projects.ldc.upenn.edu/ace\n",
            "2. These are actually 33 subtypes of the 8 event types annotated in the ACE 2005 dataset,\n",
            "but we call them event types here for convenience.\n",
            "155\n",
            "  ID: 2b46ea1b-c7ab-48ff-9607-5c9de8f3c978\n",
            "--------------------\n",
            "Node 199:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Given an English text document, an event extraction system needs to recognize\n",
            "event triggers with specific types and their corresponding arguments with the roles\n",
            "for each sentence. Following the previous work (Chen et al.,2015; Li et al.,2013b;\n",
            "Liao and Grishman,2011), we assume that the argument candidates (i.e, the entity\n",
            "mentions, temporal expressions and values) are provided (by the ACE annotation)\n",
            "to the event extraction systems.\n",
            "For instance, we are supposed to extract two event mentions in the following\n",
            "sentence:\n",
            "In Baghdad, a cameraman died when an American tank fired on the street.\n",
            "The first event mention is associated with the trigger word “died” of type “Die”,\n",
            "and has “cameraman” as the “Victim” role and “Baghdad” as the “Place” role. The\n",
            "second event mention, on the other hand, corresponds to the trigger word “fired”\n",
            "of type “Attack”, and involves “cameraman” for the “T arget” role and “Baghdad”\n",
            "for the “Place” role.\n",
            "6.2.2 Prior Deep Learning W ork for Event Extraction\n",
            "This section describes the previous deep learning work for event extraction that\n",
            "motivates our current work.\n",
            "Assume that we have a sentence with 5 words[W1;W2;W3;W4;W5] in which\n",
            "words W2 and W5 are the heads of two entity mentions appearing in this sentence.\n",
            "Figure 6.3 shows the prediction tasks in event extraction we need to solve for this\n",
            "sentence.\n",
            "The first row of this figure represents the trigger prediction tasks (rectangles)\n",
            "156\n",
            "  ID: 0b71799c-038e-41ac-a21c-f192e33c283c\n",
            "--------------------\n",
            "Node 200:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Figure 6.3: Prediction tasks for event extraction.\n",
            "for every word (i.e, from wordW1 to wordW5) in this sentence while the rectangles\n",
            "of the second and the third row correspond to the argument prediction tasks for\n",
            "the entity mentionsW2 and W5 respectively. For instance, the argument prediction\n",
            "task forW3 and W2 (the rectangle in the middle of the figure) aims at predicting\n",
            "the role ofW2 with respect to the event associated with trigger wordW3 (assuming\n",
            "W3 is a trigger word).\n",
            "Under this view, the prior deep learning work for EE has only modeled the\n",
            "tasks in the rectangles independently via some neural networks (Chen et al.,2015),\n",
            "157\n",
            "  ID: b14aa45f-aba6-4873-81a6-d1744f7cb979\n",
            "--------------------\n",
            "Node 201:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "causing the ignorance of long-range dependencies among the tasks. One of such\n",
            "interdependencies is the correlations among the event types within the same sen-\n",
            "tences that have been demonstrated at the beginning of this chapter. Another\n",
            "important interdependency in EE is regarding to the argument roles and the event\n",
            "types. For example, reconsider the example sentence with two event mentions we\n",
            "have in Section6.2.1:\n",
            "In Baghdad, a cameraman died when an American tank fired on the street.\n",
            "It is often simple for the argument classifiers of the previous deep learning\n",
            "models for EE to realize that “cameraman” is the “T arget” argument of the “Die”\n",
            "event due to the proximity between “cameraman” and “died” in this sentence.\n",
            "However, as “cameraman” is far away from “fired”, the argument classifiers in\n",
            "such models might fail to recognize “cameraman” as the “T arget” argument for the\n",
            "event “Attack” with their local features. Fortunately, we can overcome this issue\n",
            "by relying on the global features to encode the fact that a “Victim” argument for\n",
            "the “Die” event is often the “T arget” argument for the “Attack” event in the same\n",
            "sentence. Again, exploiting such interdependencies is impossible in the prior deep\n",
            "learning models.\n",
            "In order to address such limitations, we can apply the proposed memory-\n",
            "augmented neural networks to do EE. In particular, taking the example with 5\n",
            "words in the sentence above as an example, we simultaneously (jointly) solve the\n",
            "tasks (rectangles) in Figure6.3 using the order specified in Figure6.4 (joint model-\n",
            "ing). At every step along that order, we organize a memory to store the prediction\n",
            "outputs in the previous steps, and use such memories as additional evidence in\n",
            "158\n",
            "  ID: 073fdac4-ab48-46c9-9361-a00d0ed939f3\n",
            "--------------------\n",
            "Node 202:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Figure 6.4: Memory-augmented neural networks for event extraction.\n",
            "the next predictions to capture the interdependencies. A detailed joint model for\n",
            "EE will be presented in the next section. Note that we often call the memory-\n",
            "augmented networks for EE as the joint models in the following for convenience.\n",
            "6.2.3 Model\n",
            "We formalize the EE task as follow. LetW = [ w1;w2;:::;w n] be a sentence\n",
            "where nis the sentence length andwi is thei-th token. Also, letE = [ e1;e2;:::;e k]\n",
            "159\n",
            "  ID: a4c105f6-4130-4f0c-8777-893c63c6c18b\n",
            "--------------------\n",
            "Node 203:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "be the entity mentions3 in this sentence (k is the number of the entity mentions\n",
            "and can be zero). Each entity mention comes with the offsets of the head and the\n",
            "entity type. We further assume thati1;i2;:::;i k be the indexes of the last words\n",
            "of the mention heads fore1;e2;:::;e k, respectively.\n",
            "In EE, for every tokenwi in the sentence, we need to predict the event type\n",
            "(if any) for it. Ifwi is a trigger word for some event of interest, we then need to\n",
            "predict the roles (if any) that each entity mentionej plays in such event.\n",
            "The joint model for event extraction in this work consists of two phases: (i) the\n",
            "encoding phase that applies recurrent neural networks to induce a more abstract\n",
            "representation of the sentence, and (ii) theprediction phase that uses the new repre-\n",
            "sentation to perform event trigger and argument role identification simultaneously\n",
            "for W. Figure 6.5 shows an overview of the model.\n",
            "6.2.3.1 Encoding\n",
            "Sentence Encoding\n",
            "In the encoding phase, we first transform each tokenwi into a real-valued vector\n",
            "xi using the concatenation of the following three vectors:\n",
            "1. The word embedding vector ofwi: This is obtained by looking up a pre-\n",
            "trained word embedding tableEMB (Collobert and Westion,2008; Mikolov et al.,\n",
            "2013b; Turian et al.,2010).\n",
            "2. The real-valued embedding vector for the entity type ofwi: This vector is\n",
            "motivated from the prior work (Nguyen and Grishman,2015b) and generated by\n",
            "looking up the entity type embedding table (initialized randomly) for the entity\n",
            "3. i., including ACE entity mentions, times and values.\n",
            "160\n",
            "  ID: 5324ed6b-ddcd-4df6-a4ce-951723f4f2f1\n",
            "--------------------\n",
            "Node 204:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "a\n",
            "died\n",
            "when\n",
            "a\n",
            "tank\n",
            "fired\n",
            "in\n",
            "Baghdad Sentence\n",
            "Encoding\n",
            "Trigger\n",
            "Prediction\n",
            "Argument\n",
            "Role\n",
            "Prediction\n",
            "Memory\n",
            "Vectors/Matrices\n",
            "word\n",
            "embeddings\n",
            "entity type\n",
            "embeddings\n",
            "depdendecy\n",
            "tree relations\n",
            "input sentence\n",
            "indexes of trigger\n",
            "and entity mention\n",
            "candidates\n",
            "local argument\n",
            "feature generator\n",
            "(Li et al., 2013)\n",
            "memory matrices\n",
            "hidden\n",
            "vectorsword embedding\n",
            "look up\n",
            "feature representations\n",
            "prediction outputs\n",
            "X\n",
            "Bidirectional\n",
            "Recurrent\n",
            "Neural\n",
            "Network\n",
            "a\n",
            "man\n",
            "man died when tanka fired in Baghdad\n",
            "local context\n",
            "vector extraction\n",
            "entity mention \"man\"\n",
            "entity mention \"Baghdad\"\n",
            "Figure6.5: ThejointEEmodelfortheinputsentence“ a man died when a tank fired\n",
            "in Baghdad ” with local context windowd= 1 . We only demonstrate the memory\n",
            "matrices Garg/trg\n",
            "i in this figure. Green corresponds to the trigger candidate “died”\n",
            "at the current step while violet and red are for the entity mentions “man” and\n",
            "“Baghdad” respectively.\n",
            "type ofwi. Note that we also employ the BIO annotation schema to assign entity\n",
            "type labels to each token in the sentences using the heads of the entity mentions\n",
            "as do (Nguyen and Grishman,2015b).\n",
            "3. The binary vector whose dimensions correspond to the possible relations\n",
            "between words in the dependency trees. The value at each dimension of this vector\n",
            "is set to 1 only if there exists one edge of the corresponding relation connected to\n",
            "wi in the dependency tree ofW. This vector represents the dependency features\n",
            "that are shown to be helpful in the previous research (Li et al.,2013b).\n",
            "Note that we do not use the relative position features, unlike the prior work on\n",
            "161\n",
            "  ID: 073cbdd5-e3ba-4830-87a4-bdb8e318beed\n",
            "--------------------\n",
            "Node 205:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "neural networks for EE (Chen et al.,2015; Nguyen and Grishman,2015b). The\n",
            "reason is we predict the whole sentences for triggers and argument roles jointly,\n",
            "thus having no fixed positions for anchoring in the sentences.\n",
            "The transformation from the tokenwi to the vectorxi essentially converts the\n",
            "input sentenceW into a sequence of real-valued vectorsX = [ x1;x2;:::;x n], to be\n",
            "used by recurrent neural networks to learn a more effective representation.\n",
            "Recurrent Neural Networks\n",
            "Consider the input sequenceX = [ x1;x2;:::;x n]. At each stepi, we compute\n",
            "the hidden vector\u0000 !hi based on the current input vectorxi and the previous hidden\n",
            "vector \u0000\u0000!hi\u00001, using the non-linear transformation function \b: \u0000 !hi = \b( xi;\u0000\u0000!hi\u00001).\n",
            "This recurrent computation is done overX to generate the hidden vector sequence\n",
            "[\u0000 !h1;\u0000 !h2;:::; \u0000 !hn], denoted by\u0000\u0000\u0000!RNN([x1;x2;:::;x n]) = [ \u0000 !h1;\u0000 !h2;:::; \u0000 !hn].\n",
            "An important characteristics of the recurrent mechanism is that it adaptively\n",
            "accumulates the context information from position 1 toi into the hidden vector\n",
            "\u0000 !hi, making \u0000 !hi a rich representation. However, \u0000 !hi is not sufficient for the event\n",
            "trigger and argument predictions at position i as such predictions might need\n",
            "to rely on the context information in the future (i.e, from positioni to n). In\n",
            "order to address this issue, we run a second RNN in the reverse direction fromxn\n",
            "to x1 to generate the second hidden vector sequence: \u0000\u0000\u0000RNN[(xn;xn\u00001;:::;x 1)] =\n",
            "[ \u0000hn; \u0000\u0000hn\u00001;:::;  \u0000h1] in which  \u0000hi summarizes the context information from position\n",
            "n to i. Eventually, we obtain the new representation\n",
            "  ID: ef446ce9-f526-40c0-a119-40bd6e583338\n",
            "--------------------\n",
            "Node 206:\n",
            "  Text: summarizes the context information from position\n",
            "n to i. Eventually, we obtain the new representation [h1;h2;:::;h n] for X by\n",
            "concatenating the hidden vectors in[\u0000 !h1;\u0000 !h2;:::; \u0000 !hn] and [ \u0000hn; \u0000\u0000hn\u00001;:::;  \u0000h1]. Note\n",
            "that hi essentially encapsulates the context information over the whole sentence\n",
            "162\n",
            "  ID: 39089d09-68a1-4eac-b2a7-e9cdb2de0249\n",
            "--------------------\n",
            "Node 207:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "(from 1 ton) with a greater focus on positioni. Finally, we useGated Recurrent\n",
            "Units for the non-linear function \b to mitigate the vanishing gradient problem\n",
            "(Bengio et al.,1994; Cho et al.,2014a; Chung et al.,2014).\n",
            "6.2.3.2 Prediction\n",
            "In order to jointly predict triggers and argument roles (or simultaneously per-\n",
            "form the prediction tasks in EE) forW, we maintain a binary memory vectorGtrg\n",
            "i\n",
            "for triggers, and binary memory matricesGarg\n",
            "i and Garg/trg\n",
            "i for arguments (at each\n",
            "time i). These vector/matrices are set to zeros initially (i= 0 ) and updated during\n",
            "the prediction process forW.\n",
            "Given the bidirectional representationh1;h2;:::;h n in the encoding phase and\n",
            "the initialized memory vector/matrices, the joint prediction procedure loops overn\n",
            "tokens in the sentence (from 1 ton). At each time stepi, we perform the following\n",
            "three stages in order:\n",
            "(i) trigger prediction for wi.\n",
            "(ii) argument role prediction for all the entity mentionse1;e2;:::;e k with respect\n",
            "to the current tokenwi.\n",
            "(iii) compute Gtrg\n",
            "i , Garg\n",
            "i and Garg/trg\n",
            "i for the current step using the previous mem-\n",
            "ory vector/matricesGtrg\n",
            "i\u00001, Garg\n",
            "i\u00001 and Garg/trg\n",
            "i\u00001 , and the prediction output in the\n",
            "earlier stages.\n",
            "The output of this process would be the predicted trigger typeti for wi, the\n",
            "predicted argument roles ai1;ai2;:::;a ik and the memory vector/matrices Gtrg\n",
            "i ,\n",
            "163\n",
            "  ID: 4c2a6319-775e-4fe1-8bb2-c3bf3a47ae43\n",
            "--------------------\n",
            "Node 208:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Garg\n",
            "i and Garg/trg\n",
            "i for the current step. Note thatti should be the event type ifwi\n",
            "is a trigger word for some event of interest, or “Other” in the other cases.aij, in\n",
            "constrast, should be the argument role of the entity mentionej with respect towi\n",
            "if wi is a trigger word andej is an argument of the corresponding event, otherwise\n",
            "aij is set to “Other” (j = 1 to k).\n",
            "T rigger Prediction\n",
            "In the trigger prediction stage for the current tokenwi, we first compute the\n",
            "feature representation vectorRtrg\n",
            "i for wi using the concatenation of the following\n",
            "three vectors:\n",
            "• hi: the hidden vector to encapsulate the global context of the input sentence.\n",
            "• Ltrg\n",
            "i : the local context vector forwi. Ltrg\n",
            "i is generated by concatenating the\n",
            "vectors of the words in a context windowd of wi:\n",
            "Ltrg\n",
            "i = [ EMB[wi\u0000d];:::; EMB[wi];:::; EMB[wi+d]].\n",
            "• Gtrg\n",
            "i\u00001: the memory vector from the previous step.\n",
            "The representation vectorRtrg\n",
            "i = [ hi;Ltrg\n",
            "i ;Gtrg\n",
            "i\u00001] is then fed into a feed-forward\n",
            "neural networkFtrg with a softmax layer in the end to compute the probability\n",
            "distribution Ptrg\n",
            "i;t over the possible trigger types:Ptrg\n",
            "i;t = Ptrg\n",
            "i (l = t) = Ftrg\n",
            "t (Rtrg\n",
            "i )\n",
            "where t is a trigger type. Finally, we compute the predicted typeti for wi by:\n",
            "ti = argmaxt(Ptrg\n",
            "i;t ).\n",
            "Argument Role Prediction\n",
            "In the argument role prediction stage, we first check if the predicted trigger\n",
            "type ti in the previous stage is “Other” or not. If yes, we can simply setaij to\n",
            "164\n",
            "  ID: 9a3f5bbe-f190-4635-8ff0-d79995fe02d5\n",
            "--------------------\n",
            "Node 209:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "“Other” for allj = 1 to k and go to the next stage immediately. Otherwise, we\n",
            "loop over the entity mentionse1;e2;:::;e k. For each entity mentionej with the\n",
            "head index ofij, we predict the argument roleaij with respect to the trigger word\n",
            "wi using the following procedure.\n",
            "First, we generate the feature representation vectorRarg\n",
            "ij for ej and wi by con-\n",
            "catenating the following vectors:\n",
            "• hi and hij : the hidden vectors to capture the global context of the input\n",
            "sentence forwi and ej, respectively.\n",
            "• Larg\n",
            "ij : the local context vector forwi and ej. Larg\n",
            "ij is the concatenation of the\n",
            "vectors of the words in the context windows of sized for wi and wij :\n",
            "Larg\n",
            "ij = [ EMB[wi\u0000d];:::; EMB[wi];:::; EMB[wi+d];\n",
            "EMB[wij\u0000d];:::; EMB[wij ];:::; EMB[wij+d]].\n",
            "• BINij: the hidden vector for the binary feature vectorVECij. VECij is based\n",
            "on the local argument features between the tokensi and ij from (Li et al.,\n",
            "2013b). BINij is then computed by feedingVECij into a feed-forward neural\n",
            "network Fbinary for further abstraction:BINij = Fbinary(VECij).\n",
            "• Garg\n",
            "i\u00001[j] and Garg/trg\n",
            "i\u00001 [j]: the memory vectors forej that are extracted out of\n",
            "the memory matricesGarg\n",
            "i\u00001 and Garg/trg\n",
            "i\u00001 from the previous step.\n",
            "Inthenextstep, weagainuseafeed-forwardneuralnetwork Farg withasoftmax\n",
            "layer in the end to transformRarg\n",
            "ij = [ hi;hij ;Larg\n",
            "ij ;BINij;Garg\n",
            "i\u00001[j];Garg/trg\n",
            "i\u00001 [j]] into the\n",
            "probability distribution Ptrg\n",
            "ij;a over the possible argument roles: Parg\n",
            "ij;a = Parg\n",
            "ij (l =\n",
            "165\n",
            "  ID: 57cb7d6d-24c1-474b-bca1-5be6f8cf9a69\n",
            "--------------------\n",
            "Node 210:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "a) = Farg\n",
            "a (Rarg\n",
            "ij ) where a is an argument role. Eventually, the predicted argument\n",
            "role forwi and ej is aij = argmaxa(Parg\n",
            "ij;a).\n",
            "Note that the binary vector VECij enriches the feature representation Rarg\n",
            "ij\n",
            "for argument labeling with the discrete structures discovered in the prior work\n",
            "on feature analysis for EE (Li et al.,2013b). These features include the shortest\n",
            "dependency paths, the entity types, subtypes, etc.\n",
            "The Memory V ector/Matrices\n",
            "An important characteristics of EE is the existence of the dependencies between\n",
            "trigger labels and argument roles within the same sentences Li et al.,2013b. In\n",
            "this work, we encode these dependencies into the memory vectors/matricesGtrg\n",
            "i ,\n",
            "Garg\n",
            "i and Garg/trg\n",
            "i (i= 0 to n) and use them as features in the trigger and argument\n",
            "prediction explicitly (as shown in the representation vectorsRtrg\n",
            "i and Rarg\n",
            "ij above).\n",
            "We classify the dependencies into the following three categories:\n",
            "1. The dependencies among trigger types : are captured by the memory\n",
            "vectors Gtrg\n",
            "i (Gtrg\n",
            "i 2f0;1gnT for i= 0 ;:::;n , andnT is the number of the possible\n",
            "trigger types). At timei, Gtrg\n",
            "i indicates which event types have been recognized\n",
            "before i. We obtainGtrg\n",
            "i from Gtrg\n",
            "i\u00001 and the trigger prediction outputti at timei:\n",
            "Gtrg\n",
            "i [t] = 1 if t= ti and Gtrg\n",
            "i\u00001[t] otherwise.\n",
            "A motivation for such dependencies is that if aDie event appears somewhere\n",
            "in the sentences, the possibility for the later occurrence of anAttack event would\n",
            "be likely as we have shown in the previous sections.\n",
            "2. The dependencies among argument roles : are encoded by the memory\n",
            "matrix Garg\n",
            "i (Garg\n",
            "i 2 f0;1gk\u0002nA for i = 0 ;:::;n , and nA is the number of the\n",
            "166\n",
            "  ID: 25938486-25f2-4320-8a90-0249111c997f\n",
            "--------------------\n",
            "Node 211:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "possible argument roles). At timei, Garg\n",
            "i summarizes the argument roles that the\n",
            "entity mentions has played with some event in the past. In particular,Garg\n",
            "i [j][a] =\n",
            "1 if and only ifej has the role ofawith some event before timei. Garg\n",
            "i is computed\n",
            "from Garg\n",
            "i\u00001, and the prediction outputsti and ai1;:::;a ik at timei: Garg\n",
            "i [j][a] = 1\n",
            "if ti ̸= “Other” anda= aij, andGarg\n",
            "i\u00001[j][a] otherwise (forj = 1 to k).\n",
            "3. The dependencies between argument roles and trigger types : are\n",
            "encoded by the memory matrixGarg/trg\n",
            "i (Garg/trg\n",
            "i 2f0;1gk\u0002nT for i = 0 to n). At\n",
            "time i, Garg/trg\n",
            "i specifies which entity mentions have been identified as arguments\n",
            "for which event types before. In particular,Garg/trg\n",
            "i [j][t] = 1 if and only ifej has\n",
            "been detected as an argument for some event of typetbefore i. Garg/trg\n",
            "i is computed\n",
            "from Garg/trg\n",
            "i\u00001 and the trigger prediction outputti at timei: Garg/trg\n",
            "i [j][t] = 1 if ti ̸=\n",
            "“Other” andt= ti, andGarg/trg\n",
            "i\u00001 [j][t] otherwise (for allj = 1 to k).\n",
            "6.2.3.3 T raining\n",
            "Denote the given trigger types and argument roles forW in the training time\n",
            "as T = t\u0003\n",
            "1;t\u0003\n",
            "2;:::;t \u0003\n",
            "n and A = ( a\u0003\n",
            "ij)j=1;k\n",
            "i=1;n. We train the network by minimizing the\n",
            "joint negative log-likelihood functionC for triggers and argument roles:\n",
            "C(T;A;X;E ) = \u0000log P(T;AjX;E)\n",
            "= \u0000log P(TjX;E) \u0000log\n",
            "  ID: b5a92abb-fa9c-4c07-9a4f-a53c211803a9\n",
            "--------------------\n",
            "Node 212:\n",
            "  Text: \u0000log P(TjX;E) \u0000log P(AjT;X;E )\n",
            "= \u0000\n",
            "n∑\n",
            "i=1\n",
            "log Ptrg\n",
            "i;t\u0003\n",
            "i\n",
            "\u0000\n",
            "n∑\n",
            "i=1\n",
            "I(t\u0003\n",
            "i ̸= \\ Other\\)\n",
            "k∑\n",
            "j=1\n",
            "log Parg\n",
            "ij;a\u0003\n",
            "ij\n",
            "(6.1)\n",
            "167\n",
            "  ID: e574919c-e321-4219-8900-2f5dad0f5c7d\n",
            "--------------------\n",
            "Node 213:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "where I is the indicator function.\n",
            "We apply the stochastic gradient descent algorithm with mini-batches and the\n",
            "AdaDelta update rule (Zeiler, 2012). The gradients are computed using back-\n",
            "propagation. During training, besides the weight matrices, we also optimize the\n",
            "word and entity type embedding tables to achieve the optimal states. Finally, we\n",
            "rescale the weights whose Frobenius norms exceed a hyperparameter (Kim,2014;\n",
            "Nguyen and Grishman,2015a).\n",
            "6.2.4 W ord Representation\n",
            "Following the prior work (Chen et al.,2015; Nguyen and Grishman,2015b),\n",
            "we pre-train word embeddings from a large corpus and employ them to initial-\n",
            "ize the word embedding table. In this work, following Chapter 1, besides the\n",
            "CBOW and SKIP-GRAM models in (Mikolov et al.,2013a, 2013b), we examine a\n",
            "concatenation-based variant of CBOW (C-CBOW) to train word embeddings and\n",
            "compare the three models to understand their effectiveness for EE. The objective\n",
            "of C-CBOW is to predict the target word usingthe concatenation of the vectors of\n",
            "the words surrounding it .\n",
            "6.3 Experiments\n",
            "6.3.1 Resources, Parameters and Dataset\n",
            "For all the experiments below, in the encoding phase, we use 50 dimensions\n",
            "for the entity type embeddings, 300 dimensions for the word embeddings and 300\n",
            "168\n",
            "  ID: a4157157-94b0-4e5d-8a88-5883fbd7ab8e\n",
            "--------------------\n",
            "Node 214:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "units in the hidden layers for the RNNs.\n",
            "Regarding the prediction phase, we employ the context window of 2 for the\n",
            "local features, and the feed-forward neural networks with one hidden layer forFtrg,\n",
            "Farg and Fbinary (the size of the hidden layers are 600, 600 and 300 respectively).\n",
            "Finally, for training, we use the mini-batch size = 50 and the parameter for the\n",
            "Frobenius norms = 3.\n",
            "These parameter values are either inherited from the prior research (Chen et al.,\n",
            "2015; Nguyen and Grishman,2015b) or selected according to the validation data.\n",
            "We pre-train the word embeddings from the English Gigaword corpus utilizing\n",
            "the word2vec toolkit4 (modified to add the C-CBOW model). Following (Baroni\n",
            "et al.,2014), we employ the context window of 5, the subsampling of the frequent\n",
            "words set to 1e-05 and 10 negative samples.\n",
            "We also evaluate the model with the ACE 2005 corpus for event extraction. For\n",
            "the purpose of comparison, we use the same data split as the previous work (Chen\n",
            "et al., 2015; Ji and Grishman,2008; Li et al.,2013b; Liao and Grishman,2010b;\n",
            "Nguyen and Grishman,2015b). This data split includes 40 newswire articles (672\n",
            "sentences) for the test set, 30 other documents (836 sentences) for the development\n",
            "set and 529 remaining documents (14,849 sentences) for the training set. Also,\n",
            "we follow the criteria of the previous work (Chen et al.,2015; Ji and Grishman,\n",
            "2008; Li et al.,2013b; Liao and Grishman,2010b) to judge the correctness of the\n",
            "predicted event mentions.\n",
            "4. https://code.google.com/p/word2vec\n",
            "169\n",
            "  ID: 32c95bec-279e-4288-9420-cb723cf68e6c\n",
            "--------------------\n",
            "Node 215:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "6.3.1.1 Memory V ector/Matrices\n",
            "This section evaluates the effectiveness of the memory vector and matrices\n",
            "presented in Section 6.2.3.2. In particular, we test the joint model on different\n",
            "cases where the memory vector for triggers Gtrg and the memory matrices for\n",
            "arguments Garg/trg and Garg are included or excluded from the model. As there are\n",
            "4 different ways to combineGarg/trg and Garg for argument labeling and two options\n",
            "to to employGtrg or not for trigger labeling, we have 8 systems for comparison\n",
            "in total. Table 6.1 reports the identification and classification performance (F1\n",
            "scores) for triggers and argument roles on the development set. Note that we are\n",
            "using the word embeddings trained with the C-CBOW technique in this section.\n",
            "System No Garg/trg Garg Garg/trg+Garg\n",
            "No Trigger 67.9 68.0 64.6 64.2\n",
            "Argument 55.6 58.1 55.2 53.1\n",
            "Gtrg Trigger 63.8 61.0 61.3 66.8\n",
            "Argument 55.2 56.6 54.7 53.6\n",
            "Table 6.1: Performance of the memory vector/matrices on the development set.\n",
            "No means not using the memory vector/matrices.\n",
            "We observe that the memory vectorGtrg is not helpful for the joint model as it\n",
            "worsens both trigger and argument role performance (considering the same choice\n",
            "of the memory matricesGarg/trg andGarg (i.e, the same row in the table) and except\n",
            "in the row withGarg/trg + Garg).\n",
            "The clearest trend is thatGarg/trg is very effective in improving the performance\n",
            "of argument labeling. This is true in both the inclusion and exclusion ofGtrg. Garg\n",
            "and its combination withGarg/trg, on the other hand, have negative effect on this\n",
            "170\n",
            "  ID: a9ad9b78-d13b-4b59-b4d8-e6970b0c80f8\n",
            "--------------------\n",
            "Node 216:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "task. Finally, Garg/trg and Garg do not contribute much to the trigger labeling\n",
            "performance in general (except in the case where Gt, Garg/trg and Garg are all\n",
            "applied).\n",
            "These observations suggest that the dependencies among trigger types and\n",
            "among argument roles are not strong enough to be helpful for the joint model\n",
            "in this dataset. This is in contrast to the dependenciesbetween argument roles\n",
            "and trigger types that improve the joint model significantly.\n",
            "The best system corresponds to the application of the memory matrixGarg/trg\n",
            "and will be used in all the experiments below.\n",
            "6.3.1.2 W ord Embedding Evaluation\n",
            "We investigate different techniques to obtain the pre-trained word embeddings\n",
            "for initialization in the joint model of EE. Table6.2 presents the performance (for\n",
            "both triggers and argument roles) on the development set when the CBOW, SKIP-\n",
            "GRAM and C-CBOW techniques are utilized to obtain word embeddings from\n",
            "the same corpus. We also report the performance of the joint model when it is\n",
            "initialized with theword2vec word embeddings from (Mikolov et al.,2013a, 2013b)\n",
            "(trained with the Skip-gram model on Google News) (WORD2VEC). Finally, for\n",
            "comparison, the performance of the random word embeddings (RANDOM) is also\n",
            "included. All of these word embeddings are updated during the training of the\n",
            "model.\n",
            "The first observation from the table is that RANDOM is not good enough\n",
            "to initialize the word embeddings for joint EE and we need to borrow some pre-\n",
            "171\n",
            "  ID: 9f28dd5a-391d-46ef-a2c6-2e037f984a70\n",
            "--------------------\n",
            "Node 217:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Word EmbeddingsTrigger Argument\n",
            "RANDOM 59.9 50.1\n",
            "SKIP-GRAM 66.7 57.1\n",
            "CBOW 66.5 53.8\n",
            "WORD2VEC 66.9 56.4\n",
            "C-CBOW 68.0 58.1\n",
            "Table 6.2:Performance of the word embedding techniques.\n",
            "trained word embeddings for this purpose. Second, SKIP-GRAM, WORD2VEC\n",
            "and CBOW have comparable performance on trigger labeling while the argument\n",
            "labeling performance of SKIP-GRAM and WORD2VEC is much better than that\n",
            "of CBOW for the joint EE model. Third and most importantly, among the com-\n",
            "pared word embeddings, it is clear that C-CBOW significantly outperforms all the\n",
            "others. We believe that the better performance of C-CBOW stems from its con-\n",
            "catenation of the multiple context word vectors, thus providing more information\n",
            "to learn better word embeddings than SKIP-GRAM and WORD2VEC. In addi-\n",
            "tion, the concatenation mechanism essentially helps to assign different weights to\n",
            "different context words, thereby being more flexible than CBOW that applies a\n",
            "single weight for all the context words.\n",
            "From now on, for consistency, C-CBOW would be utilized in all the following\n",
            "experiments.\n",
            "6.3.1.3 Comparison to the State of the Art\n",
            "The state-of-the-art systems for EE on the ACE 2005 dataset have been the\n",
            "pipelined system with dynamic multi-pooling convolutional neural networks by\n",
            "(Chen et al.,2015) (DMCNN) and the joint system with structured prediction\n",
            "172\n",
            "  ID: 605e4224-bef1-4314-9a02-ce6de9d95b48\n",
            "--------------------\n",
            "Node 218:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "and various discrete local and global features by (Li et al.,2013b) (Li’s structure).\n",
            "Note that the pipelined system in (Chen et al.,2015) is also the best-reported\n",
            "system based on neural networks for EE. Table6.3 compares these state-of-the-\n",
            "art systems with the joint RNN-based model in this work (denoted byJRNN).\n",
            "For completeness, we also report the performance of the following representative\n",
            "systems:\n",
            "1) Li’s baseline: This is the pipelined system with local features by (Li et al.,\n",
            "2013b).\n",
            "2) Liao’s cross event: is the system by (Liao and Grishman,2010b) with the\n",
            "document-level information.\n",
            "3) Hong’s cross-entity (Hong et al.,2011): This system exploits the cross-\n",
            "entity inference, and is also the best-reported pipelined system with discrete fea-\n",
            "tures in the literature.\n",
            "Model Trigger Trigger IdentificationArgument Argument\n",
            "Identification (%)+ Classification (%)Identification (%)Role (%)\n",
            "P R F P R F P R F P R F\n",
            "Li’s basline 76.2 60.5 67.4 74.5 59.1 65.9 74.1 37.4 49.7 65.4 33.1 43.9\n",
            "Liao’s cross-event† N/A 68.7 68.9 68.8 50.9 49.7 50.3 45.1 44.1 44.6\n",
            "Hong’s cross-entity† N/A 72.9 64.3 68.3 53.4 52.9 53.1 51.6 45.5 48.3\n",
            "Li’s structure 76.9 65.0 70.4 73.7 62.3 67.5 69.8 47.9 56.8 64.7 44.4 52.7\n",
            "DMCNN 80.4 67.773.5 75.6 63.6 69.1 68.8 51.9 59.1\n",
            "  ID: 53a72b8d-81e0-4fdf-b463-6b72550582f6\n",
            "--------------------\n",
            "Node 219:\n",
            "  Text: 63.6 69.1 68.8 51.9 59.1 62.2 46.9 53.5\n",
            "JRNN 68.5 75.7 71.9 66.0 73.0 69.3 61.4 64.262.8 54.2 56.755.4\n",
            "Table 6.3:Overall performance on the blind test data. “†” designates the systems\n",
            "that employ the evidences beyond sentence level.\n",
            "From the table, we see that JRNN achieves the best F1 scores (for both trigger\n",
            "and argument labeling) among all of the compared models. This is significant with\n",
            "the argument role labeling performance (an improvement of 1.9% over the best-\n",
            "reported model DMCNN in (Chen et al.,2015)), and demonstrates the benefit of\n",
            "173\n",
            "  ID: 42ee1e35-4d5e-460c-8c97-74c99e7d44de\n",
            "--------------------\n",
            "Node 220:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "the joint model with RNNs and memory features in this work. In addition, as\n",
            "JRNN significantly outperforms the joint model with discrete features in (Li et al.,\n",
            "2013b) (an improvement of 1.8% and 2.7% for trigger and argument role labeling\n",
            "respectively), we can confirm the effectiveness of RNNs to learn effective feature\n",
            "representations for EE.\n",
            "6.3.2 Sentences with Multiple Events\n",
            "In order to further prove the effectiveness of JRNN, especially for those sen-\n",
            "tences with multiple events, we divide the test data into two parts according to\n",
            "the number of events in the sentences (i.e, single event and multiple events) and\n",
            "evaluate the performance separately, following (Chen et al.,2015). Table6.4 shows\n",
            "the performance (F1 scores) of JRNN, DMCNN and two other baseline systems,\n",
            "named Embeddings+T and CNN in (Chen et al.,2015). Embeddings+T uses\n",
            "word embeddings and the traditional sentence-level features in (Li et al.,2013b)\n",
            "while CNN is similar to DMCNN, except that it applies the standard pooling\n",
            "mechanism instead of the dynamic multi-pooling method (Chen et al.,2015).\n",
            "The most important observation from the table is that JRNN significantly\n",
            "outperforms all the other methods with large margins when the input sentences\n",
            "contain more than one events (i.e, the row labeled with1/N in the table). In\n",
            "particular, JRNN is 13.9% better than DMCNN on trigger labeling while the\n",
            "corresponding improvement for argument role labeling is 6.5%, thereby further\n",
            "suggesting the benefit of JRNN with the memory features. Regarding the per-\n",
            "formance on the single event sentences, JRNN is still the best system on trigger\n",
            "174\n",
            "  ID: 82f065fb-5837-4927-b1db-f6c89f3e83ed\n",
            "--------------------\n",
            "Node 221:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Stage Model 1/1 1/N all\n",
            "Embedding+T 68.1 25.5 59.8\n",
            "Trigger CNN 72.5 43.1 66.3\n",
            "DMCNN 74.3 50.9 69.1\n",
            "JRNN 75.6 64.8 69.3\n",
            "Embedding+T 37.4 15.5 32.6\n",
            "Argument CNN 51.6 36.6 48.9\n",
            "DMCNN 54.6 48.7 53.5\n",
            "JRNN 50.0 55.2 55.4\n",
            "Table 6.4:System performance on single event sentences (1/1) and multiple event\n",
            "sentences (1/N).\n",
            "labeling although it is worse than DMCNN on argument role labeling. This can\n",
            "be partly explained by the fact that DMCNN includes the position embedding\n",
            "features for arguments and the memory matrixGarg/trg in JRNN is not functioning\n",
            "in this single event case.\n",
            "6.4 Entity Linking with Memory-augmented\n",
            "Neural Networks\n",
            "The previous section has highlighted the benefits of the memory-augmented\n",
            "neural networks for event extraction. This section applies the memory-augmented\n",
            "networks on the task of entity linking (EL) to further demonstrate their advantages.\n",
            "6.4.1 Entity Linking\n",
            "Entity linking (EL) is the task to map entity mentions in documents to their\n",
            "correct entries (called target entities) in some existing knowledge bases (KB). As\n",
            "175\n",
            "  ID: ce2c493e-5117-4857-9780-0b8d3c4bf7e5\n",
            "--------------------\n",
            "Node 222:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "we use the typical knowledge base of Wikipedia in this work, the problem becomes\n",
            "linking entity mentions in documents to their corresponding pages in Wikipedia.\n",
            "For instance, consider the following text:\n",
            "Chelsea have long-standing rivalries with North London clubs Arsenal and\n",
            "T ottenham Hotspur. A strong rivalry with Leeds United dates back to several heated\n",
            "and controversial matches in the 1960s and 1970s.\n",
            "In this text, an entity linking system should be able to link the entity mentions\n",
            "“Chelsea”, “North London”, “Arsenal”, “T ottenham Hotspur”, and “Leeds United”\n",
            "to their corresponding Wikipedia pages about football clubs, rather than the cities\n",
            "in London. EL is a challenging problem of natural language processing, as the\n",
            "same entity might be presented in various names, and the same entity mention\n",
            "string might refer to different entities in different contexts (ambiguity).\n",
            "Inorderto tackletheambiguityinEL, thegeneral frameworkisto firstgenerate\n",
            "a set of target entities in the knowledge bases as the referent candidates for each\n",
            "entity mention in the documents (target candidates), and then solve a ranking\n",
            "problem to disambiguate the entity mention. The key challenge in this paradigm\n",
            "is the ranking model that computes the relevance of each target entity candidate to\n",
            "the corresponding entity mention using the available context information in both\n",
            "the documents and the knowledge bases.\n",
            "6.4.1.1 Prior Deep Learning W ork for Entity Linking\n",
            "The sequence of prediction tasks in entity linking corresponds to the sequence\n",
            "of entity mentions in documents where we need to perform a prediction for each\n",
            "176\n",
            "  ID: 77805d5e-c0c4-4057-86b8-cb8ebf9b712f\n",
            "--------------------\n",
            "Node 223:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "entity mention (disambiguation). The previous deep learning models have only\n",
            "solved entity linking by independently disambiguating entity mentions in docu-\n",
            "ments (Francis-Landau et al.,2016) (the local approach for EL). Figure6.6 demon-\n",
            "strates the prediction tasks that the previous deep learning models have done for\n",
            "our example text above.\n",
            "Figure 6.6: Prediction tasks for entity linking.\n",
            "In this figure, each rectangle is associated with a prediction task for an entity\n",
            "mention in the text that would be modeled by a neural network (Francis-Landau et\n",
            "al., 2016). As we can see, there are no connection between the rectangles, leading\n",
            "to the independent disambiguation of the entity mentions.\n",
            "Unfortunately, this independent mechanism in the local approach overlooks\n",
            "the topical coherence among target entities referred by entity mentions within the\n",
            "same document. The central idea is that the referent entities of some mentions\n",
            "in a document might in turn introduce useful information to link other mentions\n",
            "in that document due to the semantic relatedness among them. For instance,\n",
            "consider the entity mention “Liverpool” in the following sentence that appears\n",
            "after the aforementioned example text in the same document:\n",
            "More recently a rivalry with Liverpool has grown fol lowing repeated clashes in\n",
            "cup competitions.\n",
            "If we just rely on “Liverpool” and its context in this sentence, we might not be\n",
            "able to recognize the correct realistic entity for it as the context is not sufficient\n",
            "177\n",
            "  ID: 5773f8be-566a-40b3-8992-5dad50d03999\n",
            "--------------------\n",
            "Node 224:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "to suggest an unique entity (i.e, “Liverpool” can be any any sport clubs in this\n",
            "sentence based on the phrase “cup competitions”). However, if we refer the the\n",
            "previous entity mentions (i.e, ‘Chelsea”, “North London”, “Arsenal”, “T ottenham\n",
            "Hotspur”, and “Leeds United”) that are already known as football clubs, we can\n",
            "use the semantic relatedness to infer that ‘Liverpool” is also a football club in\n",
            "this case. Such coherence has been shown to be effective for EL in the previous\n",
            "feature-based work (Alhelbawy and Gaizauskas,2014; Han et al.,2011; He et al.,\n",
            "2013b; Hoffart et al.,2011; Pershina et al.,2015; Ratinov et al.,2011), but it is\n",
            "not exploited in the current EL models based on deep learning.\n",
            "In this work, we overcome this limitation by employing the memory-augmented\n",
            "neural networks for EL. Specifically, given a document, wesimultaneously perform\n",
            "linking for every entity mention from the beginning to the end of the document,\n",
            "as demonstrated in Figure6.7. For each entity mention, we utilize convolutional\n",
            "neural networks (CNN) to obtain the distributed representations for the entity\n",
            "mention as well as its target candidates. These distributed representations are\n",
            "then used for two purposes: (i) computing the local similarities for the entity\n",
            "mention and target candidates, and (ii) functioning as the input for the recurrent\n",
            "neural networks (RNN) that runs over the entity mentions in the documents. The\n",
            "role of the RNNs is to accumulate information about the previous entity mentions\n",
            "and target entities, and provide them as the global constraints for the linking\n",
            "process of the current entity mention (i.e, the memory in our general memory-\n",
            "augmented neural networks). We systematically evaluate the proposed model on\n",
            "multiple datasets in both the general setting and the domain adaptation setting.\n",
            "178\n",
            "  ID: 13965c86-7d4b-46c0-9c23-ef16762b300c\n",
            "--------------------\n",
            "Node 225:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "The experiment results show that the proposed model outperforms the current\n",
            "state-of-the-art models on the evaluated datasets. To our knowledge, this is also\n",
            "the first work investigating the EL problem in the domain adaptation setting.\n",
            "Figure 6.7: Memory-augmented neural networks for entity linking.\n",
            "6.4.2 Model\n",
            "The entity linking problem in this work can be formalized as follows. LetDOC\n",
            "be the input document andE = fent1;ent2;:::; entkgbe the entity mentions in\n",
            "DOC. The goal is to map each entity mentionenti to its corresponding Wikipedia\n",
            "page (entity) or return “NIL” ifenti is not present in Wikipedia. For each entity\n",
            "mention enti 2DOC, let Pi = fpagei1;pagei2;::: pageinigbe its set of Wikipedia\n",
            "candidate pages (entities)5 where ni is the number of page candidates forenti.\n",
            "Also, letpage\u0003\n",
            "i 2Pi be the correct target entity forenti.\n",
            "Following (Francis-Landau et al.,2016), we represent each entity mentionenti\n",
            "by the tripleenti = ( sufi;ctxi;doci), where sufi is the surface string of enti, ctxi\n",
            "is theimmediate context (within some predefined window) ofenti and doci is the\n",
            "entire document containing enti. Essentially, sufi, ctxi and doci are the sequences\n",
            "5. F or a fair comparison, we use the target candidates provided by (F rancis-Landau et\n",
            "al., 2016). Essentially , a query generation is executed for each entity mention, whose outputs\n",
            "are combined with link counts to retrieve the potential entities (including “ NIL”). The query\n",
            "generation itself involves removing stop words, plural suffixes, punctuation, and leading or tailing\n",
            "words.\n",
            "179\n",
            "  ID: ff67d5a8-7e46-4baa-b2db-01229042b57d\n",
            "--------------------\n",
            "Node 226:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "of words to capture the contexts or topics ofenti at multiple granularities. For\n",
            "the target candidate pagespageij, we use thetitle til ij and body content bdy ij to\n",
            "represent them (pageij = ( tilij;bdyij)). For convenience, we also denotepage\u0003\n",
            "i =\n",
            "(til\u0003\n",
            "i;bdy\u0003\n",
            "i) for the correct entity pages. Again, tilij, bdyij, til\u0003\n",
            "i and bdy\u0003\n",
            "i are also\n",
            "sequences of words.\n",
            "In order to link the entity mentions, the strategy is to assign a relevance score\n",
            "ϕ(enti;pageij) for each target candidatepageij of enti, and then use these scores to\n",
            "rank the candidates for each mention. In this work, we decomposeϕ(enti;pageij)\n",
            "as the sum of the two following factors:\n",
            "ϕ(enti;pageij) = ϕlocal(enti;pageij) + ϕglobal(ent1;ent2;:::; enti;P1;P2;:::;P i)\n",
            "(6.2)\n",
            "In this formula,ϕlocal(enti;pageij) represents the local similarities betweenenti and\n",
            "pij, i.e, only using the information related toenti and pageij. ϕglobal(ent1;ent2;:::;\n",
            "enti;P1;P2;:::;P i), on the other hand, additionally considers the other mentions\n",
            "and candidates in the document, attempting to model the interdependence among\n",
            "theseobjects. Thedenotation ϕglobal(ent1;ent2;:::; enti;P1;P2;:::;P i) impliesthat\n",
            "we are computing the ranking scores for all the target candidates of all the entity\n",
            "mentions in each document simultaneously, preserving the order of the entity men-\n",
            "tions from the beginning to the end of the document.\n",
            "The model in this work consists of three main components: (i) the encoding\n",
            "component that applies convolutional neural networks to induce the distributed\n",
            "representations for the input sequences sufi, ctxi, doci, tilij, and bdyij, (ii) the\n",
            "local\n",
            "  ID: c1cc6ddd-5b04-4bac-aa1c-06689dd6fe04\n",
            "--------------------\n",
            "Node 227:\n",
            "  Text: ctxi, doci, tilij, and bdyij, (ii) the\n",
            "local component that computes the local similarities ϕlocal(enti;pageij) for each\n",
            "180\n",
            "  ID: 8d5cc16e-395b-47bf-9841-3f0f5e1d0a11\n",
            "--------------------\n",
            "Node 228:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "entity mentionenti, and (iii) the global component that runs recurrent neural net-\n",
            "works on the entity mentionsfent1;ent2;:::; entkgto generate the global features\n",
            "ϕglobal(ent1;ent2;:::; enti;P1;P2;:::;P i).\n",
            "6.4.2.1 Encoding\n",
            "Let W be some context word sequence of the entity mentions or target candi-\n",
            "dates (i.e,x2fsufi;ctxi;docigi [ftilij;pageijgi;j [ftil\u0003\n",
            "i;bdy\u0003\n",
            "igi). In order to obtain\n",
            "the distributed representation forW, we first transform each wordwi 2W into\n",
            "a real-valued, me-dimensional vector xi using the word embedding table EMB\n",
            "(Mikolov et al., 2013b): xi = EMB[wi]. This essentially converts the word se-\n",
            "quence W into a sequence of vectors that is padded with zero vectors to form a\n",
            "fixed-length sequence of vectorsX = [ x1;x2;:::;x n] of lengthn.\n",
            "In the next step, we apply the convolution operation overX to generate the\n",
            "hidden vector sequence, that is then transformed by a non-linear functiong and\n",
            "pooled by thesum function (Francis-Landau et al.,2016). Following the previous\n",
            "work on CNN (Nguyen and Grishman, 2015a, 2015b), we utilize the set L of\n",
            "multiple window sizes to parameterize the convolution operation. Each window\n",
            "size l 2L corresponds to a convolution matrixMl 2Rv\u0002lme of dimensionalityv.\n",
            "Eventually, the concatenation vector\u0016W of the resulting vectors for each window\n",
            "size inL would be used as the distributed representation forW:\n",
            "\u0016W =\n",
            "⊕\n",
            "l2L\n",
            "n\u0000l+1∑\n",
            "i=1\n",
            "g(Mlxi:(i+l\u00001)) (6.3)\n",
            "where ⊕ is the concatenation operation over the window setLand xi:(i+l\u00001) is the\n",
            "181\n",
            "  ID: 51a1fee3-10c8-4233-a396-365a31d15db8\n",
            "--------------------\n",
            "Node 229:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "concatenation vector of the given word vectors.\n",
            "For convenience, let\u0016sufi, \u0016ctxi, \u0016doci, \u0016tilij, \u0016bdyij, \u0016til\n",
            "\u0003\n",
            "i and \u0016bdy\n",
            "\u0003\n",
            "i be the distributed\n",
            "representations ofsufi, ctxi, doci, tilij, bdyij, til\u0003\n",
            "i and bdy\u0003\n",
            "i obtained by the convolu-\n",
            "tion procedure above, respectively. Note that we apply the same set of convolution\n",
            "parameters for each type of text granularity in the source documentDOC as well\n",
            "as in the target entity side. The vector representations of the context would then\n",
            "be fed into the next components to compute the features for EL.\n",
            "6.4.2.2 Local Similarities\n",
            "We employ the local similaritiesϕlocal(enti;pageij) from Francis-Landau et al.,\n",
            "2016, the state-of-the-art neural network model for EL. In particular:\n",
            "ϕlocal(enti;pageij) = ϕsparse(enti;pageij) + ϕCNN(enti;pageij)\n",
            "= WsparseFsparse(enti;pageij) + WCNNFCNN(enti;pageij)\n",
            "(6.4)\n",
            "In this formula, Wsparse and WCNN are the weights for the feature vectors\n",
            "Fsparse and FCNN respectively. Fsparse(enti;pageij) is the sparse feature vector\n",
            "obtained from (Durrett and Klein,2014). This vector captures various linguistic\n",
            "properties and statistics that have been discovered in the previous studies for EL.\n",
            "The representative features include the anchor text counts from Wikipedia, the\n",
            "string match indications with the title of the Wikipedia candidate pages, or the\n",
            "information about the shape of the queries for candidate generations (Francis-\n",
            "Landau et al.,2016).\n",
            "FCNN(enti;pageij), on the other hand, involves the cosine similarities between\n",
            "182\n",
            "  ID: 78486ee5-3877-4805-8f9e-49d7ad2997ed\n",
            "--------------------\n",
            "Node 230:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "the representation vectors at multiple granularities ofenti and pageij. In particular:\n",
            "FCNN(enti;pageij)\n",
            "= [ cos( \u0016sufi; \u0016tilij);cos( \u0016ctxi; \u0016tilij);cos( \u0016doci; \u0016tilij);\n",
            "cos( \u0016sufi; \u0016bdyij);cos( \u0016ctxi; \u0016bdyij);cos( \u0016doci; \u0016bdyij)]\n",
            "(6.5)\n",
            "The intuition for this computation is that the similarities at different levels\n",
            "of contexts might help to enforce the potential topic compatibility between the\n",
            "contexts of the entity mentions and target candidates for EL (Francis-Landau et\n",
            "al., 2016).\n",
            "6.4.2.3 Global Similarities\n",
            "In order to encapsulate the coherence among the entity mentions and their tar-\n",
            "get entities, we run recurrent neural networks over the sequences of the representa-\n",
            "tion vectors for the entity mentions (i.e, the vector sequences for the surface strings\n",
            "( \u0016suf1; \u0016suf2;:::; \u0016sufk) and for the immediate contexts( \u0016ctx1; \u0016ctx2;:::; \u0016ctxk)) and\n",
            "the target entities (i.e, the vector sequences for the page titles( \u0016til\n",
            "\u0003\n",
            "1; \u0016til\n",
            "\u0003\n",
            "2;:::; \u0016til\n",
            "\u0003\n",
            "k)\n",
            "and for the body contents( \u0016bdy\n",
            "\u0003\n",
            "1; \u0016bdy\n",
            "\u0003\n",
            "2;:::; \u0016bdy\n",
            "\u0003\n",
            "k))6.\n",
            "Let us take the representation vector sequence of the body contents of the\n",
            "target pages( \u0016bdy\n",
            "\u0003\n",
            "1; \u0016bdy\n",
            "\u0003\n",
            "2;:::; \u0016bdy\n",
            "\u0003\n",
            "k)7 as an example. The recurrent neural network\n",
            "with the recurrent function\b for this sequence will generate the hidden vector\n",
            "sequence (hb\n",
            "1;hb\n",
            "2;:::;h b\n",
            "k) where: hb\n",
            "i = \b( hb\n",
            "i\u00001;\n",
            "  ID: f2fd8246-9e72-4ff4-95dd-b82bb9e68701\n",
            "--------------------\n",
            "Node 231:\n",
            "  Text: b\n",
            "k) where: hb\n",
            "i = \b( hb\n",
            "i\u00001; \u0016bdy\n",
            "\u0003\n",
            "i).\n",
            "6. Note that we have different recurrent neural networks for different context vector se-\n",
            "quences.\n",
            "7. In the training process, ( \u0016bdy\n",
            "\u0003\n",
            "1; \u0016bdy\n",
            "\u0003\n",
            "2; : : : ; \u0016bdy\n",
            "\u0003\n",
            "k) are obtained from the golden target entities\n",
            "while in the test time, they are retrieved from the predicted target entities.\n",
            "183\n",
            "  ID: fa2ba66f-b0e7-4a84-a914-1335e8c64e3c\n",
            "--------------------\n",
            "Node 232:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Each vectorhb\n",
            "i in this sequence encodes or summarizes the information about\n",
            "the content of the previous target entities (i.e, beforei) in the document due to\n",
            "the property of RNN.\n",
            "Given the hidden vector sequence, when predicting the target entity for the\n",
            "entity mentionenti, we ensure that the target entity is consistent with the global\n",
            "information stored inhb\n",
            "i\u00001. This is achieved by using the cosine similarities between\n",
            "hb\n",
            "i\u00001 and the representation vectors of each target candidatepageij of enti, (i.e,\n",
            "cos(hb\n",
            "i\u00001; \u0016tilij) and cos(hb\n",
            "i\u00001; \u0016bdyij)) as the global features for the ranking score.\n",
            "We can repeat this process for the other representation vector sequences in both\n",
            "the entity mention side and the target entity side. The resulting global features\n",
            "would then be grouped into a single feature vector to compute the global similarity\n",
            "score ϕglobal(ent1;ent2;:::; enti;P1;P2;:::;P i) as in the local similarity section. An\n",
            "overview of the whole model is presented in Figure6.8.\n",
            "Regarding the recurrent function\b, we also employ theGated Recurrent Units\n",
            "(Cho et al.,2014a) to alleviate the “vanishing gradient problem ” of RNN. Finally,\n",
            "for training, we jointly optimize the parameters for the CNNs, RNNs and weight\n",
            "vectorsbymaximizingthelog-likelihoodofalabeledtrainingcorpus. Weutilizethe\n",
            "stochastic gradient descent algorithm and the AdaDelta update rule Zeiler,2012.\n",
            "The gradients are computed via back-propagation. Following (Francis-Landau et\n",
            "al., 2016), we do not update the word embedding table during training.\n",
            "184\n",
            "  ID: 68610706-760e-49f2-b4fc-d2683b4bb9d7\n",
            "--------------------\n",
            "Node 233:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Figure 6.8: Joint model for learning local and global features for a document\n",
            "with 3 entity mentions: “Chelsea”, “Arsenal” and “Liverpool”. Each of the entity\n",
            "mentions has two entity candidate pages (either a football club or a city).The\n",
            "orange rectangles denote the CNN-induced representation vectors\u0016sufi, \u0016ctxi, \u0016doci,\n",
            "\u0016tilij and \u0016bdyij. The circles in red and green are the ranking scores for the target\n",
            "candidates, in which the green circles correspond to the correct target entities.\n",
            "Finally, the circles in grey are the hidden vectors (i.e, the global vectors) of the\n",
            "RNNs running over the entity mentions. We only show the global entity vectors\n",
            "in this figure to improve the visualization.\n",
            "6.4.3 Experiments\n",
            "6.4.3.1 Datasets\n",
            "Following (Francis-Landau et al.,2016), we evaluate the models on 4 different\n",
            "entity linking datasets:\n",
            "i) ACE (Bentivogli et al.,2010): This corpus is from the 2005 evaluation of\n",
            "185\n",
            "  ID: 43252a48-5d81-44a2-b02c-8da119674965\n",
            "--------------------\n",
            "Node 234:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "NIST. It is also used in (Fahrni and Strube,2014 and Durrett and Klein,2014).\n",
            "ii) CoNLL-YAGO (Hoffart et al., 2011): This corpus is originally from the\n",
            "CoNLL 2003 shared task of named entity recognition for English.\n",
            "iii) WP (Heath and Bizer,2011): This dataset consists of short snippets from\n",
            "Wikipedia.\n",
            "iv) WIKI (Ratinov et al.,2011): This dataset contains 10,000 randomly sam-\n",
            "pled Wikipedia articles. The task is to disambiguate the links in each article8.\n",
            "For all the datasets, we use the standard data splits (for training data, test\n",
            "data and development data) as the previous works for comparable comparison\n",
            "(Francis-Landau et al.,2016).\n",
            "6.4.3.2 Parameters and Resources\n",
            "For all the experiments below, in the CNN models to learn the distributed\n",
            "representations for the inputs, we use window sizes in the setL = f2;3;4;5gfor\n",
            "the convolution operation with the dimensionalityv = 200 for each window size9.\n",
            "The non-linear function for transformation isg= tanh .\n",
            "We employ the English Wikipedia dump from June 2016 as our reference knowl-\n",
            "edge base.\n",
            "8. As noted by (F rancis-Landau et al., 2016) and (Nguyen et al., 2014c), the original\n",
            "Wikipedia dump in (Ratinov et al., 2011) is no longer accessible, so we cannot duplicate the\n",
            "results or conduct comparable experiments with (Ratinov et al., 2011). W e instead compare\n",
            "our performance with (F rancis-Landau et al., 2016) that provides the access to their Wikipedia\n",
            "dump.\n",
            "9. As we need to compute the cosine similarities between the hidden vectors of the RNN\n",
            "models and the representation vectors of the target candidates, the number of hidden units for\n",
            "the RNN is set to 200jLj= 800 naturally .\n",
            "186\n",
            "  ID: df0cb3b6-7d7a-42ed-9c97-b66eec82b565\n",
            "--------------------\n",
            "Node 235:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Regarding the input contexts for the entity mentions and the target candidates,\n",
            "we utilize the window size of 10 for the immediate contextctxi, and only extract\n",
            "the first 100 words in the documents fordoci and bdyij.\n",
            "Finally, we pre-train the word embedings on the whole English Wikipedia dump\n",
            "using theword2vec toolkit (Mikolov et al.,2013b). The training parameters are\n",
            "set to the default values in this toolkit. The dimensionality of the word embeddings\n",
            "is 300.\n",
            "Note that every parameter and resource in this work is either taken from the\n",
            "previous work (Francis-Landau et al., 2016; Nguyen and Grishman, 2016c) or\n",
            "selected by the development data.\n",
            "6.4.3.3 Evaluating the Global F eatures\n",
            "In this section, we evaluate the effectiveness of the global features for EL. In\n",
            "particular, we differentiate two types of global features based on the side of in-\n",
            "formation we expect to enforce the coherence. The first type of global features\n",
            "(global-mention) concerns the entity mention side and involves applying the\n",
            "global RNN models on the CNN-induced representation vectors of the entity men-\n",
            "tions (i.e, the surface vectors( \u0016suf1; \u0016suf2;:::; \u0016sufk) and the immediate context\n",
            "vectors ( \u0016ctx1; \u0016ctx2;:::; \u0016ctxk)). The second type of global features (global-entity),\n",
            "on the other hand, focuses on the target entity side and models the coherence\n",
            "with the representation vectors of the target entities (i.e, the page title vectors\n",
            "( \u0016til\n",
            "\u0003\n",
            "1; \u0016til\n",
            "\u0003\n",
            "2;:::; \u0016til\n",
            "\u0003\n",
            "k) and the body content vectors( \u0016bdy\n",
            "\u0003\n",
            "1; \u0016bdy\n",
            "\u0003\n",
            "2;:::; \u0016bdy\n",
            "\u0003\n",
            "k)). Table 6.5\n",
            "reports the development performance (F1 scores) of the proposed model on dif-\n",
            "187\n",
            "  ID: 91cd92df-67d9-4a01-855f-a06432125523\n",
            "--------------------\n",
            "Node 236:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "ferent cases where the global-mention and global-entity features are included or\n",
            "excluded from the model.\n",
            "Global Features Dataset\n",
            "ACE CoNLL WP\n",
            "No 86.1 89.3 84.0\n",
            "global-mention 86.8 90.2 84.2\n",
            "global-entity 86.9 90.7 84.2\n",
            "global-mention + global-entity 86.2 90.6 84.0\n",
            "Table 6.5: Performance of the global features on the development set.No means\n",
            "not using the global features.\n",
            "The most important observation from the table is that the global features, in\n",
            "general, help to improve the performance of the model on different datasets. This\n",
            "is substantial on the ACE and CoNLL datasets when only one type of the global\n",
            "features (eitherglobal-mention or global-entity) is integrated into the model. The\n",
            "combination ofglobal-mention and global-entity is not very effective as it is actually\n",
            "worse than the performance of the individual global feature types. This suggests\n",
            "thatglobal-mention andglobal-entity mightcoveroverlappinginformationandtheir\n",
            "combination would inject redundancy into the model. The best performance is\n",
            "achieved by theglobal-entity features that would be used in all the evaluations\n",
            "below.\n",
            "6.4.4 Comparing to the Previous W ork\n",
            "This section compares the proposed system (calledGlobal-RNN) with the state-\n",
            "of-the-art models on our four datasets. These systems include the neural net-\n",
            "work model in (Francis-Landau et al.,2016), the joint model for entity analysis\n",
            "188\n",
            "  ID: 625acfe5-2bcb-4082-8f7d-dfd3e467a4c7\n",
            "--------------------\n",
            "Node 237:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "in (Durrett and Klein,2014) and the AIDA-light system with two-stage mapping\n",
            "in (Nguyen et al.,2014c)10. Table 6.6 shows the performance of the systems on\n",
            "the test sets with the reference knowledge base of the June 2016 Wikipedia dump.\n",
            "We also include the performance of the systems on the December 2014 Wikipedia\n",
            "dump that was used and provided by (Francis-Landau et al.,2016) for further and\n",
            "compatible comparison.\n",
            "Systems Wikipedia 2014 Wikipedia 2016\n",
            "ACECoNLLWP WIKIACE CoNLLWP WIKI\n",
            "DK2014(Durrett and Klein,2014) 79.6 - - - - - - -\n",
            "AIDA-LIGHT(Nguyen et al.,2014b) - 84.8 - - - - - -\n",
            "Local CNN(Francis-Landau et al.,2016) 89.9 85.5 90.7 82.2 86.1 84.5 90.4 81.4\n",
            "Global-RNN 89.7 87.2† 91.2†83.7†87.8† 86.5† 91.2† 81.7\n",
            "Table 6.6: Performance of the systems. Cells marked with †designate theGlobal-\n",
            "RNN models that significantly outperform theLocal CNN model (\u001a< 0:05).\n",
            "First, we see that the performance of the systems drop significantly when we\n",
            "switch from Wikipedia 2014 to Wikipedia 2016 (especially for the datasets ACE\n",
            "and CoNLL). This is can be partly explained by the inclusion of new entities\n",
            "(pages) into Wikipedia from 2014 to 2016 that has made the entity mentions in\n",
            "the datasets more ambiguous11. Second and more importantly,Global-RNN signif-\n",
            "icantly outperforms the all the compared models (except for the ACE dataset on\n",
            "Wikipedia 2014 and the WIKI dataset on Wikipedia 2016), thereby demonstrating\n",
            "the benefits of the joint modeling for local and global features via neural networks\n",
            "for EL in this work.\n",
            "10.\n",
            "  ID: dc5b73f1-4761-4298-9a1b-30d4d1fac33b\n",
            "--------------------\n",
            "Node 238:\n",
            "  Text: the joint modeling for local and global features via neural networks\n",
            "for EL in this work.\n",
            "10. W e note that (Alhelbawy and Gaizauskas, 2014) and (Pershina et al., 2015) also use\n",
            "the CoNLL-Y AGO dataset for their experiments. However, since they evaluate the models on\n",
            "the whole dataset rather than the test set as the other works do, they are not comparable to the\n",
            "performance we report in this work.\n",
            "11. The number of Wikipedia pages in 2014 is about 4.5 million while this number is 5\n",
            "million in June 2016.\n",
            "189\n",
            "  ID: 2a34c244-a620-48c0-9430-25a2d2b73f08\n",
            "--------------------\n",
            "Node 239:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "6.4.5 Domain Adaptation Experiments\n",
            "The purpose of this section is to further evaluate the models in the domain\n",
            "adaptation setting to investigate their cross-domain robustness for EL. We refer\n",
            "the reader to Chapters 1 and 2 to learn more about the domain adaptation setting.\n",
            "One of the key strategies of the domain adaptation techniques is the search for\n",
            "the domain-independent features that are discriminative across different domains\n",
            "(Blitzer et al.,2006; Jiang and Zhai,2007b; Nguyen and Grishman,2014a; Plank\n",
            "and Moschitti,2013). These invariants serve as the connectors between different\n",
            "domains and help to transfer the knowledge from one domain to the others. For\n",
            "EL, we hypothesize that the global coherence is an effective domain-independent\n",
            "feature that would help to improve the cross-domain performance of the models.\n",
            "The intuition is that the entities mentioned in a document of any domains should\n",
            "be related to each other. Eventually, we expect that the proposed model with\n",
            "global coherence features would be more robust to domain shifts than the local\n",
            "approach (Francis-Landau et al.,2016).\n",
            "Dataset\n",
            "We use the ACE dataset to evaluate the cross-domain performance of the mod-\n",
            "els as it involves documents in 6 different domains: broadcast conversation (bc),\n",
            "broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and\n",
            "webblogs (wl) that facilitate our experiments. Following the common practice of\n",
            "domain adaptation research on this dataset, we usenews (the union ofbn and nw)\n",
            "as the source domain andbc, cts, wl, un as four different target domains. We\n",
            "take half ofbc as the development set and use the remaining data for testing.\n",
            "190\n",
            "  ID: 1b7762c9-caac-4b02-8c6b-e718eca9679b\n",
            "--------------------\n",
            "Node 240:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Evaluation\n",
            "Table6.7 compares Global-RNN with the neural network EL model in (Francis-\n",
            "Landau et al.,2016), the best reported model on the ACE dataset in the litera-\n",
            "ture12. In this table, the models are trained on the source domain news, and\n",
            "evaluated onnews itself (in-domain performance) (via 5-fold cross validation) as\n",
            "well as on the 4 target domainsbc, cts, wl, un (out-of-domain performance). The\n",
            "experiments in this section are done with the 2016 Wikipedia dump.\n",
            "Models Domain\n",
            "in-domain bc cts wl un\n",
            "Local CNNFrancis-Landau et al.,2016 90.6 87.8 88.7 80.2 82.1\n",
            "Global-RNN 91.0 88.7† 88.9 81.3† 83.1†\n",
            "Table 6.7: Cross-domain performance. Cells marked with †designate the Glob-\n",
            "RNN models that significantly outperform theLocal CNN model (\u001a< 0:05).\n",
            "The first observation from the table is that the performance of all the compared\n",
            "systems on the target domains is much worse than the corresponding in-domain\n",
            "performance. In particular, the performance gap between the in-domain perfor-\n",
            "mance and the the worst out-of-domain performance (on the domainwl) is up to\n",
            "10%, thus indicating the mismatches between the source and the target domains\n",
            "for EL. Second and most importantly,Global-RNN is consistently better than the\n",
            "model with only local features in (Francis-Landau et al.,2016) over all the target\n",
            "domains (although it is less pronounced in thects domain). This demonstrates\n",
            "the cross-domain robustness of the proposed model and confirms our hypothesis\n",
            "about the domain-independence of the global coherence features for EL.\n",
            "12. The performance of the model from (F rancis-Landau et al., 2016) reported in this work\n",
            "is obtained by running their actual released system.\n",
            "191\n",
            "  ID: 38ccfd4d-ce5c-4eb7-a2e5-27ccbfb28bb2\n",
            "--------------------\n",
            "Node 241:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Analysis\n",
            "In order to better understand the performance gap in the domain adaptation\n",
            "experiments for EL, we visualize the representation vectors of the entity mentions\n",
            "in different domains. In particular, afterGlobal-RNN is trained, we retrieve the\n",
            "representation vectors\u0016ci for the immediate contexts of the entity mentions in the\n",
            "source and target domains, project them into the 2-dimension space via the t-SNE\n",
            "algorithm and plot them. Figure6.9 shows the plot.\n",
            "NEWS\n",
            "BC\n",
            "CTS\n",
            "WL\n",
            "UN\n",
            "Figure 6.9: t-SNE visualization on the representation vectorsctxi of different do-\n",
            "mains.\n",
            "As we can see from the figure, the entity mentions in the target domainsbc,\n",
            "cts, wl and un are quite separated from those of the source domainnews, thereby\n",
            "192\n",
            "  ID: e2e3f6a2-3974-41ec-9d15-977f4553bf6e\n",
            "--------------------\n",
            "Node 242:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "explaining the performance loss in the domain adaption experiments.\n",
            "It is not clear in Figure6.9 why the models perform much worse on the target\n",
            "domainswl andun thantheotherdomains(i.e, bc andcts). Wefurtherinvestigate\n",
            "this problem by computing the similarities between the target domains and the\n",
            "source domain. While there are several methods to estimate domain similarities\n",
            "(PlankandNoord, 2011), inthiswork, weemploythemeanofthecosinesimilarities\n",
            "of every mention pairs in the two domains of interest. Specifically, letDOM1 and\n",
            "DOM2 be the two domains of interest, andDOM1 = fdom1\n",
            "1;dom2\n",
            "1;:::; doml1\n",
            "1 gand\n",
            "DOM2 = fdom1\n",
            "2;dom2\n",
            "2;:::; doml2\n",
            "2 gbe the sets of the representation vectors for the\n",
            "entity mentions inDOM1 and DOM2 respectively (l1 = jDOM1j;l2 = jDOM2j).\n",
            "The similarity betweenDOM1 and DOM2 is then given by:\n",
            "Sim(DOM1;DOM2) = 100 \u0002\n",
            "∑l1\n",
            "i=1\n",
            "∑l2\n",
            "j=1 cos(domi\n",
            "1;domj\n",
            "2)\n",
            "l1l2\n",
            "(6.6)\n",
            "Table 6.8 shows the similarities between the source domain news and each\n",
            "target domains bc, cts, wl and un with respect to the representation vectors of\n",
            "the immediate context \u0016ctxi (context) and the target entity title\u0016til\n",
            "\u0003\n",
            "i (title) for the\n",
            "entity mentionsenti. We also include the similarities in which the representation\n",
            "vectors are the local feature vectorsFCNN(enti;page\u0003\n",
            "i) in Equation6.5(interaction).\n",
            "The goal of the local feature similarities is to characterize how the entity mentions\n",
            "in different domains interact with their target entities.\n",
            "It is clear from the table thatwl is the most dissimilar domain from the source\n",
            "domain. This is followed byun and partly explains the performance in Table6.7.\n",
            "193\n",
            "  ID: 408f694f-cb09-4f29-ba5e-8e43716ce94d\n",
            "--------------------\n",
            "Node 243:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Domain context title interaction\n",
            "bc 10.7 2.0 34.4\n",
            "cts 11.4 2.0 32.6\n",
            "wl 9.2 0.8 30.3\n",
            "un 9.5 1.4 31.1\n",
            "Table 6.8:Similarities to the source domainnews.\n",
            "6.5 Related W ork\n",
            "As the memory-augmented neural networks for information extraction are new,\n",
            "we only focus on the related work for event extraction and entity linking in this\n",
            "part. The related work for event extraction can be found in Chapter 5. We only\n",
            "review the related work for entity linking in this section.\n",
            "Entity linking or disambiguation has been studied extensively in NLP research,\n",
            "falling broadly into two major approaches: local and global disambiguation. Both\n",
            "approaches share the goal of measuring the similarities between the entity mentions\n",
            "and the target candidates in the reference KB. The local paradigm focuses on the\n",
            "internal structures of each separate mention-entity pair, covering the name string\n",
            "comparisons between the surfaces of the entity mentions and target candidates,\n",
            "entity popularity or entity type and so on (Bunescu and Pasca,2006; Cassidy et\n",
            "al., 2011; Ji and Grishman,2011; Mendes et al.,2011; Milne and Witten,2008;\n",
            "Shen et al.,2014b; Zheng et al.,2010). In contrast, the global approach jointly\n",
            "maps all the entity mentions within documents to model the topical coherence.\n",
            "Various techniques have been exploited for capturing such semantic consistency,\n",
            "including Wikipedia category agreement (Cucerzan,2007), Wikipedia link-based\n",
            "measures (Hoffart et al.,2011; Kulkarni et al.,2009; Shen et al.,2012), Point-wise\n",
            "194\n",
            "  ID: 318689f0-bde8-4353-9680-aeb3c5e0ace3\n",
            "--------------------\n",
            "Node 244:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "Mutual Information measures (Ratinov et al.,2011), integer linear programming\n",
            "(Cheng and Roth,2013), PageRank (Alhelbawy and Gaizauskas,2014; Pershina\n",
            "et al.,2015), stacked generalization (He et al.,2013a), to name a few. The entity\n",
            "linking techniques and systems have been actively evaluated at the NIST-organized\n",
            "Text Analysis Conference (Ji et al.,2014).\n",
            "Neural networks are applied to entity linking very recently. He et al.,2013b\n",
            "learn enttiy representation via Stacked Denoising Auto-encoders. Sun et al.,2015\n",
            "employ convolutional neural networks and neural tensor networks to model men-\n",
            "tions, entities and contexts while Francis-Landau et al.,2016 combine CNN-based\n",
            "representations with sparse features to improve the performance. However, none\n",
            "of these work utilize recurrent neural networks to capture the coherence features\n",
            "as we do in this work.\n",
            "6.6 Conclusion\n",
            "We propose a novel neural network framework based on memory to address the\n",
            "joint inference problem for information extraction. In such framework, the predic-\n",
            "tion tasks for IE are solved simultaneously; and memories are maintained during\n",
            "the process to capture the interdependencies among the outputs of the tasks. We\n",
            "demonstrate the advantages of the proposed framework on two important tasks of\n",
            "IE, i.e, event extraction and entity linking. In particular, the memory-augmented\n",
            "neural networks can well exploit the interdependencies between event types and\n",
            "argument roles for EE and the topical coherence among the entities of documents\n",
            "for EL. The extensive experiments show that we achieve the state-of-the-art per-\n",
            "195\n",
            "  ID: 4f98763b-1426-468c-afe3-c62ad3beda17\n",
            "--------------------\n",
            "Node 245:\n",
            "  Text: CHAPTER 6. MEMORY-AUGMENTED NETWORKS FOR JOINT\n",
            "INFERENCE IN INFORMATION EXTRACTION\n",
            "formance for both tasks on the benchmark datasets.\n",
            "196\n",
            "  ID: 92827343-446a-4a89-9b5c-a03dbc7bbf4c\n",
            "--------------------\n",
            "Node 246:\n",
            "  Text: Chapter 7\n",
            "Conclusion and F uture W ork\n",
            "This dissertation departs from the traditional feature-based methods and de-\n",
            "velops new deep learning models for information extraction tasks. The major\n",
            "motivation for such deep learning models are the ability to generalize over vocabu-\n",
            "lary (i.e, mitigate the unseen word/feature problems) and the automatic learning\n",
            "of effective feature representations. The dissertation involves three main parts.\n",
            "The first part corresponds to Chapter 2 and introduces the use of word embed-\n",
            "dings to generate robust features that can work well on different domains (domain\n",
            "adaptation) for relation extraction. The second part involves Chapters 3, 4 and\n",
            "5 that explore various deep learning models for entity mention detection, relation\n",
            "extraction and event detection respectively. We show that such deep learning\n",
            "models help to minimize the effort of feature engineering while achieving the best\n",
            "reported performance for such tasks. Finally, the third part is associated with\n",
            "Chapter 6 that proposes memory-augmented neural networks to simultaneously\n",
            "solve multiple prediction tasks for information extraction (joint inference). The\n",
            "197\n",
            "  ID: f60f5d3a-192c-4892-812c-c2f5199fdc6b\n",
            "--------------------\n",
            "Node 247:\n",
            "  Text: CHAPTER 7. CONCLUSION AND FUTURE WORK\n",
            "memory-augmented neural networks maintain memories to capture the long range\n",
            "dependencies in information extraction tasks. We apply this general framework in\n",
            "two tasks of event extraction and entity linking, yielding the systems with sate-of-\n",
            "the-art performance for such tasks.\n",
            "We envision much future research on deep learning for information extraction\n",
            "following this dissertation. In this section, we describe two promising directions to\n",
            "explore in the future.\n",
            "The first direction concerns the unsupervised deep learning models for informa-\n",
            "tion extraction. One of the major drawback of the current work is the requirement\n",
            "of large training datasets (labeled data) to obtain good performance (supervised\n",
            "learning). Such large training datasets are often very expensive to obtain in prac-\n",
            "tice as they require proper creation of annotation guideline, effective training for\n",
            "annotators, good domain knowledge, strict quality control etc. This hinders the\n",
            "portability of the systems to new domains where training data is not available or\n",
            "limited. In contrast to labeled data, unlabeled data and/or weakly labeled data are\n",
            "often abundant in application domains. How can we make use of unlabeled data\n",
            "and weakly labeled data to automatically build schemas and extract high-quality\n",
            "information from text with deep learning? The first step could be investigating\n",
            "unsupervised learning models in deep learning that have been applied successfully\n",
            "in other problems such as autoencoder models (Vincent et al.,2010), generative\n",
            "adversarial networks (GAN) (Goodfellow et al.,2014) etc. The insights from such\n",
            "research could suggest us to develop better unsupervised deep learning models for\n",
            "information extraction.\n",
            "198\n",
            "  ID: 88ec989c-5061-4f50-bfd7-a1cde77a2753\n",
            "--------------------\n",
            "Node 248:\n",
            "  Text: CHAPTER 7. CONCLUSION AND FUTURE WORK\n",
            "The second direction considers the multitask deep learning frameworks for in-\n",
            "formation extraction. The main idea is to explore deep learning models that can\n",
            "simultaneously solve several information extraction tasks to improve the perfor-\n",
            "mance of the individual tasks (joint learning). Deep learning facilitates such mul-\n",
            "titask learning objectives as it allows the shared representations among different\n",
            "tasks. This encourages the communication among multiple tasks so they can fix\n",
            "the errors from each other and produce better representations for the tasks. We\n",
            "have seen some positive evidences for this direction in Chapter 6.\n",
            "199\n",
            "  ID: 9ae7410c-f4c3-4645-9840-2113cd3a1d4c\n",
            "--------------------\n",
            "Node 249:\n",
            "  Text: Bibliography\n",
            "Agichtein, Eugene and Gravano, Luis (2000). “Snowball: Extracting Relations from\n",
            "Large Plain-Text Collections”. In:Proceedings of the Fifth ACM Conference on\n",
            "Digital Libraries.\n",
            "Ahn, David (2006). “The Stages of Event Extraction”. In:Proceedings of the W ork-\n",
            "shop on Annotating and Reasoning about Time and Events .\n",
            "Alhelbawy, Ayman and Gaizauskas, Robert (2014). “Graph Ranking for Collective\n",
            "Named Entity Disambiguation”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) .\n",
            "Ando, Rie and Zhang, Tong (2005). “A High-Performance Semi-Supervised Learn-\n",
            "ing Method for Text Chunking”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) .\n",
            "Bahdanau, Dzmitry, Cho, Kyunghyun, and Bengio, Yoshua (2015). “Neural Ma-\n",
            "chine Translation by Jointly Learning to Align and Translate”. In:Proceedings\n",
            "of the International Conference on Learning Representations (ICLR) .\n",
            "Baroni, Macro, Bernardini, Silvia, Ferraresi, Adriano, and Zanchetta, Eros (2009).\n",
            "“The WaCky Wide Web: a Collection of Very Large Linguistically Processed\n",
            "Web-crawled Corpora”. In:Proceedings of Language Resources and Evaluation.\n",
            "200\n",
            "  ID: 17f1d39a-b727-473a-80e8-108a8bed9ced\n",
            "--------------------\n",
            "Node 250:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Baroni, Marco and Zamparelli, Roberto (2010). “Nouns are Vectors, Adjectives\n",
            "are Matrices: Representing Adjective-Noun Constructions in Semantic Space”.\n",
            "In: Proceedings of the Conference on Empirical Methods in Natural Language\n",
            "Processing (EMNLP).\n",
            "Baroni, Marco, Dinu, Georgiana, and Kruszewski, Germán (2014). “Don’t count,\n",
            "predict! A systematic comparison of context-counting vs. context-predicting\n",
            "semantic vectors”. In:Proceedings of the Annual Meeting of the Association for\n",
            "Computational Linguistics (ACL) .\n",
            "Becker, M., Hachey, B., Alex, B., and Grove, L. (2005). “Optimising Selective\n",
            "Sampling for Bootstrapping Named Entity Recognition”. In:Proceedings of the\n",
            "ICML-2005 W orkshop on Learning with Multiple Views.\n",
            "Bengio, Yoshua, Ducharme, Réjean, Vincent, Pascal, and Jauvin, Christian (2003).\n",
            "“A Neural Probabilistic Language Model”. In:Journal of Machine Learning\n",
            "Research 3.\n",
            "Bengio, Yoshua, Simard, Patrice, and Frasconi, Paolo (1994). “Learning Long-term\n",
            "Dependencies with Gradient Descent is Difficult”. In:Journal of Machine Learn-\n",
            "ing Research 3.\n",
            "Bentivogli, Luisa, Forner, Pamela, Giuliano, Claudio, Marchetti, Alessandro, Pi-\n",
            "anta, Emanuele, and Tymoshenko, Kateryna (2010). “Extending English ACE\n",
            "2005 Corpus Annotation with Ground-truth Links to Wikipedia”. In:Proceed-\n",
            "ings of the 2nd W orkshop on The People’s W eb Meets NLP: Col laboratively\n",
            "Constructed Semantic Resources.\n",
            "Bikel, D. M., Miller, S., Schwartz, R., and Weischedel, R. (1997). “Nymble: a High-\n",
            "Performance Learning Name-finder”. In:ANLP.\n",
            "201\n",
            "  ID: 9c4efb29-ad82-4ef8-bc60-58473dd2ddda\n",
            "--------------------\n",
            "Node 251:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Blacoe, W. and Lapata, M. (2012). “A Comparison of Vector-based Representa-\n",
            "tions for Semantic Composition”. In:Proceedings of the Conference on Empir-\n",
            "ical Methods in Natural Language Processing (EMNLP).\n",
            "Blitzer, John, McDonald, Ryan, and Pereira, Fernando (2006). “Domain Adapta-\n",
            "tion with Structural Correspondence Learning”. In:Proceedings of the Confer-\n",
            "ence on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Blitzer, John, Dredze, Mark, and Pereira, Fernando (2007). “Biographies, Bolly-\n",
            "wood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classifica-\n",
            "tion”. In:Proceedings of the Annual Meeting of the Association for Computa-\n",
            "tional Linguistics (ACL) .\n",
            "Blitzer, John, Foster, Dean, and Kakade, Sham (2011). “Domain Adaptation with\n",
            "Coupled Subspaces”. In:Proceedings of the Conference on Artificial Intel ligence\n",
            "and Statistics.\n",
            "Bloehdorn, Stephan and Moschitti, Alessandro (2007). “Exploiting Structure and\n",
            "Semantics for Expressive Text Kernels”. In:Proceedings of the International\n",
            "Conference on Information and Knowledge Management (CIKM) .\n",
            "Borthwick,Andrew,Sterling,John,Agichtein,Eugene,andGrishman,Ralph(1997).\n",
            "“Exploiting Diverse Knowledge Sources via Maximum Entropy in Named Entity\n",
            "Recognition”. In:Sixth W orkshop on V ery Large Corpora.\n",
            "Boschee, Elizabeth, Weischedel, Ralph, and Zamanian, Alex (2005). “Automatic\n",
            "Information Extraction”. In:Proceedings of the International Conference on\n",
            "Intel ligence Analysis.\n",
            "Brin, Sergey (1998). “Extracting Patterns and Relations from the World Wide\n",
            "Web”. In:Proceedings of the International W orkshop on the W orld Wide W eb\n",
            "and Databases.\n",
            "202\n",
            "  ID: b744773f-f374-4d7a-94ce-e1021cade9c1\n",
            "--------------------\n",
            "Node 252:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Brown, P. F., deSouza, P. V., Mercer, R. L., Pietra, V. J. D., and Lai, J. C.\n",
            "(1992). “Class-Based n-gram Models of Natural Language”. In:Computational\n",
            "Linguistics.\n",
            "Bunescu, Razvan and Mooney, Raymond (2005a). “A Shortest Path Dependency\n",
            "Kernel for Relation Extraction”. In:Proceedings of the Conference on Empirical\n",
            "Methods in Natural Language Processing (EMNLP).\n",
            "Bunescu, Razvan and Mooney, Raymond (2005b). “Subsequence Kernels for Re-\n",
            "lation Extraction”. In:Proceedings of the Conference on Neural Information\n",
            "Processing Systems (NIPS).\n",
            "Bunescu, Razvan and Pasca, Marius (2006). “Using Encyclopedic Knowledge for\n",
            "Named Entity Disambiguation”. In:Proceedings of the European Chapter of the\n",
            "Association for Computational Linguistics (EACL) .\n",
            "Cao, Kai, Li, Xiang, and Grishman, Ralph (2015a). “Improving Event Detection\n",
            "with Dependency Regularization”. In:Proceedings of the Recent Advances in\n",
            "Natural Language Processing (RANLP).\n",
            "Cao, Kai, Li, Xiang, Fan, Miao, and Grishman, Ralph (2015b). “Improving Event\n",
            "Detection with Active Learning”. In:Proceedings of the Recent Advances in\n",
            "Natural Language Processing (RANLP).\n",
            "Carreras, Xavier, Màrques, Lluís, and Padró, Lluís (2002). “Named Entity Ex-\n",
            "traction using AdaBoost”. In:Proceedings of the Conference on Computational\n",
            "Natural Language Learning (CoNLL).\n",
            "Cassidy, Taylor, Chen, Zheng, Artiles, Javier, Ji, Heng, Deng, Hongbo, Ratinov,\n",
            "Lev-Arie, Zheng, Jing, Han, Jiawei, and Roth, Dan (2011). “CUNY-UIUC-SRI\n",
            "TAC-KBP2011 Entity Linking System Description”. In:Proceedings of T ext\n",
            "Analysis Conference (T AC).\n",
            "203\n",
            "  ID: e75831ed-ad73-4bf7-90d3-d9eae43234a0\n",
            "--------------------\n",
            "Node 253:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Chan, Yee Seng and Roth, Dan (2010). “Exploiting Background Knowledge for\n",
            "Relation Extraction”. In:Proceedings of the International Conference on Com-\n",
            "putational Linguistics (COLING) .\n",
            "Chen, Yubo, Xu, Liheng, Liu, Kang, Zeng, Daojian, and Zhao, Jun (2015). “Event\n",
            "Extraction via Dynamic Multi-Pooling Convolutional Neural Networks”. In:\n",
            "Proceedings of the Annual Meeting of the Association for Computational Lin-\n",
            "guistics (ACL).\n",
            "Cheng, Xiao and Roth, Dan (2013). “Relational Inference for Wikification”. In:\n",
            "Proceedings of the Conference on Empirical Methods in Natural Language Pro-\n",
            "cessing (EMNLP).\n",
            "Cherry, Colin and Guo, Hongyu (2015). “The Unreasonable Effectiveness of Word\n",
            "Representations for Twitter Named Entity Recognition”. In:Proceedings of the\n",
            "North American Chapter of the Association for Computational Linguistics Con-\n",
            "ference (HL T-NAACL).\n",
            "Cho, Kyunghyun, Merrienboer, Bart van, Gulcehre, Caglar, Bahdanau, Dzmitry,\n",
            "Bougares,Fethi,Schwenk,Holger,andBengio,Yoshua(2014a).“LearningPhrase\n",
            "Representations using RNN Encoder–Decoder for Statistical Machine Trans-\n",
            "lation”. In: Proceedings of the Conference on Empirical Methods in Natural\n",
            "Language Processing (EMNLP).\n",
            "Cho, Kyunghyun (2014b). “Quick Introduction to Natural Language Processing\n",
            "with Neural Networks”. In:Lecture at the Ecole Polytechnique de Montreal .\n",
            "Chung, Junyoung, Gulcehre, Caglar, Cho, KyungHyun, and Bengio, Yoshua (2014).\n",
            "“Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Mod-\n",
            "eling”. In:arXiv preprint arXiv:1412.3555 .\n",
            "204\n",
            "  ID: 1ac9136f-874a-45da-a557-add5990dc296\n",
            "--------------------\n",
            "Node 254:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Clark, Kevin and Manning, Christopher D. (2016). “Improving Coreference Reso-\n",
            "lution by Learning Entity-Level Distributed Representations”. In:Proceedings\n",
            "of the Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Collins, Michael and Singer, Yoram (1999). “Unsupervised Models for Named En-\n",
            "tity Classification”. In:Proceedings of the Joint SIGDA T Conference on Em-\n",
            "pirical Methods in Natural Language Processing and V ery Large Corpora.\n",
            "Collobert, Ronan and Westion, Jason (2008). “A Unified Architecture for Natu-\n",
            "ral Language Processing: Deep Neural Networks with Multitask Learning”. In:\n",
            "Proceedings of the International Conference on Machine Learning (ICML) .\n",
            "Collobert, Ronan, Weston, Jason, Bottou, Leon, Karlen, Michael, Kavukcuoglu,\n",
            "Koray, and Kuksa, Pavel (2011). “Natural Language Processing (almost) from\n",
            "Scratch”. In:Journal of Machine Learning Research.\n",
            "Craven, Mark and Kumlien, Johan (1999). “Constructing Biological Knowledge\n",
            "Bases by Extracting Information from Text Sources”. In:Proceedings of the\n",
            "Seventh International Conference on Intel ligent Systems for Molecular Biology.\n",
            "Cristianini, Nello and Taylor, John Shawe (2000). “An Introduction to Support\n",
            "Vector Machines and Other Kernel-based Learning Methods”. In:Cambridge\n",
            "University Press.\n",
            "Cucerzan, Silviu (2007). “Large-Scale Named Entity Disambiguation Based on\n",
            "Wikipedia Data”. In:Proceedings of the Conference on Empirical Methods in\n",
            "Natural Language Processing (EMNLP).\n",
            "Daume, Hal (2007). “Frustratingly Easy Domain Adaptation”. In:Proceedings of\n",
            "the Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "205\n",
            "  ID: e5625fae-b996-4083-8d4f-5fdf8d2d7902\n",
            "--------------------\n",
            "Node 255:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Daume, Hal, Kumar, A., and Saha, A. (2010). “Co-regularization Based Semi-\n",
            "supervised Domain Adaptation”. In:Proceedings of the Conference on Neural\n",
            "Information Processing Systems (NIPS).\n",
            "Duchi, John, Hazan, Elad, and Singer, Yoram (2011). “Adaptive Subgradient Meth-\n",
            "ods for Online Learning and Stochastic Optimization”. In:Journal of Machine\n",
            "Learning Research 12 2121-2159.\n",
            "Durrett, Greg and Klein, Dan (2013). “Easy Victories and Uphill Battles in Coref-\n",
            "erence Resolution”. In:Proceedings of the Conference on Empirical Methods in\n",
            "Natural Language Processing (EMNLP).\n",
            "Durrett, Greg and Klein, Dan (2014). “A Joint Model for Entity Analysis: Coref-\n",
            "erence, Typing, and Linking”. In:T ransactions of the Association for Compu-\n",
            "tational Linguistics (T ACL).\n",
            "Fahrni,AngelaandStrube,Michael(2014).“ALatentVariableModelforDiscourse-\n",
            "aware Concept and Entity Disambiguation”. In:Proceedings of the European\n",
            "Chapter of the Association for Computational Linguistics (EACL) .\n",
            "Florian, Radu, Ittycheriah, Abe, Jing, Hongyan, and Zhang, Tong (2003). “Named\n",
            "Entity Recognition through Classifier Combination”. In:Proceedings of the Con-\n",
            "ference on Computational Natural Language Learning (CoNLL) .\n",
            "Florian, R., Hassan, H., Ittycheriah, A., Jing, H., Kambhatla, N., Luo, X., Nicolov,\n",
            "N., and Roukos, S. (2004). “A Statistical Model for Multilingual Entity De-\n",
            "tection and Tracking”. In:Proceedings of the North American Chapter of the\n",
            "Association for Computational Linguistics Conference (HL T-NAACL).\n",
            "Florian, Radu, Jing, Hongyan, Kambhatla, Nanda, and Zitouni, Imed (2006). “Fac-\n",
            "torizing Complex Models: A Case Study in Mention Detection”. In:Proceedings\n",
            "of the Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "206\n",
            "  ID: 31ed7470-1b93-4251-8590-baf98f6f5e6f\n",
            "--------------------\n",
            "Node 256:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Florian, Radu, Pitrelli, John, Roukos, Salum, and Zitouni, Imed (2010). “Improv-\n",
            "ing Mention Detection Robustness to Noisy Input”. In:Proceedings of the Con-\n",
            "ference on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Francis-Landau, Matthew, Durrett, Greg, and Klein, Dan (2016). “Capturing Se-\n",
            "mantic Similarity for Entity Linking with Convolutional Neural Networks”. In:\n",
            "Proceedings of the North American Chapter of the Association for Computa-\n",
            "tional Linguistics Conference (HL T-NAACL).\n",
            "Fu,LishengandGrishman,Ralph(2013).“AnEfficientActiveLearningFramework\n",
            "for New Relation Types”. In:Proceedings of the International Joint Conference\n",
            "on Natural Language Processing (IJCNLP).\n",
            "Gillick, Dan, Brunk, Cliff, Vinyals, Oriol, and Subramanya, Amarnag (2015). “Mul-\n",
            "tilingualLanguageProcessingFromBytes”.In: arXiv preprint arXiv:1512.00103.\n",
            "Giuliano, Claudio, Lavelli, Alberto, and Romano, Lorenza (2007). “Relation Ex-\n",
            "traction and the Influence of Automatic Named-entity Recognition”. In:ACM\n",
            "T ransactions on Speech and Language Processing (TSLP), V olume 5, Issue 1.\n",
            "Goodfellow, Ian J., Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley,\n",
            "David,Ozair,Sherjil,Courville,Aaron,andBengio,Yoshua(2014).“Generative\n",
            "Adversarial Networks”. In:arXiv preprint arXiv:1406.2661 .\n",
            "Goodfellow, Ian, Bengio, Yoshua, and Courville, Aaron (2016). “Deep Learning”.\n",
            "In: MIT Press.\n",
            "Gormley, Matthew R., Yu, Mo, and Dredze, Mark (2015). “Improved Relation\n",
            "Extraction with Feature-Rich Compositional Embedding Models”. In:Proceed-\n",
            "ings of the Conference on Empirical Methods in Natural Language\n",
            "  ID: 683e36eb-afdd-4413-aa28-1c0e5d7f5ba2\n",
            "--------------------\n",
            "Node 257:\n",
            "  Text: Embedding Models”. In:Proceed-\n",
            "ings of the Conference on Empirical Methods in Natural Language Processing\n",
            "(EMNLP).\n",
            "207\n",
            "  ID: 067789d3-a4f7-4639-820f-df6568733a08\n",
            "--------------------\n",
            "Node 258:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Grishman, Ralph, Westbrook, David, and Meyers, Adam (2005). “NYU’s English\n",
            "ACE 2005 System Description”. In:The ACE 2005 Evaluation W orkshop.\n",
            "Grishman, R. (2012). “Information Extraction: Capabilities and Challenges”. In:\n",
            "International Winter School in Language and Speech T echnologies, Rovira i\n",
            "Virgili University, Spain.\n",
            "Gupta, Prashant and Ji, Heng (2009). “Predicting Unknown Time Arguments\n",
            "Based on Cross-Event Propagation”. In:Proceedings of the Annual Meeting\n",
            "of the Association for Computational Linguistics (ACL) .\n",
            "Han, Xianpei, Sun, Le, and Zhao, Jun (2011). “Collective Entity Linking in Web\n",
            "Text: A Graph-based Method”. In:Proceedings of the Special Interest Group on\n",
            "Information Retrieval (SIGIR) .\n",
            "Hasegawa, T., Sekine, S., and Grishman, R. (2004). “Discovering Relations among\n",
            "Named Entities from Large Corpora”. In:Proceedings of the Annual Meeting of\n",
            "the Association for Computational Linguistics (ACL) .\n",
            "He, Zhengyan, Liu, Shujie, Song, Yang, Li, Mu, Zhou, Ming, and Wang, Houfeng\n",
            "(2013a). “Efficient Collective Entity Linking with Stacking”. In:Proceedings of\n",
            "the Conference on Empirical Methods in Natural Language Processing (EMNLP).\n",
            "He,Zhengyan,Liu,Shujie,Li,Mu,Zhou,Ming,Zhang,Longkai,andWang,Houfeng\n",
            "(2013b). “Learning Entity Representation for Entity Disambiguation”. In:Pro-\n",
            "ceedings of the Annual Meeting of the Association for Computational Linguistics\n",
            "(ACL).\n",
            "Heath, Tom and Bizer, Christian (2011). “Linked Data: Evolving the Web into a\n",
            "Global Data Space”. In:Morgan and Claypool, 1st edition .\n",
            "Hendrickx, Iris, Kim, Su Nam, Kozareva, Zornitsa, Nakov, Preslav, Séaghdha,\n",
            "Diarmuid Ó, Padó, Sebastian,\n",
            "  ID: cb056c9b-4937-4564-ace5-78cb163e805e\n",
            "--------------------\n",
            "Node 259:\n",
            "  Text: Preslav, Séaghdha,\n",
            "Diarmuid Ó, Padó, Sebastian, Pennacchiotti, Marco, Romano, Lorenza, and\n",
            "208\n",
            "  ID: 9e6391cf-74e5-4e19-955a-76bc91769070\n",
            "--------------------\n",
            "Node 260:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Szpakowicz, Stan (2010). “SemEval-2010 Task 8: Multi-Way Classification of\n",
            "Semantic Relations Between Pairs of Nominals”. In:Proceedings of the Inter-\n",
            "national W orkshop on Semantic Evaluation (SemEval).\n",
            "Hochreiter, Sepp and Schmidhuber, Jurgen (1997). “Long Short-Term Memory”.\n",
            "In: Neural Computation.\n",
            "Hoffart,Johannes,Yosef,MohamedAmir,Bordino,Ilaria,Fürstenau,Hagen,Pinkal,\n",
            "Manfred, Spaniol, Marc, Thater, Stefan, and Weikum, Gerhard (2011). “Robust\n",
            "Disambiguation of Named Entities in Text”. In:Proceedings of the Conference\n",
            "on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Hoffmann, Raphael, Zhang, Congle, Ling, Xiao, Zettlemoyer, Luke, and Weld,\n",
            "Daniel (2011). “Knowledge-based Weak Supervision for Information Extrac-\n",
            "tion of Overlapping Relations”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) .\n",
            "Hong, Yu, Zhang, Jianfeng, Ma, Bin, Yao, Jian-Min, Zhou, Guodong, and Zhu,\n",
            "Qiaoming (2011). “Using Cross-entity Inference to Improve Event Extraction”.\n",
            "In: Proceedings of the Annual Meeting of the Association for Computational\n",
            "Linguistics (ACL).\n",
            "Huang, Fei and Yates, Alexander (2010). “Exploring Representation-Learning Ap-\n",
            "proaches to Domain Adaptation”. In:The ACL W orkshop on Domain Adapta-\n",
            "tion for Natural Language Processing (DANLP) .\n",
            "Huang, Ruihong and Riloff, Ellen (2012). “Modeling Textual Cohesion for Event\n",
            "Extraction”. In:Proceedings of the Association for the Advancement of Artificial\n",
            "Intel ligence (AAAI).\n",
            "Jagannatha, Abhyuday N and Yu, Hong (2016). “Bidirectional RNN for Medical\n",
            "Event Detection in Electronic Health Records”. In:Proceedings of the North\n",
            "209\n",
            "  ID: 031c08c1-fa52-4477-a14c-d7e9ae633e05\n",
            "--------------------\n",
            "Node 261:\n",
            "  Text: BIBLIOGRAPHY\n",
            "American Chapter of the Association for Computational Linguistics Conference\n",
            "(HL T-NAACL).\n",
            "Ji, Heng and Grishman, Ralph (2005). “Improving Name Tagging by Reference\n",
            "Resolution and Relation Detection”. In:Proceedings of the Annual Meeting of\n",
            "the Association for Computational Linguistics (ACL) .\n",
            "Ji, Heng, Westbrook, David, and Grishman, Ralph (2005). “Using Semantic Re-\n",
            "lations to Refine Coreference Decisions”. In:Proceedings of the Conference on\n",
            "Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Ji, Heng and Grishman, Ralph (2008). “Refining Event Extraction through Cross-\n",
            "Document Inference”. In:Proceedings of the Annual Meeting of the Association\n",
            "for Computational Linguistics (ACL) .\n",
            "Ji, Heng and Grishman, Ralph (2011). “Knowledge Base Population: Successful\n",
            "Approaches and Challenges”. In:Proceedings of the Annual Meeting of the As-\n",
            "sociation for Computational Linguistics (ACL) .\n",
            "Ji, Heng, Nothman, Joel, and Hachey, Ben (2014). “Overview of TAC-KBP2014\n",
            "Entity Discovery and Linking Tasks”. In:Proceedings of T ext Analysis Confer-\n",
            "ence (T AC).\n",
            "Jiang, Jing and Zhai, ChengXiang (2007a). “A Systematic Exploration of the Fea-\n",
            "ture Space for Relation Extraction”. In:Proceedings of the North American\n",
            "Chapter of the Association for Computational Linguistics Conference (HL T-\n",
            "NAACL).\n",
            "Jiang, Jing and Zhai, ChengXiang (2007b). “Instance Weighting for Domain Adap-\n",
            "tation in NLP”. In:Proceedings of the Annual Meeting of the Association for\n",
            "Computational Linguistics (ACL) .\n",
            "210\n",
            "  ID: 280235b5-9ef4-4e06-9878-87e6ec26e562\n",
            "--------------------\n",
            "Node 262:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Jiang, Jing and Zhai, ChengXiang (2007c). “A Two-stage Approach to Domain\n",
            "Adaptation for Statistical Classifiers”. In: Proceedings of the Conference on\n",
            "Information and Knowledge Management (CIKM) .\n",
            "Józefowicz, Rafal, Zaremba, Wojciech, and Sutskever, Ilya (2015). “An Empirical\n",
            "Exploration of Recurrent Network Architectures”. In:Proceedings of the Inter-\n",
            "national Conference on Machine Learning (ICML) .\n",
            "Kalchbrenner, Nal, Grefenstette, Edward, and Blunsom, Phil (2014). “A Convolu-\n",
            "tional Neural Network for Modelling Sentences”. In:Proceedings of the Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Kambhatla, Nanda (2004). “Combining Lexical, Syntactic, and Semantic Features\n",
            "with Maximum Entropy Models for Information Extraction”. In:Proceedings of\n",
            "the Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Kate, J. Rohit and Mooney, Raymond (2010). “Joint Entity and Relation Ex-\n",
            "traction Using Card-Pyramid Parsing”. In:Proceedings of the Conference on\n",
            "Computational Natural Language Learning (CoNLL) .\n",
            "Kim, Yoon (2014). “Convolutional Neural Networks for Sentence Classification”.\n",
            "In: Proceedings of the Conference on Empirical Methods in Natural Language\n",
            "Processing (EMNLP).\n",
            "Kingma, Diederik and Ba, Jimmy (2014). “Adam: A Method for Stochastic Opti-\n",
            "mization”. In:arXiv preprint arXiv:1412.6980.\n",
            "Kuksa, Pavel, Qi, Yanjun, Bai, Bing, Collobert, Ronan, Weston, Jason, Pavlovic,\n",
            "Vladimir,andNing,Xia(2010).“Semi-supervisedAbstraction-augmentedString\n",
            "Kernel for Multi-level Bio-relation Extraction”. In:Proceedings of the European\n",
            "Conference on Machine Learning and Principles and Practice of Knowledge\n",
            "Discovery in Databases (ECML PKDD) .\n",
            "211\n",
            "  ID: c89c9f6d-85fd-41f9-b7bb-03b5f1f84b85\n",
            "--------------------\n",
            "Node 263:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Kulkarni, Sayali, Singh, Amit, Ramakrishnan, Ganesh, and Chakrabarti, Soumen\n",
            "(2009). “Collective Annotation of Wikipedia Entities in Web Text”. In:Pro-\n",
            "ceedings of the Association for Computing Machinery’s (ACM) Special Interest\n",
            "Group (SIG) on Knowledge Discovery and Data Mining (SIGKDD) .\n",
            "Lafferty, John, McCallum, Andrew, and Pereira, Fernando (2001). “Conditional\n",
            "Random Fields: Probabilistic Models for Segmenting and Labeling Sequence\n",
            "Data”. In:Proceedings of the International Conference on Machine Learning\n",
            "(ICML).\n",
            "LeCun,Yann,Bottou,Léon,Bengio,Yoshua,andHaffner,Patrick(1988).“Gradient-\n",
            "basedLearningAppliedtoDocumentRecognition”.In: Proceedings of the IEEE,\n",
            "86(11).\n",
            "Lei, Tao, Barzilay, Regina, and Jaakkola, Tommi (2015). “Molding CNNs for Text:\n",
            "Non-linear, Non-consecutive Convolutions”. In:Proceedings of the Conference\n",
            "on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Li, Peifeng, Zhu, Qiaoming, and Zhou, Guodong (2013a). “Argument Inference\n",
            "from Relevant Event Mentions in Chinese Argument Extraction”. In:Proceed-\n",
            "ings of the Annual Meeting of the Association for Computational Linguistics\n",
            "(ACL).\n",
            "Li, Qi, Ji, Heng, and Huang, Liang (2013b). “Joint Event Extraction via Structured\n",
            "Prediction with Global Features”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) .\n",
            "Li, Qi and Ji, Heng (2014a). “Incremental Joint Extraction of Entity Mentions\n",
            "and Relations”. In:Proceedings of the Annual Meeting of the Association for\n",
            "Computational Linguistics (ACL) .\n",
            "212\n",
            "  ID: be31ebcf-62a4-433b-bcdc-c1c017efd7ce\n",
            "--------------------\n",
            "Node 264:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Li, Qi, Ji, Heng, Hong, Yu, and Li, Sujian (2014b). “Constructing Information Net-\n",
            "works Using One Single Model”. In:Proceedings of the Conference on Empirical\n",
            "Methods in Natural Language Processing (EMNLP).\n",
            "Li, Xiang, Nguyen, Thien Huu, Cao, Kai, and Grishman, Ralph (2015). “Improving\n",
            "Event Detection with Abstract Meaning Representation”. In:Proceedings of\n",
            "ACL-IJCNLP W orkshop on Computing News Storylines (CNewS).\n",
            "Liao, Shasha and Grishman, Ralph (2010a). “Filtered Ranking for Bootstrapping\n",
            "in Event Extraction”. In:Proceedings of the 23rd International Conference on\n",
            "Computational Linguistics (COLING) .\n",
            "Liao, Shasha and Grishman, Ralph (2010b). “Using Document Level Cross-event\n",
            "Inference to Improve Event Extraction”. In:Proceedings of the Annual Meeting\n",
            "of the Association for Computational Linguistics (ACL) .\n",
            "Liao, Shasha and Grishman, Ralph (2011). “Acquiring Topic Features to Improve\n",
            "Event Extraction: in Preselected and Balanced Collections”. In:Proceedings of\n",
            "the Recent Advances in Natural Language Processing (RANLP).\n",
            "Lin, Dekang and Wu, Xiaoyun (2009). “Phrase Clustering for Discriminative Learn-\n",
            "ing”. In:Proceedings of the Annual Meeting of the Association for Computa-\n",
            "tional Linguistics (ACL) .\n",
            "Liu, ChunYang, Sun, WenBo, Chao, WenHan, and Che, WanXiang (2013). “Con-\n",
            "volution Neural Network for Relation Extraction”. In:Proceedings of 9th In-\n",
            "ternational Conference on Advanced Data Mining and Applications, Part II\n",
            "(ADMA 2013) .\n",
            "Liu, Yang, Wei, Furu, Li, Sujian, Ji, Heng, Zhou, Ming, and WANG, Houfeng\n",
            "(2015). “A Dependency-Based Neural Network for Relation Classification”. In:\n",
            "213\n",
            "  ID: f6fd08c8-53ca-4a8e-8c79-c61c984ae1ec\n",
            "--------------------\n",
            "Node 265:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Proceedings of the Annual Meeting of the Association for Computational Lin-\n",
            "guistics (ACL).\n",
            "Liu, Shulin, Liu, Kang, He, Shizhu, and Zhao, Jun (2016). “A Probabilistic Soft\n",
            "Logic Based Approach to Exploiting Latent and Global Information in Event\n",
            "Classification”. In:Proceedings of the Association for the Advancement of Arti-\n",
            "ficial Intel ligence (AAAI).\n",
            "McClosky, David, Surdeanu, Mihai, and Manning, Chris (2011). “Event Extrac-\n",
            "tion as Dependency Parsing”. In:Proceedings of the Annual Meeting of the\n",
            "Association for Computational Linguistics (ACL) .\n",
            "McClosky, David, Charniak, Eugene, and Johnson, Mark (2010). “Automatic Do-\n",
            "main Adaptation for Parsing”. In:Proceedings of the North American Chapter\n",
            "of the Association for Computational Linguistics Conference (HL T-NAACL).\n",
            "Mendes, Pablo N., Jakob, Max, García-Silva, Andrés, and Bizer, Christian (2011).\n",
            "“DBpedia Spotlight: Shedding Light on the Web of Documents”. In:Proceedings\n",
            "of the 7th International Conference on Semantic Systems .\n",
            "Mesnil, Gregoire, He, Xiaodong, Deng, Li, and Bengio, Yoshua (2013). “Investi-\n",
            "gation of Recurrent Neural Network Architectures and Learning Methods for\n",
            "Spoken Language Understanding”. In:Interspeech.\n",
            "Mikolov, Tomas, Chen, Kai, Corrado, Greg, and Dean, Jeffrey (2013a). “Efficient\n",
            "Estimation of Word Representations in Vector Space”. In:Proceedings of the\n",
            "International Conference on Learning Representations (ICLR).\n",
            "Mikolov, Tomas, Sutskever, Ilya, Chen, Kai, Corrado, Greg, and Dean, Jeffrey\n",
            "(2013b). “Distributed Representations of Words and Phrases and their Compo-\n",
            "sitionality”. In:Proceedings of the Conference on Neural Information Processing\n",
            "Systems (NIPS) .\n",
            "214\n",
            "  ID: 6a0057b3-9ea2-4791-a062-6ddced48259c\n",
            "--------------------\n",
            "Node 266:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Miller, Scott, Guinness, Jethran, and Zamanian, Alex (2004). “Name Tagging\n",
            "with Word Clusters and Discriminative Training”. In:Proceedings of the North\n",
            "American Chapter of the Association for Computational Linguistics Conference\n",
            "(HL T-NAACL).\n",
            "Milne, David and Witten, Ian H. (2008). “Learning to Link with Wikipedia”. In:\n",
            "Proceedings of the Conference on Information and Knowledge Management\n",
            "(CIKM).\n",
            "Min, Bonan, Shi, Shuming, Grishman, Ralph, and Lin, Chin-Yew (2012). “Ensem-\n",
            "ble Semantics for Large-scale Unsupervised Relation Extraction”. In:Proceed-\n",
            "ings of the Conference on Empirical Methods in Natural Language Processing\n",
            "(EMNLP).\n",
            "Mintz, M., Bills, S., Snow, R., and Jurafsky, D. (2009). “Distant Supervision for\n",
            "Relation Extraction without Labeled Data”. In:Proceedings of the 47th Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Miwa, Makoto, Thompson, Paul, Korkontzelos, Ioannis, and Ananiadou, Sophia\n",
            "(2014). “Comparable Study of Event Extraction in Newswire and Biomedical\n",
            "Domains”. In:Proceedings of the International Conference on Computational\n",
            "Linguistics (COLING) .\n",
            "Mnih, Andriy and Hinton, Geoffrey (2007). “Three new Graphical Models for Sta-\n",
            "tistical Language Modelling”. In:Proceedings of the International Conference\n",
            "on Machine Learning (ICML) .\n",
            "Mnih, Andriy and Hinton, Geoffrey (2008). “A Scalable Hierarchical Distributed\n",
            "Language Model”. In: Proceedings of the Conference on Neural Information\n",
            "Processing Systems (NIPS).\n",
            "215\n",
            "  ID: 47f3c203-79f3-42a4-b00c-91d906f52e42\n",
            "--------------------\n",
            "Node 267:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Moschitti, Alessandro (2006). “Efficient Convolution Kernels for Dependency and\n",
            "Constituent Syntactic Trees”. In:Proceedings of the European Conference on\n",
            "Machine Learning and Principles and Practice of Knowledge Discovery in\n",
            "Databases (ECML PKDD) .\n",
            "Moschitti, Alessandro (2008). “Kernel Methods, Syntax and Semantics for Rela-\n",
            "tional Text Categorization”. In:Proceedings of the International Conference on\n",
            "Information and Knowledge Management (CIKM) .\n",
            "Nguyen,T.Truc-Vien,Moschitti,Alessandro,andRiccardi,Giuseppe(2009).“Con-\n",
            "volution Kernels on Constituent, Dependency and Sequential Structures for Re-\n",
            "lation Extraction”. In:Proceedings of the Conference on Empirical Methods in\n",
            "Natural Language Processing (EMNLP).\n",
            "Nguyen, Thien Huu and Grishman, Ralph (2014a). “Employing Word Represen-\n",
            "tations and Regularization for Domain Adaptation of Relation Extraction”. In:\n",
            "Proceedings of the Annual Meeting of the Association for Computational Lin-\n",
            "guistics (ACL).\n",
            "Nguyen, Thien Huu, He, Yifan, Pershina, Maria, Li, Xiang, and Grishman, Ralph\n",
            "(2014b). “New York University 2014 Knowledge Base Population Systems”. In:\n",
            "Proceedings of T ext Analysis Conference (T AC).\n",
            "Nguyen, Dat Ba, Hoffart, Johannes, Theobald, Martin, and Weikum, Gerhard\n",
            "(2014c). “AIDA-light: High-Throughput Named-Entity Disambiguation”. In:\n",
            "Proceedings of the International W orld Wide W eb Conference (WWW).\n",
            "Nguyen, Luan Minh, Tsang, W. Ivor, Chai, A. Kian Ming, and Chieu, Leong Hai\n",
            "(2014d). “Robust Domain Adaptation for Relation Extraction via Clustering\n",
            "Consistency”. In: Proceedings of the Annual Meeting of the Association for\n",
            "Computational Linguistics (ACL) .\n",
            "216\n",
            "  ID: 248cf75b-cb4e-4135-b815-cc41f325f3cc\n",
            "--------------------\n",
            "Node 268:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Nguyen, Thien Huu and Grishman, Ralph (2015a). “Relation Extraction: Perspec-\n",
            "tive from Convolutional Neural Networks”. In:The NAACL W orkshop on V ec-\n",
            "tor Space Modeling for NLP (VSM) .\n",
            "Nguyen, Thien Huu and Grishman, Ralph (2015b). “Event Detection and Domain\n",
            "Adaptation with Convolutional Neural Networks”. In:Proceedings of the Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Nguyen, Thien Huu, Plank, Barbara, and Grishman, Ralph (2015c). “Semantic\n",
            "Representations for Domain Adaptation: A Case Study on the Tree Kernel-\n",
            "based Method for Relation Extraction”. In:Proceedings of the Annual Meeting\n",
            "of the Association for Computational Linguistics (ACL) .\n",
            "Nguyen, Thien Huu, Cho, Kyunghyun, and Grishman, Ralph (2016a). “Joint Event\n",
            "Extraction via Recurrent Neural Networks”. In:NAACL.\n",
            "Nguyen, Thien Huu, Fu, Lisheng, Cho, Kyunghyun, and Grishman, Ralph (2016b).\n",
            "“A Two-stage Approach for Extending Event Detection to New Types via Neu-\n",
            "ral Networks”. In:Proceedings of the 1st ACL W orkshop on Representation\n",
            "Learning for NLP (RepL4NLP).\n",
            "Nguyen, Thien Huu and Grishman, Ralph (2016c). “Combining Neural Networks\n",
            "and Log-linear Models to Improve Relation Extraction”. In:Proceedings of IJ-\n",
            "CAI W orkshop on Deep Learning for Artificial Intel ligence (DLAI).\n",
            "Nguyen, Thien Huu, Sil, Avirup, Dinu, Georgiana, and Florian, Radu (2016d).\n",
            "“Toward Mention Detection Robustness with Recurrent Neural Networks”. In:\n",
            "Proceedings of IJCAI W orkshop on Deep Learning for Artificial Intel ligence\n",
            "(DLAI).\n",
            "217\n",
            "  ID: f9f41221-89be-45d7-993d-ca47e59b3407\n",
            "--------------------\n",
            "Node 269:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Nguyen, Thien Huu and Grishman, Ralph (2016e). “Modeling Skip-Grams for\n",
            "Event Detection with Convolutional Neural Networks”. In:Proceedings of the\n",
            "Conference on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Nguyen, Thien Huu, Fauceglia, Nicolas, Muro, Mariano Rodriguez, Hassanzadeh,\n",
            "Oktie, Gliozzo, Alfio Massimiliano, and Sadoghi, Mohammad (2016f). “Joint\n",
            "Learning of Local and Global Features for Entity Linking via Neural Networks”.\n",
            "In: Proceedings of the International Conference on Computational Linguistics\n",
            "(COLING).\n",
            "Nguyen, Thien Huu, Meyers, Adam, and Grishman, Ralph (2016g). “New York\n",
            "University 2016 System for KBP Event Nugget: A Deep Learning Approach”.\n",
            "In: Proceedings of T ext Analysis Conference (T AC).\n",
            "Nothman, Joel, Ringland, Nicky, Radford, Will, Murphy, Tara, and Curran, James\n",
            "R (2013). “Learning Multilingual Named Entity Recognition from Wikipedia”.\n",
            "In: Artificial Intel ligence.\n",
            "Paperno, Denis, Pham, The Nghia, and Baroni, Marco (2014). “A Practical and\n",
            "Linguistically-motivated Approach to Compositional Distributional Semantics”.\n",
            "In: Proceedings of the Annual Meeting of the Association for Computational\n",
            "Linguistics (ACL).\n",
            "Pascanu, Razvan, Mikolov, Tomas, and Bengio, Yoshua (2012). “On the Difficulty\n",
            "of Training Recurrent Neural Networks”. In:arXiv preprint arXiv:1211.5063 .\n",
            "Passos, Alexandre, Kumar, Vineet, and McCallum, Andrew (2014). “Lexicon In-\n",
            "fused Phrase Embeddings for Named Entity Resolution”. In:Proceedings of the\n",
            "Conference on Computational Natural Language Learning (CoNLL) .\n",
            "218\n",
            "  ID: 28af9215-a78e-42bb-b9f1-cf98eb582720\n",
            "--------------------\n",
            "Node 270:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Patwardhan, Siddharth and Rilof, Ellen (2009). “A Unified Model of Phrasal and\n",
            "Sentential Evidence for Information Extraction”. In:Proceedings of the Confer-\n",
            "ence on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Pedersen, Ted (2008). “Empiricism is Not a Matter of Faith”. In:Computational\n",
            "Linguistics 3 .\n",
            "Pershina, Maria, He, Yifan, and Grishman, Ralph (2015). “Personalized Page Rank\n",
            "for Named Entity Disambiguation”. In: Proceedings of the North American\n",
            "Chapter of the Association for Computational Linguistics Conference (HL T-\n",
            "NAACL).\n",
            "Plank, Barbara and Noord, Gertjan van (2011). “Effective Measures of Domain\n",
            "Similarity for Parsing”. In:Proceedings of the Annual Meeting of the Association\n",
            "for Computational Linguistics (ACL) .\n",
            "Plank,BarbaraandMoschitti,Alessandro(2013).“EmbeddingSemanticSimilarity\n",
            "in Tree Kernels for Domain Adaptation of Relation Extraction”. In:Proceedings\n",
            "of the Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Poon, Hoifung and Vanderwende, Lucy (2010). “Joint Inference for Knowledge\n",
            "Extraction from Biomedical Literature”. In:Proceedings of the North American\n",
            "Chapter of the Association for Computational Linguistics Conference (HL T-\n",
            "NAACL).\n",
            "Qian, Longhua, Zhou, Guodong, Kong, Fang, Zhu, Qiaoming, and Qian, Peide\n",
            "(2008). “Exploiting Constituent Dependencies for Tree Kernel-Based Seman-\n",
            "tic Relation Extraction”. In:Proceedings of the International Conference on\n",
            "Computational Linguistics (COLING) .\n",
            "219\n",
            "  ID: a7a409bb-4fcd-4735-a5c1-867b6553897a\n",
            "--------------------\n",
            "Node 271:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Raghunathan, Karthik, Lee, Heeyoung, Rangarajan, Sudarshan, Chambers, Nate,\n",
            "Surdeanu, Mihai, Jurafsky, Dan, and Manning, Christopher (2010). “A Multi-\n",
            "Pass Sieve for Coreference Resolution”. In:EMNLP.\n",
            "Ratinov, Lev and Roth, Dan (2009). “Design Challenges and Misconceptions in\n",
            "Named Entity Recognition”. In:Proceedings of the Conference on Computa-\n",
            "tional Natural Language Learning (CoNLL) .\n",
            "Ratinov, Lev, Roth, Dan, Downey, Doug, and Anderson, Mike (2011). “Local and\n",
            "Global Algorithms for Disambiguation to Wikipedia”. In:Proceedings of the\n",
            "Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Riedel, Sebastian, Chun, Hong-Woo, Takagi, Toshihisa, and Tsujii, Junichi (2009).\n",
            "“A Markov Logic Approach to Bio-Molecular Event Extraction”. In:Proceedings\n",
            "of the BioNLP 2009 W orkshop Companion V olume for Shared T ask.\n",
            "Riedel, Sebastian and McCallum, Andrew (2011a). “Fast and Robust Joint Models\n",
            "for Biomedical Event Extraction”. In:Proceedings of the Conference on Empir-\n",
            "ical Methods in Natural Language Processing (EMNLP).\n",
            "Riedel, Sebastian and McCallum, Andrew (2011b). “Robust Biomedical Event Ex-\n",
            "traction with Dual Decomposition and Minimal Domain Adaptation”. In:Pro-\n",
            "ceedings of the BioNLP Shared T ask 2011 W orkshop.\n",
            "Riloff, E. (1996). “Automatically Generating Extraction Patterns from Untagged\n",
            "Text”. In:Proceedings of the Thirteenth National Conference on Artificial In-\n",
            "tel ligence (AAAI).\n",
            "Ritter, Alan, Clark, Sam, Mausam, and Etzioni, Oren (2011). “Named Entity\n",
            "Recognition in Tweets: An Experimental Study”. In:Proceedings of the Con-\n",
            "ference on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "220\n",
            "  ID: 12e3bb0a-79fc-4cb8-a2f4-1ee21f960c21\n",
            "--------------------\n",
            "Node 272:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Roth, Dan and Yih, Wen-tau (2004). “A Linear Programming Formulation for\n",
            "Global Inference in Natural Language Tasks”. In:Proceedings of the Conference\n",
            "on Computational Natural Language Learning (CoNLL) .\n",
            "Roth, D. and Yih, W. (2007). “Global Inference for Entity and Relation Identifi-\n",
            "cation via a Linear Programming Formulation”. In:Introduction to Statistical\n",
            "Relational Learning.\n",
            "Sam, Rathany Chan, Le, Huong Thanh, Nguyen, Thuy Thanh, and Nguyen, Thien\n",
            "Huu (2011). “Combining Proper Name-Coreference with Conditional Random\n",
            "Fields for Semi-supervised Named Entity Recognition in Vietnamese Text”. In:\n",
            "Proceedings of the Pacific-Asia Conference on Knowledge Discovery and Data\n",
            "Mining (P AKDD).\n",
            "Sang, Erik F. Tjong Kim and Meulder, Fien De (2002). “Introduction to the\n",
            "CoNLL-2002 Shared Task: Language-Independent Named Entity Recognition”.\n",
            "In: Proceedings of the Conference on Computational Natural Language Learning\n",
            "(CoNLL).\n",
            "Sang, Erik F. Tjong Kim and Meulder, Fien De (2003). “Introduction to the\n",
            "CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition”.\n",
            "In: Proceedings of the Conference on Computational Natural Language Learning\n",
            "(CoNLL).\n",
            "Santos, Cicero dos, Xiang, Bing, and Zhou, Bowen (2015a). “Classifying Relations\n",
            "byRankingwithConvolutionalNeuralNetworks”.In: Proceedings of the Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Schnabel, Tobias and Schütze, Hinrich (2014). “FLORS: Fast and Simple Domain\n",
            "Adaptation for Part-of-Speech Tagging”. In:T ransactions of the Association of\n",
            "Computational Linguistics (T ACL).\n",
            "221\n",
            "  ID: 4e47365a-5c79-4b58-9828-8407f8296cde\n",
            "--------------------\n",
            "Node 273:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Shen, Wei, Wang, Jianyong, Luo, Ping, and Wang, Min (2012). “LINDEN: Linking\n",
            "Named Entities with Knowledge Base via Semantic Knowledge”. In:Proceedings\n",
            "of the International W orld Wide W eb Conference (WWW).\n",
            "Shen,Yelong,He,Xiaodong,Gao,Jianfeng,Deng,Li,andMesnil,Gregoire(2014a).\n",
            "“Learning Semantic Representations Using Convolutional Neural Networks for\n",
            "Web Search”. In:Proceedings of the International W orld Wide W eb Conference\n",
            "(WWW).\n",
            "Shen, Wei, Wang, Jianyong, and Han, Jiawei (2014b). “Entity Linking with a\n",
            "Knowledge Base: Issues, Techniques, and Solutions”. In:TKDE.\n",
            "Shinyama,Y.andSekine,S.(2006).“PreemptiveInformationExtractionUsingUn-\n",
            "restricted Relation Discovery”. In:Proceedings of the North American Chapter\n",
            "of the Association for Computational Linguistics Conference (HL T-NAACL).\n",
            "Singh, Sameer, Riedel, Sebastian, Martin, Brian, Zheng, Jiaping, and McCallum,\n",
            "Andrew (2013). “Joint Inference of Entities, Relations, and Coreference”. In:\n",
            "CIKM W orkshop on Automated Knowledge Base Construction (AKBC).\n",
            "Socher, Richard, Perelygin, Alex, Wu, Jean Y., Chuang, Jason, Manning, Christo-\n",
            "pher D., Ng, Andrew Y., and Potts, Christopher (2012a). “Recursive Deep\n",
            "Models for Semantic Compositionality Over a Sentiment Treebank”. In:Pro-\n",
            "ceedings of the Conference on Empirical Methods in Natural Language Process-\n",
            "ing (EMNLP).\n",
            "Socher, Richard, Huval, Brody, Manning, Christopher D., and Ng, Andrew Y.\n",
            "(2012b).“SemanticCompositionalityThroughRecursiveMatrix-VectorSpaces”.\n",
            "In: Proceedings of the Conference on Empirical Methods in Natural Language\n",
            "Processing (EMNLP).\n",
            "222\n",
            "  ID: 1f54d296-b512-4bf2-ac0c-71d1a8341096\n",
            "--------------------\n",
            "Node 274:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Srivastava,N.,Hinton,G.,Krizhevsky,A.,andSalakhutdinov,R.(2014).“Dropout:\n",
            "A Simple Way to Prevent Neural Networks from Overfitting”. In:Journal of\n",
            "Machine Learning Research 15(1):1929-1958.\n",
            "Sterckx, Lucas, Demeester, Thomas, Deleu, Johannes, and Develder, Chris (2014).\n",
            "“Using Active Learning and Semantic Clustering for Noise Reduction in Distant\n",
            "Supervision”. In:Proceedings of the W orkshop on Automated Knowledge Base\n",
            "Construction.\n",
            "Stevenson, M. and Greenwood, M. A. (2005). “A Semantic Approach to IE Pat-\n",
            "tern Induction”. In:Proceedings of the Annual Meeting of the Association for\n",
            "Computational Linguistics (ACL) .\n",
            "Sun,Ang,Grishman,Ralph,andSekine,Satoshi(2011).“Semi-supervisedRelation\n",
            "Extraction with Large-scale Word Clustering”. In:Proceedings of the Annual\n",
            "Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Sun, Ang and Grishman, Ralph (2012). “Active Learning for Relation Type Exten-\n",
            "sion with Local and Global Data Views”. In:Proceedings of the International\n",
            "Conference on Information and Knowledge Management (CIKM) .\n",
            "Sun, Yaming, Lin, Lei, Tang, Duyu, Yang, Nan, Ji, Zhenzhou, and Wang, Xiao-\n",
            "long (2015). “Modeling Mention, Context and Entity with Neural Networks for\n",
            "Entity Disambiguation”. In:Proceedings of the International Joint Conference\n",
            "on Artificial Intel ligence (IJCAI).\n",
            "Surdeanu, M., Tibshirani, J., Nallapati, R., and Manning, C. D. (2012). “Multi-\n",
            "instance Multi-label Learning for Relation Extraction”. In:Proceedings of the\n",
            "Conference on Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "223\n",
            "  ID: 546d50ad-c8a0-470a-8cda-09e6bc641ebc\n",
            "--------------------\n",
            "Node 275:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Suzuki, Jun and Isozaki, Hideki (2008). “Semi-Supervised Sequential Labeling and\n",
            "Segmentation Using Giga-Word Scale Unlabeled Data”. In:Proceedings of the\n",
            "Annual Meeting of the Association for Computational Linguistics (ACL) .\n",
            "Turian, Joseph, Ratinov, Lev-Arie, and Bengio, Yoshua (2010). “Word Represen-\n",
            "tations: A Simple and General Method for Semi-Supervised Learning”. In:Pro-\n",
            "ceedings of the Annual Meeting of the Association for Computational Linguistics\n",
            "(ACL).\n",
            "Venugopal, Deepak, Chen, Chen, Gogate, Vibhav, and Ng, Vincent (2014). “Reliev-\n",
            "ing the Computational Bottleneck: Joint Inference for Event Extraction with\n",
            "High-Dimensional Features”. In:Proceedings of the Conference on Empirical\n",
            "Methods in Natural Language Processing (EMNLP).\n",
            "Vincent, Pascal, Larochelle, Hugo, Lajoie, Isabelle, Bengio, Yoshua, and Manzagol,\n",
            "Pierre-Antoine (2010). “Stacked Denoising Autoencoders: Learning Useful Rep-\n",
            "resentations in a Deep Network with a Local Denoising Criterion”. In:Journal\n",
            "of Machine Learning Research 11.\n",
            "Wang, Mengqiu (2008). “A Re-examination of Dependency Path Kernels for Re-\n",
            "lation Extraction”. In:Proceedings of the International Joint Conference on\n",
            "Natural Language Processing (IJCNLP).\n",
            "Werning, Markus, Machery, Edouard, and Schurz, Gerhard (2006). “Composition-\n",
            "ality of Meaning and Content: Foundational Issues (Linguistics & Philosophy)”.\n",
            "In: Linguistics & Philosophy .\n",
            "Wiseman, Sam, Rush, Alexander M, Shieber, Stuart M, and Weston, Jason (2015).\n",
            "“Learning Anaphoricity and Antecedent Ranking Features for Coreference Res-\n",
            "olution”. In:Proceedings of the Annual Meeting of the Association for Compu-\n",
            "tational Linguistics (ACL) .\n",
            "224\n",
            "  ID: a4ecf69f-4c13-4f5a-9620-69efdc1aad64\n",
            "--------------------\n",
            "Node 276:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Xiao, Min and Guo, Yuhong (2013). “Domain Adaptation for Sequence Labeling\n",
            "Tasks with a Probabilistic Language Adaptation Model”. In:Proceedings of the\n",
            "International Conference on Machine Learning (ICML) .\n",
            "Xu, Yan, Mou, Lili, Li, Ge, Chen, Yunchuan, Peng, Hao, and Jin, Zhi (2015).\n",
            "“Classifying Relations via Long Short Term Memory Networks along Shortest\n",
            "Dependency Paths”. In:Proceedings of the Conference on Empirical Methods\n",
            "in Natural Language Processing (EMNLP).\n",
            "Yangarber, R., Grishman, R., Tapanainen, P., and Huttunen, S. (2000). “Auto-\n",
            "matic Acquisition of Domain Knowledge for Information Extraction”. In:Pro-\n",
            "ceedings of the International Conference on Computational Linguistics (COL-\n",
            "ING).\n",
            "Yangarber, R., Lin, W., and Grishman, R. (2002). “Unsupervised Learning of Gen-\n",
            "eralized Names”. In:Proceedings of the 19th International Conference on Com-\n",
            "putational Linguistics (COLING) .\n",
            "Yangarber, R. (2003). “Counter-Training in Discovery of Semantic Patterns”. In:\n",
            "Proceedings of the Annual Meeting of the Association for Computational Lin-\n",
            "guistics (ACL).\n",
            "Yao, L., Haghighi, A., Riedel, S., and McCallum, A. (2011). “Structured Rela-\n",
            "tion Discovery Using Generative Models”. In:Proceedings of the Conference on\n",
            "Empirical Methods in Natural Language Processing (EMNLP) .\n",
            "Yao, Kaisheng, Zweig, Geoffrey, Hwang, Mei-Yuh, Shi, Yangyang, and Yu, Dong\n",
            "(2013). “Recurrent Neural Networks for Language Understanding”. In:Inter-\n",
            "speech. Interspeech.\n",
            "Yao, Kaisheng, Peng, Baolin, Zhang, Yu, Yu, Dong, Zweig, Geoffrey, and Shi,\n",
            "Yangyang (2014). “Spoken Language Understanding Using Long Short-Term\n",
            "225\n",
            "  ID: 2430c387-a6b4-402b-9548-a52b83f0484a\n",
            "--------------------\n",
            "Node 277:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Memory Neural Networks”. In:Proceedings of the IEEE W orkshop on Spoken\n",
            "Lanuage T echnology.\n",
            "Yates, A. and Etzioni, O. (2007). “Unsupervised Resolution of Objects and Re-\n",
            "lations on the Web”. In:Proceedings of the North American Chapter of the\n",
            "Association for Computational Linguistics Conference (HL T-NAACL).\n",
            "Yih, Wen-tau, He, Xiaodong, and Meek, Christopher (2014). “Semantic Parsing\n",
            "for Single-Relation Question Answering”. In:Proceedings of the Annual Meeting\n",
            "of the Association for Computational Linguistics (ACL) .\n",
            "Yu, Mo, Gormley, Matthew, and Dredze, Mark (2014). “Factor-based Composi-\n",
            "tional Embedding Models”. In:The NIPS workshop on Learning Semantics .\n",
            "Yu, Mo, Gormley, Matthew, and Dredze, Mark (2015). “Combining Word Em-\n",
            "beddings and Feature Embeddings for Fine-grained Relation Extraction”. In:\n",
            "Proceedings of the North American Chapter of the Association for Computa-\n",
            "tional Linguistics Conference (HL T-NAACL).\n",
            "Zaremba, W., Sutskever, I., and Vinyals, O. (2014). “Recurrent Neural Network\n",
            "Regularization”. In:arXiv preprint arXiv:1409.2329.\n",
            "Zeiler,M.D.(2012).“ADADELTA:AnAdaptiveLearningRateMethod”.In: arXiv\n",
            "preprint arXiv:1212.5701.\n",
            "Zelenko, Dmitry, Aone, Chinatsu, and Richardella, Anthony (2003). “Kernel Meth-\n",
            "ods for Relation Extraction”. In:Journal of Machine Learning Research 3 .\n",
            "Zeng, Daojian, Liu, Kang, Lai, Siwei, Zhou, Guangyou, and Zhao, Jun (2014). “Re-\n",
            "lation Classification via Convolutional Deep Neural Network”. In:Proceedings\n",
            "of the International Conference on Computational Linguistics (COLING) .\n",
            "226\n",
            "  ID: 31a8e9e5-a899-4888-bd2f-c88b599fcf64\n",
            "--------------------\n",
            "Node 278:\n",
            "  Text: BIBLIOGRAPHY\n",
            "Zeng, Daojian, Liu, Kang, Chen, Yubo, and Zhao, Jun (2015). “Distant Super-\n",
            "vision for Relation Extraction via Piecewise Convolutional Neural Networks”.\n",
            "In: Proceedings of the Conference on Empirical Methods in Natural Language\n",
            "Processing (EMNLP).\n",
            "Zhang,Min,Zhang,Jie,Su,Jian,andZhou,Guodong(2006).“ACompositeKernel\n",
            "to Extract Relations between Entities with both Flat and Structured Features”.\n",
            "In: Proceedings of the Annual Meeting of the Association for Computational\n",
            "Linguistics (ACL).\n",
            "Zheng, Zhicheng, Li, Fangtao, Huang, Minlie, and Zhu, Xiaoyan (2010). “Learning\n",
            "to Link Entities with Knowledge Base”. In:Proceedings of the North American\n",
            "Chapter of the Association for Computational Linguistics Conference (HL T-\n",
            "NAACL).\n",
            "Zhou, GuoDong, Su, Jian, Zhang, Jie, and Zhang, Min (2005). “Exploring Various\n",
            "Knowledge in Relation Extraction”. In:Proceedings of the Annual Meeting of\n",
            "the Association for Computational Linguistics (ACL) .\n",
            "Zhou, Jie and Xu, Wei (2015). “End-to-end Learning of Semantic Role Labeling\n",
            "using Recurrent Neural Networks”. In:Proceedings of the Annual Meeting of\n",
            "the Association for Computational Linguistics (ACL) .\n",
            "Zitouni, Imed and Florian, Radu (2008). “Mention Detection Crossing the Lan-\n",
            "guage Barrier”. In: Proceedings of the Conference on Empirical Methods in\n",
            "Natural Language Processing (EMNLP).\n",
            "227\n",
            "  ID: 0a32a608-3f1b-4f40-882f-b329a7642866\n",
            "--------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IWKEqqrfc_Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task\n",
        "\n",
        "Remove textbooks with pdfs from database\n",
        "\n",
        "Keep only important information like ppts, ipynbs and some pdfs related to the module.\n",
        "\n",
        "(Maybe like 3-4 important files for each module)\n",
        "\n",
        "Then parse, make sure all nodes or chunk is of same size and maintaine good overlap between each chunk.\n",
        "\n",
        "Metadata is important add metadata (file_path, id, some important information to easily indentity which chunk it retriving)\n",
        "\n",
        "Then, try with some querys to find relevant information from vectordatabase."
      ],
      "metadata": {
        "id": "7Aqaab-JmfKT"
      }
    }
  ]
}